{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7Aq8ahlpjaY",
        "outputId": "d0dd11ce-ca1e-46f0-8f3d-0458faca8116"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CELL 1: Environment Setup & Data Loading\n",
            "======================================================================\n",
            "\n",
            "[1/5] Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "✓ Drive mounted\n",
            "\n",
            "[2/5] Checking dataset status...\n",
            "Dataset not found, will extract from: /content/drive/MyDrive/STA 160/dataset/aivideo-dataset.zip\n",
            "\n",
            "[3/5] Extracting dataset...\n",
            "  Installing 7z...\n",
            "  Creating extraction directory...\n",
            "  Extracting features and META files...\n",
            "  (This may take 2-3 minutes...)\n",
            "  ✓ Extraction complete\n",
            "\n",
            "[4/5] Locating features...\n",
            "✓ Found features at: /content/aivideo-dataset/features_logmel_sr16k_v1\n",
            "✓ Root directory: /content/aivideo-dataset\n",
            "\n",
            "[5/5] Counting files...\n",
            "✓ Found 9,565 .npz files\n",
            "  Average file size: 5130.3 KB\n",
            "\n",
            "======================================================================\n",
            "SETUP COMPLETE\n",
            "======================================================================\n",
            "ZIP extracted from: /content/drive/MyDrive/STA 160/dataset/aivideo-dataset.zip\n",
            "ROOT_DIR:           /content/aivideo-dataset\n",
            "FEATURE_DIR:        /content/aivideo-dataset/features_logmel_sr16k_v1\n",
            "OUTPUT_DIR:         /content/models/run_01\n",
            "Total .npz files:   9,565\n",
            "======================================================================\n",
            "\n",
            "✅ Cell 1 Complete - Ready for Cell 2\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# CELL 1: Environment Setup & Data Loading (WITH ZIP EXTRACTION)\n",
        "# ==============================================================================\n",
        "\n",
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CELL 1: Environment Setup & Data Loading\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Mount Drive\n",
        "print(\"\\n[1/5] Mounting Google Drive...\")\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "print(\"✓ Drive mounted\")\n",
        "\n",
        "# Check if dataset needs extraction\n",
        "print(\"\\n[2/5] Checking dataset status...\")\n",
        "\n",
        "ZIP_PATH = \"/content/drive/MyDrive/STA 160/dataset/aivideo-dataset.zip\"\n",
        "EXTRACT_TO = \"/content\"\n",
        "ROOT_DIR = Path(\"/content/aivideo-dataset\")\n",
        "\n",
        "# Check if already extracted\n",
        "if ROOT_DIR.exists() and any(ROOT_DIR.glob(\"**/*.npz\")):\n",
        "    print(f\"✓ Dataset already extracted at: {ROOT_DIR}\")\n",
        "    skip_extraction = True\n",
        "else:\n",
        "    print(f\"Dataset not found, will extract from: {ZIP_PATH}\")\n",
        "    skip_extraction = False\n",
        "\n",
        "# Extract if needed\n",
        "if not skip_extraction:\n",
        "    print(\"\\n[3/5] Extracting dataset...\")\n",
        "\n",
        "    if not Path(ZIP_PATH).exists():\n",
        "        print(f\"❌ ERROR: ZIP file not found at: {ZIP_PATH}\")\n",
        "        raise FileNotFoundError(f\"ZIP not found: {ZIP_PATH}\")\n",
        "\n",
        "    print(\"  Installing 7z...\")\n",
        "    !apt-get -yq install p7zip-full > /dev/null 2>&1\n",
        "\n",
        "    print(\"  Creating extraction directory...\")\n",
        "    !mkdir -p {EXTRACT_TO}/aivideo-dataset\n",
        "\n",
        "    print(\"  Extracting features and META files...\")\n",
        "    print(\"  (This may take 2-3 minutes...)\")\n",
        "\n",
        "    # Extract\n",
        "    !7z x \"{ZIP_PATH}\" -o{EXTRACT_TO} -y \\\n",
        "      -ir!*/META*.parquet \\\n",
        "      -ir!*/features_logmel_sr16k_v1/* \\\n",
        "      -ir!*/features_logmel_sr16k_v1_canonical/* \\\n",
        "      > /dev/null 2>&1\n",
        "\n",
        "    print(\"  ✓ Extraction complete\")\n",
        "else:\n",
        "    print(\"\\n[3/5] Skipping extraction (already done)\")\n",
        "\n",
        "# Find features directory\n",
        "print(\"\\n[4/5] Locating features...\")\n",
        "\n",
        "# Search for features\n",
        "feature_search = !find /content -maxdepth 3 -type d -name \"features_logmel_sr16k_v1*\" -print\n",
        "\n",
        "if feature_search:\n",
        "    # Take first result\n",
        "    FEATURE_DIR = Path(feature_search[0])\n",
        "    print(f\"✓ Found features at: {FEATURE_DIR}\")\n",
        "\n",
        "    # Update ROOT_DIR to parent\n",
        "    ROOT_DIR = FEATURE_DIR.parent\n",
        "    print(f\"✓ Root directory: {ROOT_DIR}\")\n",
        "else:\n",
        "    print(\"❌ Features directory not found after extraction!\")\n",
        "    print(\"\\nSearching for any .npz files...\")\n",
        "    npz_files = !find /content -name \"*.npz\" -print 2>/dev/null | head -5\n",
        "\n",
        "    if npz_files and npz_files[0]:\n",
        "        print(f\"Found .npz files at: {npz_files[0]}\")\n",
        "        FEATURE_DIR = Path(npz_files[0]).parent\n",
        "        ROOT_DIR = FEATURE_DIR.parent\n",
        "        print(f\"✓ Using FEATURE_DIR: {FEATURE_DIR}\")\n",
        "    else:\n",
        "        print(\"\\n❌ ERROR: No .npz files found!\")\n",
        "        print(\"\\nShowing /content structure:\")\n",
        "        !ls -la /content/\n",
        "\n",
        "        if Path(\"/content/aivideo-dataset\").exists():\n",
        "            print(\"\\nShowing /content/aivideo-dataset:\")\n",
        "            !ls -la /content/aivideo-dataset/\n",
        "\n",
        "        raise FileNotFoundError(\"No features found after extraction\")\n",
        "\n",
        "# Count files\n",
        "print(\"\\n[5/5] Counting files...\")\n",
        "all_npz_files = sorted(glob.glob(str(FEATURE_DIR / \"*.npz\")))\n",
        "total_files = len(all_npz_files)\n",
        "\n",
        "if total_files == 0:\n",
        "    print(\"❌ No .npz files in features directory!\")\n",
        "    print(f\"Directory: {FEATURE_DIR}\")\n",
        "    print(\"\\nContents:\")\n",
        "    !ls -la {FEATURE_DIR}\n",
        "    raise FileNotFoundError(\"No .npz files found\")\n",
        "\n",
        "print(f\"✓ Found {total_files:,} .npz files\")\n",
        "\n",
        "# Check file sizes\n",
        "sample_sizes = [Path(f).stat().st_size for f in all_npz_files[:10]]\n",
        "avg_size = sum(sample_sizes) / len(sample_sizes)\n",
        "print(f\"  Average file size: {avg_size/1024:.1f} KB\")\n",
        "\n",
        "# Create output directory\n",
        "OUTPUT_DIR = Path(\"/content/models/run_01\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Save config\n",
        "import json\n",
        "config = {\n",
        "    'ROOT_DIR': str(ROOT_DIR),\n",
        "    'FEATURE_DIR': str(FEATURE_DIR),\n",
        "    'OUTPUT_DIR': str(OUTPUT_DIR),\n",
        "    'total_files': total_files,\n",
        "    'zip_path': ZIP_PATH\n",
        "}\n",
        "\n",
        "config_path = OUTPUT_DIR / \"config.json\"\n",
        "with open(config_path, 'w') as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "\n",
        "# Summary\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SETUP COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"ZIP extracted from: {ZIP_PATH}\")\n",
        "print(f\"ROOT_DIR:           {ROOT_DIR}\")\n",
        "print(f\"FEATURE_DIR:        {FEATURE_DIR}\")\n",
        "print(f\"OUTPUT_DIR:         {OUTPUT_DIR}\")\n",
        "print(f\"Total .npz files:   {total_files:,}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n✅ Cell 1 Complete - Ready for Cell 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKdZJerdpoP-",
        "outputId": "36bac6a2-37f1-4e0f-865e-726e69e3783b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CELL 2: Clean Orphaned Files & Select 4,000 Samples\n",
            "======================================================================\n",
            "\n",
            "[1/6] Loading configuration...\n",
            "✓ FEATURE_DIR: /content/aivideo-dataset/features_logmel_sr16k_v1\n",
            "✓ Total files: 9,565\n",
            "\n",
            "[2/6] Validating feature files...\n",
            "  Found 9,565 .npz files\n",
            "  Validating files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 9565/9565 [08:31<00:00, 18.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ Valid files: 9,565\n",
            "✗ Invalid files: 0\n",
            "\n",
            "[3/6] Removing orphaned/corrupted files...\n",
            "✓ No orphaned files to remove\n",
            "\n",
            "[4/6] Selecting 4,000 samples...\n",
            "✓ Selected 4,000 files randomly\n",
            "\n",
            "[5/6] Verifying selection...\n",
            "  Time frames - Min: 9005, Max: 64989, Mean: 24086\n",
            "✓ Verification complete\n",
            "\n",
            "[6/6] Saving file list...\n",
            "✓ Saved to: /content/models/run_01/feature_list_4k.txt\n",
            "\n",
            "======================================================================\n",
            "CLEANING COMPLETE\n",
            "======================================================================\n",
            "Total files found:    9,565\n",
            "Valid files:          9,565\n",
            "Invalid files:        0\n",
            "Selected for dataset: 4,000\n",
            "File list saved:      /content/models/run_01/feature_list_4k.txt\n",
            "======================================================================\n",
            "\n",
            "✅ Cell 2 Complete - Ready for Cell 3\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "CELL 2: Clean Orphaned Files & Select 4,000 Samples\n",
        "====================================================\n",
        "\n",
        "Purpose:\n",
        "- Load configuration from Cell 1\n",
        "- Validate all feature files\n",
        "- Remove corrupted/orphaned files\n",
        "- Select exactly 4,000 good samples\n",
        "- Save list of valid files\n",
        "\n",
        "Output:\n",
        "- feature_list_4k.txt: List of 4,000 valid feature paths\n",
        "- Cleaned feature directory\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CELL 2: Clean Orphaned Files & Select 4,000 Samples\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ==================== LOAD CONFIG ====================\n",
        "print(\"\\n[1/6] Loading configuration...\")\n",
        "\n",
        "OUTPUT_DIR = Path(\"/content/models/run_01\")\n",
        "config_path = OUTPUT_DIR / \"config.json\"\n",
        "\n",
        "if not config_path.exists():\n",
        "    raise FileNotFoundError(\"Config not found. Run Cell 1 first!\")\n",
        "\n",
        "with open(config_path, 'r') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "ROOT_DIR = Path(config['ROOT_DIR'])\n",
        "FEATURE_DIR = Path(config['FEATURE_DIR'])\n",
        "\n",
        "print(f\"✓ FEATURE_DIR: {FEATURE_DIR}\")\n",
        "print(f\"✓ Total files: {config['total_files']:,}\")\n",
        "\n",
        "# ==================== VALIDATE FEATURES ====================\n",
        "print(\"\\n[2/6] Validating feature files...\")\n",
        "\n",
        "MEL_BINS = 128\n",
        "MIN_FRAMES = 32\n",
        "\n",
        "def validate_feature_file(filepath):\n",
        "    \"\"\"\n",
        "    Validate a feature file.\n",
        "\n",
        "    Returns:\n",
        "        (is_valid, reason, shape) tuple\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Check file size first\n",
        "        size = Path(filepath).stat().st_size\n",
        "        if size < 1024:  # Less than 1KB\n",
        "            return False, \"too_small\", None\n",
        "\n",
        "        # Try to load\n",
        "        if str(filepath).endswith('.npy'):\n",
        "            arr = np.load(filepath, allow_pickle=False)\n",
        "        else:\n",
        "            with np.load(filepath, allow_pickle=False) as data:\n",
        "                # Try common key names\n",
        "                arr = None\n",
        "                for key in ['logmel', 'log_mel', 'mel', 'features', 'x', 'S']:\n",
        "                    if key in data:\n",
        "                        arr = data[key]\n",
        "                        break\n",
        "\n",
        "                # If no common key, take first array\n",
        "                if arr is None:\n",
        "                    for key in data.files:\n",
        "                        if isinstance(data[key], np.ndarray):\n",
        "                            arr = data[key]\n",
        "                            break\n",
        "\n",
        "        if arr is None:\n",
        "            return False, \"no_array\", None\n",
        "\n",
        "        # Check dimensionality\n",
        "        if arr.ndim == 3 and 1 in arr.shape:\n",
        "            arr = arr.squeeze()\n",
        "\n",
        "        if arr.ndim != 2:\n",
        "            return False, f\"wrong_dims_{arr.ndim}D\", arr.shape\n",
        "\n",
        "        # Check mel bins\n",
        "        if arr.shape[0] != MEL_BINS and arr.shape[1] == MEL_BINS:\n",
        "            arr = arr.T\n",
        "\n",
        "        if arr.shape[0] != MEL_BINS:\n",
        "            return False, f\"wrong_mels_{arr.shape[0]}\", arr.shape\n",
        "\n",
        "        # Check time frames\n",
        "        if arr.shape[1] < MIN_FRAMES:\n",
        "            return False, f\"too_short_{arr.shape[1]}\", arr.shape\n",
        "\n",
        "        # Check for NaN/Inf\n",
        "        if not np.isfinite(arr).all():\n",
        "            return False, \"nan_inf\", arr.shape\n",
        "\n",
        "        return True, \"valid\", arr.shape\n",
        "\n",
        "    except Exception as e:\n",
        "        return False, f\"error_{type(e).__name__}\", None\n",
        "\n",
        "# Get all files\n",
        "all_files = sorted(glob.glob(str(FEATURE_DIR / \"*.npz\")))\n",
        "print(f\"  Found {len(all_files):,} .npz files\")\n",
        "\n",
        "# Validate each file\n",
        "print(\"  Validating files...\")\n",
        "valid_files = []\n",
        "invalid_files = []\n",
        "reasons = {}\n",
        "\n",
        "for filepath in tqdm(all_files, desc=\"Validating\"):\n",
        "    is_valid, reason, shape = validate_feature_file(filepath)\n",
        "\n",
        "    if is_valid:\n",
        "        valid_files.append(filepath)\n",
        "    else:\n",
        "        invalid_files.append((filepath, reason, shape))\n",
        "        reasons[reason] = reasons.get(reason, 0) + 1\n",
        "\n",
        "print(f\"\\n✓ Valid files: {len(valid_files):,}\")\n",
        "print(f\"✗ Invalid files: {len(invalid_files):,}\")\n",
        "\n",
        "if reasons:\n",
        "    print(\"\\nInvalid file reasons:\")\n",
        "    for reason, count in sorted(reasons.items(), key=lambda x: -x[1]):\n",
        "        print(f\"  {reason}: {count}\")\n",
        "\n",
        "# ==================== REMOVE ORPHANED FILES ====================\n",
        "print(f\"\\n[3/6] Removing orphaned/corrupted files...\")\n",
        "\n",
        "if len(invalid_files) > 0:\n",
        "    # Create backup directory\n",
        "    backup_dir = FEATURE_DIR.parent / \"features_backup_bad\"\n",
        "    backup_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    removed_count = 0\n",
        "    for filepath, reason, shape in invalid_files[:100]:  # Limit to 100 for safety\n",
        "        try:\n",
        "            # Move to backup instead of deleting\n",
        "            filename = Path(filepath).name\n",
        "            backup_path = backup_dir / filename\n",
        "            os.rename(filepath, backup_path)\n",
        "            removed_count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"  Warning: Could not move {filename}: {e}\")\n",
        "\n",
        "    print(f\"✓ Moved {removed_count} bad files to backup\")\n",
        "    print(f\"  Backup location: {backup_dir}\")\n",
        "else:\n",
        "    print(\"✓ No orphaned files to remove\")\n",
        "\n",
        "# ==================== SELECT 4,000 SAMPLES ====================\n",
        "print(f\"\\n[4/6] Selecting 4,000 samples...\")\n",
        "\n",
        "TARGET_COUNT = 4000\n",
        "\n",
        "if len(valid_files) < TARGET_COUNT:\n",
        "    print(f\"⚠️  Warning: Only {len(valid_files):,} valid files available\")\n",
        "    print(f\"   Using all {len(valid_files):,} files instead of {TARGET_COUNT}\")\n",
        "    selected_files = valid_files\n",
        "else:\n",
        "    # Random sampling for diversity\n",
        "    import random\n",
        "    random.seed(2025)\n",
        "    selected_files = random.sample(valid_files, TARGET_COUNT)\n",
        "    selected_files.sort()  # Sort for reproducibility\n",
        "    print(f\"✓ Selected {len(selected_files):,} files randomly\")\n",
        "\n",
        "# ==================== VERIFY SELECTION ====================\n",
        "print(f\"\\n[5/6] Verifying selection...\")\n",
        "\n",
        "# Check distribution\n",
        "sample_shapes = []\n",
        "for filepath in selected_files[:100]:  # Check first 100\n",
        "    _, _, shape = validate_feature_file(filepath)\n",
        "    if shape:\n",
        "        sample_shapes.append(shape[1])  # Time frames\n",
        "\n",
        "if sample_shapes:\n",
        "    import numpy as np\n",
        "    print(f\"  Time frames - Min: {min(sample_shapes)}, Max: {max(sample_shapes)}, Mean: {np.mean(sample_shapes):.0f}\")\n",
        "\n",
        "print(f\"✓ Verification complete\")\n",
        "\n",
        "# ==================== SAVE FILE LIST ====================\n",
        "print(f\"\\n[6/6] Saving file list...\")\n",
        "\n",
        "output_file = OUTPUT_DIR / \"feature_list_4k.txt\"\n",
        "with open(output_file, 'w') as f:\n",
        "    for filepath in selected_files:\n",
        "        f.write(filepath + '\\n')\n",
        "\n",
        "print(f\"✓ Saved to: {output_file}\")\n",
        "\n",
        "# Update config\n",
        "config['valid_files'] = len(valid_files)\n",
        "config['selected_files'] = len(selected_files)\n",
        "config['feature_list'] = str(output_file)\n",
        "\n",
        "with open(OUTPUT_DIR / \"config.json\", 'w') as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "\n",
        "# ==================== SUMMARY ====================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CLEANING COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Total files found:    {len(all_files):,}\")\n",
        "print(f\"Valid files:          {len(valid_files):,}\")\n",
        "print(f\"Invalid files:        {len(invalid_files):,}\")\n",
        "print(f\"Selected for dataset: {len(selected_files):,}\")\n",
        "print(f\"File list saved:      {output_file}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n✅ Cell 2 Complete - Ready for Cell 3\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-rqYve3A0l0t",
        "outputId": "298a6916-2baa-4441-d0ae-9e654b54ba1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CELL 3: Build Master with Quality Signals\n",
            "======================================================================\n",
            "\n",
            "[1/6] Loading configuration...\n",
            "\n",
            "[2/6] Loading feature list...\n",
            "✓ Loaded 4,000 features\n",
            "\n",
            "[3/6] Loading META.parquet & Kaggle CSV...\n",
            "✓ META rows: 9,578\n",
            "\n",
            "[4/6] Matching features to metadata...\n",
            "✓ Matched 1,607 / 4,200 (38.3%)\n",
            "✓ After filtering: 1,598 rows\n",
            "\n",
            "[5/6] Computing quality signals...\n",
            "✓ Quality signals computed\n",
            "  Samples: 1,598\n",
            "\n",
            "[6/6] Saving master metadata...\n",
            "\n",
            "======================================================================\n",
            "METADATA COMPLETE\n",
            "======================================================================\n",
            "Samples:  1,598\n",
            "Targets:  ['user_engagement_signal', 'platform_quality_signal', 'quality_final']\n",
            "Output:   /content/models/run_01/META_master_4k.parquet\n",
            "======================================================================\n",
            "\n",
            "Target statistics:\n",
            "  user_engagement_signal: mean=0.000  std=1.000  min=-1.730  max=1.730\n",
            "  platform_quality_signal: mean=-0.000  std=1.000  min=-3.965  max=1.752\n",
            "  quality_final: mean=0.000  std=1.000  min=-2.413  max=1.759\n",
            "\n",
            "✅ Cell 3 Complete\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "CELL 3: Build Master with Quality Signals (case-safe, META+Kaggle)\n",
        "------------------------------------------------------------------\n",
        "- Loads feature list produced earlier (4k paths)\n",
        "- Extracts video_id from filenames (PRESERVE ORIGINAL CASE)\n",
        "- Loads META.parquet and Kaggle CSV\n",
        "- Joins on a case-insensitive helper key (video_id_upper) but keeps original case\n",
        "- Computes: user_engagement_signal, platform_quality_signal, quality_final\n",
        "\"\"\"\n",
        "\n",
        "import os, json, re\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CELL 3: Build Master with Quality Signals\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ---------------- [1/6] Load configuration ----------------\n",
        "print(\"\\n[1/6] Loading configuration...\")\n",
        "OUTPUT_DIR = Path(\"/content/models/run_01\")\n",
        "CONFIG_PATH = OUTPUT_DIR / \"config.json\"\n",
        "cfg = json.loads(CONFIG_PATH.read_text())\n",
        "\n",
        "ROOT_DIR = Path(cfg.get(\"ROOT_DIR\", \"/content/aivideo-dataset\"))\n",
        "FEATURE_DIR = Path(cfg.get(\"feature_dir\", str(ROOT_DIR / \"features_logmel_sr16k_v1\")))\n",
        "feature_list_file = cfg[\"feature_list\"]   # created by your previous cell\n",
        "\n",
        "# ---------------- [2/6] Load feature list ----------------\n",
        "print(\"\\n[2/6] Loading feature list...\")\n",
        "with open(feature_list_file, \"r\") as f:\n",
        "    feature_paths = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "df_features = pd.DataFrame({\"feature_path\": feature_paths})\n",
        "df_features[\"filename\"] = df_features[\"feature_path\"].apply(lambda x: Path(x).name)\n",
        "# DO NOT upper-case here (YouTube IDs are case-sensitive)\n",
        "df_features[\"video_id\"] = df_features[\"filename\"].str.replace(\".npz\", \"\", regex=False)\n",
        "\n",
        "print(f\"✓ Loaded {len(df_features):,} features\")\n",
        "\n",
        "# ---------------- [3/6] Load META & Kaggle ----------------\n",
        "print(\"\\n[3/6] Loading META.parquet & Kaggle CSV...\")\n",
        "\n",
        "# Locate META\n",
        "meta_candidates = [\n",
        "    ROOT_DIR / \"META.parquet\",\n",
        "    Path(\"/content/aivideo-dataset/META.parquet\"),\n",
        "    Path(\"/content/drive/MyDrive/STA 160/dataset/META.parquet\"),\n",
        "]\n",
        "meta_path = next((p for p in meta_candidates if p.exists()), None)\n",
        "if meta_path is None:\n",
        "    # fallback: search\n",
        "    found = list(ROOT_DIR.glob(\"**/META*.parquet\"))\n",
        "    meta_path = found[0] if found else None\n",
        "if meta_path is None:\n",
        "    raise FileNotFoundError(\"META.parquet not found\")\n",
        "\n",
        "meta = pd.read_parquet(meta_path)\n",
        "print(f\"✓ META rows: {len(meta):,}\")\n",
        "\n",
        "# Normalize META IDs (create helper key, keep original column untouched)\n",
        "if \"video_id\" not in meta.columns:\n",
        "    for alt in [\"id\", \"videoId\", \"yt_video_id\", \"youtube_id\"]:\n",
        "        if alt in meta.columns:\n",
        "            meta = meta.rename(columns={alt: \"video_id\"})\n",
        "            print(f\"  Using '{alt}' as video_id\")\n",
        "            break\n",
        "if \"video_id\" not in meta.columns:\n",
        "    meta[\"video_id\"] = pd.NA\n",
        "\n",
        "meta[\"video_id\"] = meta[\"video_id\"].astype(str)\n",
        "meta[\"video_id_upper\"] = meta[\"video_id\"].str.upper()\n",
        "\n",
        "# Ensure META count columns exist (rename common aliases)\n",
        "alias_map = {\n",
        "    \"views\": [\"views\", \"view_count\", \"yt_views\", \"Views\"],\n",
        "    \"likes\": [\"likes\", \"like_count\", \"yt_likes\", \"Likes\"],\n",
        "    \"comments\": [\"comments\", \"comment_count\", \"yt_comments\", \"Comments\"],\n",
        "}\n",
        "for tgt, aliases in alias_map.items():\n",
        "    if tgt not in meta.columns:\n",
        "        for a in aliases:\n",
        "            if a in meta.columns:\n",
        "                meta = meta.rename(columns={a: tgt})\n",
        "                break\n",
        "for col in [\"views\",\"likes\",\"comments\"]:\n",
        "    if col in meta.columns:\n",
        "        meta[col] = pd.to_numeric(meta[col], errors=\"coerce\")\n",
        "\n",
        "# Load Kaggle (optional enrichment)\n",
        "kag_path = Path(\"/content/drive/My Drive/STA 160/Spotify Youtube Dataset.csv\")\n",
        "if kag_path.exists():\n",
        "    kag = pd.read_csv(kag_path)\n",
        "    def extract_vid(u):\n",
        "        if pd.isna(u): return None\n",
        "        u = str(u)\n",
        "        if \"youtube.com/watch\" in u:\n",
        "            return parse_qs(urlparse(u).query).get(\"v\", [None])[0]\n",
        "        if \"youtu.be/\" in u:\n",
        "            return u.split(\"youtu.be/\")[-1].split(\"?\")[0]\n",
        "        m = re.search(r\"[?&]v=([^&]+)\", u)\n",
        "        return m.group(1) if m else None\n",
        "    kag[\"video_id\"] = kag[\"Url_youtube\"].apply(extract_vid).astype(str)\n",
        "    kag[\"video_id_upper\"] = kag[\"video_id\"].str.upper()\n",
        "\n",
        "    # standardize columns\n",
        "    for src, dst in [(\"Views\",\"views\"),(\"Likes\",\"likes\"),(\"Comments\",\"comments\"),\n",
        "                     (\"Artist\",\"artist\"),(\"Track\",\"track\")]:\n",
        "        if src in kag.columns:\n",
        "            kag = kag.rename(columns={src: dst})\n",
        "    for c in [\"views\",\"likes\",\"comments\"]:\n",
        "        if c in kag.columns:\n",
        "            kag[c] = pd.to_numeric(kag[c], errors=\"coerce\")\n",
        "else:\n",
        "    kag = pd.DataFrame(columns=[\"video_id\",\"video_id_upper\",\"views\",\"likes\",\"comments\",\"artist\",\"track\"])\n",
        "\n",
        "# ---------------- [4/6] Match features to META/Kaggle ----------------\n",
        "print(\"\\n[4/6] Matching features to metadata...\")\n",
        "\n",
        "df_features[\"video_id_upper\"] = df_features[\"video_id\"].astype(str).str.upper()\n",
        "\n",
        "keep_meta = [\"video_id\",\"video_id_upper\",\"views\",\"likes\",\"comments\",\"channel\",\"yt_channel\",\"published_date\"]\n",
        "keep_meta = [c for c in keep_meta if c in meta.columns]\n",
        "m = df_features.merge(meta[keep_meta], on=\"video_id_upper\", how=\"left\", suffixes=(\"\",\"_meta\"))\n",
        "\n",
        "# Fill from Kaggle where META missing\n",
        "if not kag.empty:\n",
        "    keep_kag = [\"video_id_upper\",\"views\",\"likes\",\"comments\",\"artist\",\"track\"]\n",
        "    keep_kag = [c for c in keep_kag if c in kag.columns]\n",
        "    m = m.merge(kag[keep_kag], on=\"video_id_upper\", how=\"left\", suffixes=(\"\",\"_kag\"))\n",
        "    # prefer META first, then Kaggle\n",
        "    for col in [\"views\",\"likes\",\"comments\"]:\n",
        "        src_meta = col\n",
        "        src_kag  = f\"{col}_kag\"\n",
        "        if src_meta not in m.columns and src_kag in m.columns:\n",
        "            m[src_meta] = np.nan\n",
        "        if src_meta in m.columns and src_kag in m.columns:\n",
        "            m[src_meta] = m[src_meta].where(m[src_meta].notna(), m[src_kag])\n",
        "\n",
        "matched = int(m[\"views\"].notna().sum())\n",
        "print(f\"✓ Matched {matched:,} / {len(m):,} ({matched/len(m)*100:.1f}%)\")\n",
        "\n",
        "# Keep only rows with all three counts\n",
        "for c in [\"likes\",\"comments\"]:\n",
        "    if c not in m.columns:\n",
        "        m[c] = np.nan\n",
        "master = m.dropna(subset=[\"views\",\"likes\",\"comments\"], how=\"any\").reset_index(drop=True)\n",
        "print(f\"✓ After filtering: {len(master):,} rows\")\n",
        "\n",
        "# ---------------- [5/6] Compute quality signals ----------------\n",
        "print(\"\\n[5/6] Computing quality signals...\")\n",
        "\n",
        "master[\"views_log\"] = np.log1p(master[\"views\"].fillna(0))\n",
        "\n",
        "# channel key\n",
        "if \"channel\" in master.columns and master[\"channel\"].notna().any():\n",
        "    ch_key = \"channel\"\n",
        "elif \"yt_channel\" in master.columns and master[\"yt_channel\"].notna().any():\n",
        "    ch_key = \"yt_channel\"\n",
        "else:\n",
        "    master[\"_channel\"] = \"all\"\n",
        "    ch_key = \"_channel\"\n",
        "\n",
        "# week key\n",
        "if \"published_date\" in master.columns:\n",
        "    master[\"_week\"] = pd.to_datetime(master[\"published_date\"], errors=\"coerce\").dt.to_period(\"W\").astype(str)\n",
        "else:\n",
        "    master[\"_week\"] = \"all\"\n",
        "\n",
        "# Laplace-smoothed engagement rate\n",
        "k_prior = 4.0\n",
        "likes_rate    = (master[\"likes\"]    + 1) / (master[\"views\"] + k_prior)\n",
        "comments_rate = (master[\"comments\"] + 1) / (master[\"views\"] + k_prior)\n",
        "eng_rate = 0.8 * likes_rate + 0.2 * comments_rate\n",
        "master[\"engagement_rate\"] = eng_rate\n",
        "\n",
        "# User engagement signal (within-week percentile → channel-normalized z)\n",
        "eng_rank = master.groupby(\"_week\")[\"engagement_rate\"].rank(pct=True)\n",
        "er_mu = eng_rank.groupby(master[ch_key]).transform(\"mean\")\n",
        "er_sd = eng_rank.groupby(master[ch_key]).transform(\"std\").replace(0, 1)\n",
        "user_eng = (eng_rank - er_mu) / er_sd\n",
        "user_eng = user_eng.fillna(0)\n",
        "\n",
        "# Platform quality: views_log residual within week, normalized by channel\n",
        "wk_mu = master.groupby(\"_week\")[\"views_log\"].transform(\"mean\")\n",
        "resid = master[\"views_log\"] - wk_mu\n",
        "rw_mu = resid.groupby(master[ch_key]).transform(\"mean\")\n",
        "rw_sd = resid.groupby(master[ch_key]).transform(\"std\").replace(0, 1)\n",
        "plat_qual = (resid - rw_mu) / rw_sd\n",
        "# fallback to simple channel z if needed\n",
        "ch_mu = master.groupby(ch_key)[\"views_log\"].transform(\"mean\")\n",
        "ch_sd = master.groupby(ch_key)[\"views_log\"].transform(\"std\").replace(0, 1)\n",
        "z_ch = (master[\"views_log\"] - ch_mu) / ch_sd\n",
        "plat_qual = plat_qual.fillna(z_ch)\n",
        "\n",
        "# Blend & winsorize\n",
        "qual_final = 0.6 * plat_qual + 0.4 * user_eng\n",
        "lo, hi = np.nanquantile(qual_final, [0.01, 0.99])\n",
        "qual_final = np.clip(qual_final, lo, hi)\n",
        "\n",
        "# Standardize signals\n",
        "def standardize(x):\n",
        "    x = pd.Series(x).astype(float)\n",
        "    m, s = x.mean(), x.std()\n",
        "    return (x - m) / (s if s > 0 else 1)\n",
        "\n",
        "master[\"user_engagement_signal\"] = standardize(user_eng).astype(\"float32\")\n",
        "master[\"platform_quality_signal\"] = standardize(plat_qual).astype(\"float32\")\n",
        "master[\"quality_final\"] = standardize(qual_final).astype(\"float32\")\n",
        "\n",
        "# Clean temp cols\n",
        "master.drop(columns=[c for c in [\"_channel\",\"_week\",\"views_log\",\"engagement_rate\"] if c in master.columns], inplace=True)\n",
        "\n",
        "print(\"✓ Quality signals computed\")\n",
        "print(f\"  Samples: {len(master):,}\")\n",
        "\n",
        "# ---------------- [6/6] Save & update config ----------------\n",
        "print(\"\\n[6/6] Saving master metadata...\")\n",
        "out_file = OUTPUT_DIR / \"META_master_4k.parquet\"\n",
        "master.to_parquet(out_file, index=False)\n",
        "\n",
        "cfg[\"master_file\"] = str(out_file)\n",
        "cfg[\"master_rows\"] = int(len(master))\n",
        "cfg[\"targets\"] = [\"user_engagement_signal\",\"platform_quality_signal\",\"quality_final\"]\n",
        "CONFIG_PATH.write_text(json.dumps(cfg, indent=2))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"METADATA COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Samples:  {len(master):,}\")\n",
        "print(f\"Targets:  {cfg['targets']}\")\n",
        "print(f\"Output:   {out_file}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nTarget statistics:\")\n",
        "for t in cfg[\"targets\"]:\n",
        "    vals = master[t]\n",
        "    print(f\"  {t}: mean={vals.mean():.3f}  std={vals.std():.3f}  min={vals.min():.3f}  max={vals.max():.3f}\")\n",
        "print(\"\\n✅ Cell 3 Complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oLf9sPQGFhA",
        "outputId": "8771a42b-d186-4473-d685-8e925355d989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "REBUILDING + ENRICHING MASTER (META + KAGGLE)\n",
            "======================================================================\n",
            "✓ Loaded META: 9,578 rows\n",
            "✓ Found NPZ features: 9,565\n",
            "→ After META join, with ALL 3 targets: 3,286/9,578 (34.3%)\n",
            "\n",
            "Enriching from Kaggle CSV (fill missing targets only)…\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "COVERAGE SUMMARY\n",
            "----------------------------------------------------------------------\n",
            "Total NPZ: 9,578\n",
            "With ALL targets (after enrichment): 3,336 (34.8%)\n",
            "  views    :  3,363 present\n",
            "  likes    :  3,349 present\n",
            "  comments :  3,349 present\n",
            "\n",
            "======================================================================\n",
            "FILES WRITTEN\n",
            "======================================================================\n",
            "MASTER : /content/models/run_01/META_final_clean.parquet\n",
            "TRAIN  : /content/models/run_01/META_training_ready.parquet\n",
            "ENRICH : /content/models/run_01/META_final_enriched.parquet\n",
            "\n",
            "======================================================================\n",
            "FINAL DATASET SUMMARY\n",
            "======================================================================\n",
            "Total NPZ files: 9,578\n",
            "Matched video_ids (any targets): 9,578\n",
            "With all targets (views/likes/comments): 3,336\n",
            "Coverage: 34.8%\n",
            "\n",
            "SAMPLE (first 10 rows with targets):\n",
            "   video_id                                                      feature_path       views     likes  comments        artist                                                                                          track\n",
            "--BHuKeveg4 /content/aivideo-dataset/features_logmel_sr16k_v1/--BHuKeveg4.npz 198040556.0 1616301.0   61093.0    Will Smith                                                                                      Está Rico\n",
            "--FmExEAsM8 /content/aivideo-dataset/features_logmel_sr16k_v1/--FmExEAsM8.npz 178904653.0 2611370.0  133665.0           IVE                                                                                         ELEVEN\n",
            "--zku6TB5NY /content/aivideo-dataset/features_logmel_sr16k_v1/--zku6TB5NY.npz 134100685.0 1458886.0   96831.0       BIGBANG                                                                                     LAST DANCE\n",
            "-18sqJ97gHQ /content/aivideo-dataset/features_logmel_sr16k_v1/-18sqJ97gHQ.npz      2520.0      60.0       0.0      Dina Rae                                                                                        Post It\n",
            "-1J5l0kzGns /content/aivideo-dataset/features_logmel_sr16k_v1/-1J5l0kzGns.npz    349809.0    5627.0     264.0 Vanesa Martín                                                                              Cuando no estabas\n",
            "-4R4wl766t8 /content/aivideo-dataset/features_logmel_sr16k_v1/-4R4wl766t8.npz  14528324.0   70883.0    3924.0  Aleks Syntek                                                                                   Tú Necesitas\n",
            "-59jGD4WrmE /content/aivideo-dataset/features_logmel_sr16k_v1/-59jGD4WrmE.npz 788318126.0 6142541.0  142101.0     Lil Wayne Sucker for Pain (with Wiz Khalifa, Imagine Dragons, Logic & Ty Dolla $ign feat. X Ambassadors)\n",
            "-5u4SjpxVLo /content/aivideo-dataset/features_logmel_sr16k_v1/-5u4SjpxVLo.npz   8863049.0   36309.0    1176.0         Mœnia                                                                                  Dejame Entrar\n",
            "-6J3HfX4sbg /content/aivideo-dataset/features_logmel_sr16k_v1/-6J3HfX4sbg.npz 268455102.0 1981157.0   22148.0    João Gomes                                                                                    Se For Amor\n",
            "-8VfKZCOo_I /content/aivideo-dataset/features_logmel_sr16k_v1/-8VfKZCOo_I.npz 140993773.0 1834062.0   37567.0    Ed Sheeran                                                                     Bam Bam (feat. Ed Sheeran)\n",
            "\n",
            "✅ DATASET READY FOR TRAINING\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# REBUILD + ENRICH MASTER (META + Kaggle) → TRAINING SUBSET\n",
        "# One cell. Safe to re-run. Non-destructive.\n",
        "# ============================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import glob, re\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "\n",
        "# ---------- Config ----------\n",
        "FEATURE_DIR = Path(\"/content/aivideo-dataset/features_logmel_sr16k_v1\")\n",
        "META_PATH   = Path(\"/content/aivideo-dataset/META.parquet\")\n",
        "KAGGLE_CSV  = Path(\"/content/drive/My Drive/STA 160/Spotify Youtube Dataset.csv\")\n",
        "\n",
        "OUTDIR = Path(\"/content/models/run_01\")\n",
        "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
        "MASTER_OUT   = OUTDIR / \"META_final_clean.parquet\"\n",
        "TRAIN_OUT    = OUTDIR / \"META_training_ready.parquet\"\n",
        "ENRICHED_OUT = OUTDIR / \"META_final_enriched.parquet\"   # also write an enriched copy\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"REBUILDING + ENRICHING MASTER (META + KAGGLE)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def extract_video_id(url):\n",
        "    if pd.isna(url):\n",
        "        return None\n",
        "    try:\n",
        "        url = str(url)\n",
        "        if \"youtube.com/watch\" in url:\n",
        "            q = parse_qs(urlparse(url).query)\n",
        "            vid = q.get(\"v\", [None])[0]\n",
        "            return vid\n",
        "        if \"youtu.be/\" in url:\n",
        "            return url.split(\"youtu.be/\")[-1].split(\"?\")[0]\n",
        "        m = re.search(r\"[?&]v=([^&]+)\", url)\n",
        "        if m:\n",
        "            return m.group(1)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "def coerce_numeric(df, cols):\n",
        "    for c in cols:\n",
        "        if c in df.columns:\n",
        "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "# ---------- Load META ----------\n",
        "meta = pd.read_parquet(META_PATH)\n",
        "print(f\"✓ Loaded META: {len(meta):,} rows\")\n",
        "\n",
        "# Normalize/alias video_id\n",
        "if \"video_id\" not in meta.columns:\n",
        "    for alt in [\"id\",\"videoId\",\"yt_video_id\",\"youtube_id\"]:\n",
        "        if alt in meta.columns:\n",
        "            meta = meta.rename(columns={alt: \"video_id\"})\n",
        "            break\n",
        "meta[\"video_id_upper\"] = meta[\"video_id\"].astype(str).str.upper()\n",
        "\n",
        "# Standardize target columns in META\n",
        "count_aliases = {\n",
        "    \"views\":    [\"views\",\"view_count\",\"yt_views\",\"Views\"],\n",
        "    \"likes\":    [\"likes\",\"like_count\",\"yt_likes\",\"Likes\"],\n",
        "    \"comments\": [\"comments\",\"comment_count\",\"yt_comments\",\"Comments\"],\n",
        "}\n",
        "for tgt, alts in count_aliases.items():\n",
        "    if tgt not in meta.columns:\n",
        "        for a in alts:\n",
        "            if a in meta.columns:\n",
        "                meta = meta.rename(columns={a: tgt})\n",
        "                break\n",
        "coerce_numeric(meta, [\"views\",\"likes\",\"comments\"])\n",
        "\n",
        "# ---------- Load feature file list ----------\n",
        "npz_files = sorted(glob.glob(str(FEATURE_DIR / \"*.npz\")))\n",
        "df_features = pd.DataFrame({\"feature_path\": npz_files})\n",
        "df_features[\"basename\"] = df_features[\"feature_path\"].map(lambda p: Path(p).name)\n",
        "df_features[\"video_id\"] = df_features[\"basename\"].str.replace(\".npz\",\"\",regex=False)\n",
        "df_features[\"video_id_upper\"] = df_features[\"video_id\"].astype(str).str.upper()\n",
        "\n",
        "print(f\"✓ Found NPZ features: {len(df_features):,}\")\n",
        "\n",
        "# ---------- Base merge: features ⟵ META ----------\n",
        "keep_meta_cols = [\"video_id_upper\",\"views\",\"likes\",\"comments\",\"artist\",\"track\",\"channel\",\"yt_channel\",\"published_date\"]\n",
        "keep_meta_cols = [c for c in keep_meta_cols if c in meta.columns]\n",
        "master = df_features.merge(meta[keep_meta_cols], on=\"video_id_upper\", how=\"left\")\n",
        "\n",
        "# Coverage before enrichment\n",
        "base_all = int(master[[\"views\",\"likes\",\"comments\"]].notna().all(axis=1).sum())\n",
        "print(f\"→ After META join, with ALL 3 targets: {base_all:,}/{len(master):,} \"\n",
        "      f\"({base_all/len(master)*100:.1f}%)\")\n",
        "\n",
        "# ---------- Kaggle enrichment (fill only missing) ----------\n",
        "print(\"\\nEnriching from Kaggle CSV (fill missing targets only)…\")\n",
        "try:\n",
        "    kaggle = pd.read_csv(KAGGLE_CSV)\n",
        "except Exception as e:\n",
        "    kaggle = pd.DataFrame()\n",
        "    print(f\"⚠ Kaggle CSV not loaded: {e}\")\n",
        "\n",
        "if len(kaggle):\n",
        "    # Extract video_id from URLs if needed\n",
        "    if \"video_id\" not in kaggle.columns:\n",
        "        url_col = None\n",
        "        for c in [\"Url_youtube\",\"url_youtube\",\"youtube_url\",\"yt_url\",\"url\"]:\n",
        "            if c in kaggle.columns:\n",
        "                url_col = c; break\n",
        "        if url_col:\n",
        "            kaggle[\"video_id\"] = kaggle[url_col].apply(extract_video_id)\n",
        "        else:\n",
        "            kaggle[\"video_id\"] = None\n",
        "\n",
        "    kaggle[\"video_id_upper\"] = kaggle[\"video_id\"].astype(str).str.upper()\n",
        "    # Standardize counts\n",
        "    for tgt, alts in count_aliases.items():\n",
        "        if tgt not in kaggle.columns:\n",
        "            for a in alts:\n",
        "                if a in kaggle.columns:\n",
        "                    kaggle = kaggle.rename(columns={a: tgt})\n",
        "                    break\n",
        "    coerce_numeric(kaggle, [\"views\",\"likes\",\"comments\"])\n",
        "\n",
        "    keep_kag_cols = [\"video_id_upper\",\"views\",\"likes\",\"comments\",\"Artist\",\"Track\"]\n",
        "    keep_kag_cols = [c for c in keep_kag_cols if c in kaggle.columns]\n",
        "    ksub = kaggle[keep_kag_cols].drop_duplicates(\"video_id_upper\")\n",
        "\n",
        "    # Merge (left) & fill only where META is missing\n",
        "    master = master.merge(ksub, on=\"video_id_upper\", how=\"left\", suffixes=(\"\",\"_kag\"))\n",
        "    for tgt in [\"views\",\"likes\",\"comments\"]:\n",
        "        if f\"{tgt}_kag\" in master.columns:\n",
        "            master[tgt] = master[tgt].where(master[tgt].notna(), master[f\"{tgt}_kag\"])\n",
        "            master.drop(columns=[f\"{tgt}_kag\"], inplace=True, errors=\"ignore\")\n",
        "\n",
        "    # informational enrichment (non-essential)\n",
        "    if \"Artist\" in master.columns and \"artist\" in master.columns:\n",
        "        master[\"artist\"] = master[\"artist\"].where(master[\"artist\"].notna(), master[\"Artist\"])\n",
        "        master.drop(columns=[\"Artist\"], inplace=True, errors=\"ignore\")\n",
        "    if \"Track\" in master.columns and \"track\" in master.columns:\n",
        "        master[\"track\"] = master[\"track\"].where(master[\"track\"].notna(), master[\"Track\"])\n",
        "        master.drop(columns=[\"Track\"], inplace=True, errors=\"ignore\")\n",
        "\n",
        "# ---------- Provenance & coverage report ----------\n",
        "prov = {}\n",
        "for tgt in [\"views\",\"likes\",\"comments\"]:\n",
        "    src_meta = tgt in meta.columns\n",
        "    src_kag  = tgt in kaggle.columns if len(kaggle) else False\n",
        "    if src_meta and src_kag and f\"{tgt}_kag\" not in master.columns:\n",
        "        # we already filled; estimate by presence before fill\n",
        "        # build temporary booleans from available data\n",
        "        prov[f\"{tgt}_from_meta\"] = int((df_features.merge(meta[[\"video_id_upper\",tgt]], on=\"video_id_upper\", how=\"left\")[tgt].notna()).sum())\n",
        "        prov[f\"{tgt}_from_kaggle\"] = int((master[tgt].notna().sum()) - prov[f\"{tgt}_from_meta\"])\n",
        "    else:\n",
        "        prov[f\"{tgt}_from_meta\"]   = int(master[tgt].notna().sum()) if src_meta else 0\n",
        "        prov[f\"{tgt}_from_kaggle\"] = 0\n",
        "\n",
        "has_all = master[[\"views\",\"likes\",\"comments\"]].notna().all(axis=1)\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"COVERAGE SUMMARY\")\n",
        "print(\"-\"*70)\n",
        "print(f\"Total NPZ: {len(master):,}\")\n",
        "print(f\"With ALL targets (after enrichment): {has_all.sum():,} ({has_all.sum()/len(master)*100:.1f}%)\")\n",
        "for tgt in [\"views\",\"likes\",\"comments\"]:\n",
        "    present = master[tgt].notna().sum()\n",
        "    print(f\"  {tgt:<9}: {present:6,} present\")\n",
        "\n",
        "# ---------- Save outputs ----------\n",
        "# Full master (may include rows with missing targets)\n",
        "master.to_parquet(MASTER_OUT, index=False)\n",
        "# Training subset (must have all three)\n",
        "train_ready = master[has_all].copy()\n",
        "train_ready.to_parquet(TRAIN_OUT, index=False)\n",
        "# Also keep an explicit “enriched” copy (alias of MASTER_OUT for downstream cells)\n",
        "master.to_parquet(ENRICHED_OUT, index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FILES WRITTEN\")\n",
        "print(\"=\"*70)\n",
        "print(f\"MASTER : {MASTER_OUT}\")\n",
        "print(f\"TRAIN  : {TRAIN_OUT}\")\n",
        "print(f\"ENRICH : {ENRICHED_OUT}\")\n",
        "\n",
        "# ---------- Final summary ----------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FINAL DATASET SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Total NPZ files: {len(master):,}\")\n",
        "print(f\"Matched video_ids (any targets): {(master['video_id'].notna()).sum():,}\")\n",
        "print(f\"With all targets (views/likes/comments): {len(train_ready):,}\")\n",
        "print(f\"Coverage: {len(train_ready)/len(master)*100:.1f}%\")\n",
        "\n",
        "# Sample preview\n",
        "display_cols = ['video_id', 'feature_path', 'views', 'likes', 'comments', 'artist', 'track']\n",
        "print(\"\\nSAMPLE (first 10 rows with targets):\")\n",
        "print(train_ready[[c for c in display_cols if c in train_ready.columns]].head(10).to_string(index=False))\n",
        "print(\"\\n✅ DATASET READY FOR TRAINING\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2optzmczeqd",
        "outputId": "5f051eba-8ce0-4ffe-c643-37e4fefd02b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Using master_file: /content/models/run_01/META_master_4k.parquet\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================\n",
        "# Bootstrap: safely resolve config + master_file before target gen\n",
        "# ==============================================================\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Fallback default directory\n",
        "OUTPUT_DIR = Path(globals().get(\"OUTPUT_DIR\", \"/content/drive/MyDrive/STA 160/models/run_01\"))\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "config_file = OUTPUT_DIR / \"config.json\"\n",
        "\n",
        "# Load existing config or initialize new one\n",
        "if config_file.exists():\n",
        "    with open(config_file, \"r\") as f:\n",
        "        config = json.load(f)\n",
        "else:\n",
        "    config = {}\n",
        "\n",
        "# Try to find a master file\n",
        "master_file = config.get(\"master_file\", None)\n",
        "\n",
        "if master_file is None or not Path(master_file).exists():\n",
        "    candidates = [\n",
        "        \"/content/models/run_01/META_training_clean.parquet\",\n",
        "        \"/content/drive/MyDrive/STA 160/META_training_clean.parquet\",\n",
        "        \"/content/drive/MyDrive/META_clean_v2.parquet\",\n",
        "        \"/content/drive/MyDrive/STA 160/models/run_01/META_master.parquet\",\n",
        "    ]\n",
        "    master_file = next((p for p in candidates if Path(p).exists()), None)\n",
        "\n",
        "if master_file is None:\n",
        "    raise FileNotFoundError(\"Cannot locate master parquet. Place it in /content/drive/MyDrive/STA 160/.\")\n",
        "\n",
        "# Normalize to Path and save back to config\n",
        "master_file = str(Path(master_file))\n",
        "config[\"master_file\"] = master_file\n",
        "with open(config_file, \"w\") as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "\n",
        "print(f\"✓ Using master_file: {master_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2Lvi4fB4jAf",
        "outputId": "f5aee1b4-d5b9-4231-f427-5509939ac3bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded master: 1,598 rows, 18 columns\n",
            "Non-null counts: {'user_engagement_signal': np.int64(1598), 'platform_quality_signal': np.int64(1598), 'quality_final': np.int64(1598)}\n",
            "Rows with ≥1 target present: 1,598 / 1,598\n",
            "✓ Enriched master written to: /content/models/run_01/META_master_4k_enriched.parquet\n",
            "✓ Config updated with targets & new master_file\n"
          ]
        }
      ],
      "source": [
        "# ======================================================================\n",
        "# CELL 2.9: Target generation & verification (run this before Cell 3)\n",
        "# ======================================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# 1) Load the current master parquet (use the same 'master_file' you already resolved)\n",
        "_master_path = Path(config.get('master_file', master_file))\n",
        "assert _master_path.exists(), f\"Master file not found: {_master_path}\"\n",
        "master = pd.read_parquet(_master_path)\n",
        "print(f\"Loaded master: {len(master):,} rows, {master.columns.size} columns\")\n",
        "\n",
        "# 2) Utility helpers\n",
        "def safe_z(x):\n",
        "    x = pd.to_numeric(x, errors='coerce')\n",
        "    m = x.mean(skipna=True)\n",
        "    s = x.std(skipna=True)\n",
        "    if not np.isfinite(m): m = 0.0\n",
        "    if not np.isfinite(s) or s < 1e-6: s = 1.0\n",
        "    return (x - m) / s\n",
        "\n",
        "def nz(v, fill=0.0):\n",
        "    v = pd.to_numeric(v, errors='coerce')\n",
        "    return v.fillna(fill)\n",
        "\n",
        "def exists(col):\n",
        "    return col in master.columns\n",
        "\n",
        "# 3) Create common engineered columns (only if present → no KeyErrors)\n",
        "if exists('likes'):\n",
        "    master['likes_log'] = np.log1p(nz(master['likes']))\n",
        "if exists('views'):\n",
        "    master['views_log'] = np.log1p(nz(master['views']))\n",
        "if exists('comments'):\n",
        "    master['comments_log'] = np.log1p(nz(master['comments']))\n",
        "\n",
        "# Engagement rate proxy (robust to missing cols)\n",
        "likes = nz(master['likes']) if exists('likes') else 0.0\n",
        "comments = nz(master['comments']) if exists('comments') else 0.0\n",
        "views = nz(master['views']).replace(0, np.nan) if exists('views') else np.nan\n",
        "eng_rate = (likes + 0.5 * comments) / views\n",
        "master['engagement_rate'] = eng_rate.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# 4) Build TARGETS if missing (derivations are proxies; replace with your official formulas when available)\n",
        "need_user = 'user_engagement_signal' not in master.columns\n",
        "need_platform = 'platform_quality_signal' not in master.columns\n",
        "need_quality = 'quality_final' not in master.columns\n",
        "\n",
        "# user_engagement_signal: emphasize engagement metrics\n",
        "if need_user:\n",
        "    parts = []\n",
        "    if 'likes_log' in master: parts.append(safe_z(master['likes_log']))\n",
        "    if 'comments_log' in master: parts.append(safe_z(master['comments_log']))\n",
        "    if 'engagement_rate' in master: parts.append(safe_z(master['engagement_rate']))\n",
        "    if parts:\n",
        "        master['user_engagement_signal'] = np.nanmean(np.vstack(parts), axis=0)\n",
        "        print(\"Created user_engagement_signal from available components.\")\n",
        "    else:\n",
        "        master['user_engagement_signal'] = np.nan\n",
        "\n",
        "# platform_quality_signal: softer blend with scale exposure (views)\n",
        "if need_platform:\n",
        "    parts = []\n",
        "    if 'views_log' in master: parts.append(0.6 * safe_z(master['views_log']))\n",
        "    if 'engagement_rate' in master: parts.append(0.4 * safe_z(master['engagement_rate']))\n",
        "    if parts:\n",
        "        master['platform_quality_signal'] = np.nansum(np.vstack(parts), axis=0)\n",
        "        print(\"Created platform_quality_signal from available components.\")\n",
        "    else:\n",
        "        master['platform_quality_signal'] = np.nan\n",
        "\n",
        "# quality_final: balanced composite (tune weights as you like)\n",
        "if need_quality:\n",
        "    parts = []\n",
        "    if 'user_engagement_signal' in master: parts.append(0.5 * safe_z(master['user_engagement_signal']))\n",
        "    if 'platform_quality_signal' in master: parts.append(0.5 * safe_z(master['platform_quality_signal']))\n",
        "    # optional bonus: recency decay if you have days_since_publish\n",
        "    if exists('days_since_publish'):\n",
        "        # newer content gets small boost; cap effect to be gentle\n",
        "        dsp = pd.to_numeric(master['days_since_publish'], errors='coerce')\n",
        "        recency = -safe_z(np.log1p(dsp.clip(lower=0)))\n",
        "        parts.append(0.2 * recency)\n",
        "    if parts:\n",
        "        master['quality_final'] = np.nansum(np.vstack(parts), axis=0)\n",
        "        print(\"Created quality_final composite target.\")\n",
        "    else:\n",
        "        master['quality_final'] = np.nan\n",
        "\n",
        "# 5) Final cleaning: coerce to float32, drop rows with all-targets-missing\n",
        "TARGETS = ['user_engagement_signal', 'platform_quality_signal', 'quality_final']\n",
        "for t in TARGETS:\n",
        "    master[t] = pd.to_numeric(master[t], errors='coerce').astype('float32')\n",
        "\n",
        "non_null_counts = master[TARGETS].notna().sum()\n",
        "print(\"Non-null counts:\", dict(non_null_counts))\n",
        "\n",
        "# Keep rows that have at least one target (you can require 'all' if you prefer)\n",
        "mask_any = master[TARGETS].notna().any(axis=1)\n",
        "kept = int(mask_any.sum())\n",
        "print(f\"Rows with ≥1 target present: {kept:,} / {len(master):,}\")\n",
        "\n",
        "# Hard fail if everything is empty → prevents training on random weights\n",
        "if non_null_counts.max() == 0:\n",
        "    raise RuntimeError(\n",
        "        \"All requested targets are empty. Either run your official Preprocessing \"\n",
        "        \"to populate them or switch TARGETS to existing columns (e.g., likes_log/views_log).\"\n",
        "    )\n",
        "\n",
        "# 6) Persist the enriched master and update config\n",
        "enriched_path = _master_path.with_name(_master_path.stem + \"_enriched.parquet\")\n",
        "master.to_parquet(enriched_path, index=False)\n",
        "config['master_file'] = str(enriched_path)\n",
        "config['targets'] = TARGETS\n",
        "with open(config_file, 'w') as f:\n",
        "    import json; json.dump(config, f, indent=2)\n",
        "print(f\"✓ Enriched master written to: {enriched_path}\")\n",
        "print(\"✓ Config updated with targets & new master_file\")\n",
        "\n",
        "# 7) Hand-off to your existing Cell 3+:\n",
        "#    Downstream code should read config['master_file'] and config['targets'].\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYs49MSa0Aj6",
        "outputId": "b0389117-3848-4d24-ef02-90e9d4843eb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CELL 3: Build Master with Quality Signals (duration-aware)\n",
            "======================================================================\n",
            "\n",
            "[1/6] Loading configuration...\n",
            "\n",
            "[2/6] Loading feature list...\n",
            "✓ Loaded 4,000 features\n",
            "\n",
            "[3/6] Loading META.parquet...\n",
            "  Found: /content/aivideo-dataset/META.parquet\n",
            "✓ Loaded 9,578 rows\n",
            "✓ Found columns: ['views', 'likes', 'comments']\n",
            "\n",
            "[4/6] Matching features to metadata...\n",
            "✓ Matched 1,391 / 4,001 (34.8%)\n",
            "✓ After filtering: 1,376 rows\n",
            "\n",
            "[5/6] Computing quality signals...\n",
            "✓ Quality signals computed\n",
            "  Samples: 1,376\n",
            "  Signals: user_engagement, platform_quality, quality_final\n",
            "\n",
            "[6/6] Saving master metadata...\n",
            "\n",
            "======================================================================\n",
            "METADATA COMPLETE\n",
            "======================================================================\n",
            "Samples:  1,376\n",
            "Targets:  ['user_engagement_signal', 'platform_quality_signal', 'quality_final']\n",
            "Output:   /content/models/run_01/META_master_4k.parquet\n",
            "======================================================================\n",
            "\n",
            "Target statistics:\n",
            "  user_engagement_signal: mean=0.000  std=1.000  min=-1.730  max=1.730\n",
            "  platform_quality_signal: mean=-0.000  std=1.000  min=-3.695  max=1.802\n",
            "  quality_final: mean=0.000  std=1.000  min=-2.374  max=1.816\n",
            "\n",
            "✅ Cell 3 Complete\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "CELL 3: Build Master with Quality Signals (with duration-ID recovery)\n",
        "====================================================================\n",
        "\n",
        "- Load features from config['feature_list']\n",
        "- Recover video_id from filename; fill missing via /content/sha1_ALL_matched_final.csv\n",
        "- Join META by video_id (uppercased consistently)\n",
        "- Compute: user_engagement_signal, platform_quality_signal, quality_final\n",
        "\"\"\"\n",
        "\n",
        "import os, json, re, glob\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CELL 3: Build Master with Quality Signals (duration-aware)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ---------------- Config ----------------\n",
        "print(\"\\n[1/6] Loading configuration...\")\n",
        "OUTPUT_DIR = Path(\"/content/models/run_01\")\n",
        "with open(OUTPUT_DIR / \"config.json\", \"r\") as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "feature_list_file = Path(config[\"feature_list\"])\n",
        "ROOT_DIR = Path(config[\"ROOT_DIR\"])\n",
        "DURATION_MAP = Path(\"/content/sha1_ALL_matched_final.csv\")  # produced by your duration matching\n",
        "\n",
        "# ---------------- Features ----------------\n",
        "print(\"\\n[2/6] Loading feature list...\")\n",
        "with open(feature_list_file, \"r\") as f:\n",
        "    feature_paths = [line.strip() for line in f if line.strip()]\n",
        "df_features = pd.DataFrame({\"feature_path\": feature_paths})\n",
        "df_features[\"basename\"] = df_features[\"feature_path\"].map(lambda p: Path(p).name)\n",
        "df_features[\"filename\"] = df_features[\"basename\"]\n",
        "\n",
        "def is_ytid(s: str) -> bool:\n",
        "    s = str(s)\n",
        "    if len(s) != 11: return False\n",
        "    # allow A-Z/a-z/0-9/-/_\n",
        "    return all(ch.isalnum() or ch in \"-_\" for ch in s)\n",
        "\n",
        "# video_id from filename stem\n",
        "df_features[\"stem\"] = df_features[\"basename\"].str.replace(\".npz\", \"\", regex=False)\n",
        "df_features[\"video_id\"] = df_features[\"stem\"].where(df_features[\"stem\"].map(is_ytid))\n",
        "\n",
        "# fill via duration map for non-IDs (sha1_* or word-named)\n",
        "if DURATION_MAP.exists():\n",
        "    dur = pd.read_csv(DURATION_MAP)\n",
        "    # npz_basename -> video_id\n",
        "    if \"npz_basename\" in dur.columns and \"video_id\" in dur.columns:\n",
        "        dur = dur[[\"npz_basename\", \"video_id\"]].dropna()\n",
        "        dur[\"npz_basename\"] = dur[\"npz_basename\"].astype(str)\n",
        "        dur[\"video_id\"] = dur[\"video_id\"].astype(str)\n",
        "        df_features = df_features.merge(\n",
        "            dur.rename(columns={\"npz_basename\": \"basename\", \"video_id\": \"video_id_from_dur\"}),\n",
        "            on=\"basename\", how=\"left\"\n",
        "        )\n",
        "        df_features[\"video_id\"] = df_features[\"video_id\"].fillna(df_features[\"video_id_from_dur\"])\n",
        "        df_features.drop(columns=[\"video_id_from_dur\"], inplace=True, errors=\"ignore\")\n",
        "\n",
        "print(f\"✓ Loaded {len(df_features):,} features\")\n",
        "\n",
        "# ---------------- META ----------------\n",
        "print(\"\\n[3/6] Loading META.parquet...\")\n",
        "meta_candidates = [\n",
        "    ROOT_DIR / \"META.parquet\",\n",
        "    Path(\"/content/aivideo-dataset/META.parquet\"),\n",
        "    Path(\"/content/drive/MyDrive/STA 160/dataset/META.parquet\"),\n",
        "]\n",
        "meta_path = next((p for p in meta_candidates if p.exists()), None)\n",
        "if meta_path is None:\n",
        "    found = glob.glob(str(ROOT_DIR / \"**\" / \"META*.parquet\"), recursive=True)\n",
        "    meta_path = Path(found[0]) if found else None\n",
        "if meta_path is None:\n",
        "    raise FileNotFoundError(\"META.parquet not found\")\n",
        "\n",
        "print(\"  Found:\", meta_path)\n",
        "meta = pd.read_parquet(meta_path)\n",
        "print(f\"✓ Loaded {len(meta):,} rows\")\n",
        "\n",
        "# Normalize video_id column\n",
        "if \"video_id\" not in meta.columns:\n",
        "    for alt in [\"id\", \"videoId\", \"yt_video_id\", \"youtube_id\"]:\n",
        "        if alt in meta.columns:\n",
        "            meta = meta.rename(columns={alt: \"video_id\"})\n",
        "            print(f\"  Using '{alt}' as video_id\")\n",
        "            break\n",
        "\n",
        "# Standardize casing for JOIN ONLY\n",
        "meta[\"video_id_upper\"] = meta[\"video_id\"].astype(str).str.upper()\n",
        "df_features[\"video_id_upper\"] = df_features[\"video_id\"].astype(str).str.upper()\n",
        "\n",
        "# Normalize raw count column names and numeric types\n",
        "alias_map = {\n",
        "    \"views\":     [\"views\", \"view_count\", \"yt_views\", \"Views\"],\n",
        "    \"likes\":     [\"likes\", \"like_count\", \"yt_likes\", \"Likes\"],\n",
        "    \"comments\":  [\"comments\", \"comment_count\", \"yt_comments\", \"Comments\"],\n",
        "}\n",
        "for std, alts in alias_map.items():\n",
        "    if std not in meta.columns:\n",
        "        for c in alts:\n",
        "            if c in meta.columns:\n",
        "                meta = meta.rename(columns={c: std})\n",
        "                break\n",
        "for c in [\"views\", \"likes\", \"comments\"]:\n",
        "    if c in meta.columns:\n",
        "        meta[c] = pd.to_numeric(meta[c], errors=\"coerce\")\n",
        "\n",
        "print(\"✓ Found columns:\",\n",
        "      [c for c in [\"views\",\"likes\",\"comments\"] if c in meta.columns])\n",
        "\n",
        "# ---------------- Match ----------------\n",
        "print(\"\\n[4/6] Matching features to metadata...\")\n",
        "\n",
        "keep_cols = [\"video_id\", \"views\", \"likes\", \"comments\"]\n",
        "for opt in [\"channel\", \"yt_channel\", \"published_date\"]:\n",
        "    if opt in meta.columns:\n",
        "        keep_cols.append(opt)\n",
        "\n",
        "# join using *_upper, but keep original meta['video_id']\n",
        "meta_join = meta[[\"video_id_upper\"] + [c for c in keep_cols if c != \"video_id\"]].copy()\n",
        "df = df_features.merge(meta_join, on=\"video_id_upper\", how=\"left\")\n",
        "\n",
        "matched = int(df[\"views\"].notna().sum()) if \"views\" in df.columns else 0\n",
        "print(f\"✓ Matched {matched:,} / {len(df):,} ({matched/len(df)*100:.1f}%)\")\n",
        "\n",
        "# require all three counts\n",
        "have_all = all(c in df.columns for c in [\"views\",\"likes\",\"comments\"])\n",
        "master = df.dropna(subset=[\"views\",\"likes\",\"comments\"], how=\"any\").reset_index(drop=True) if have_all else df.copy()\n",
        "print(f\"✓ After filtering: {len(master):,} rows\")\n",
        "\n",
        "if len(master) < 100:\n",
        "    print(\"⚠️  Low match count; check that duration map and META align.\")\n",
        "\n",
        "# ---------------- Quality signals ----------------\n",
        "print(\"\\n[5/6] Computing quality signals...\")\n",
        "\n",
        "# safe helpers\n",
        "def nz(a, fill=0.0):\n",
        "    return pd.to_numeric(a, errors=\"coerce\").fillna(fill)\n",
        "\n",
        "master[\"views_log\"] = np.log1p(nz(master.get(\"views\", 0)))\n",
        "# Channel key\n",
        "if \"channel\" in master.columns and master[\"channel\"].notna().any():\n",
        "    ch_key = \"channel\"\n",
        "elif \"yt_channel\" in master.columns and master[\"yt_channel\"].notna().any():\n",
        "    ch_key = \"yt_channel\"\n",
        "else:\n",
        "    master[\"_channel\"] = \"all\"\n",
        "    ch_key = \"_channel\"\n",
        "\n",
        "# Week key\n",
        "if \"published_date\" in master.columns:\n",
        "    master[\"_week\"] = pd.to_datetime(master[\"published_date\"], errors=\"coerce\").dt.to_period(\"W\").astype(str)\n",
        "else:\n",
        "    master[\"_week\"] = \"all\"\n",
        "\n",
        "# engagement rate (Laplace)\n",
        "k_prior = 4.0\n",
        "likes_rate    = (nz(master[\"likes\"])    + 1.0) / (nz(master[\"views\"]) + k_prior)\n",
        "comments_rate = (nz(master[\"comments\"]) + 1.0) / (nz(master[\"views\"]) + k_prior)\n",
        "master[\"engagement_rate\"] = 0.8 * likes_rate + 0.2 * comments_rate\n",
        "\n",
        "# rank by week\n",
        "eng_rank = master.groupby(\"_week\")[\"engagement_rate\"].rank(pct=True)\n",
        "\n",
        "# channel-standardize\n",
        "er_mu = eng_rank.groupby(master[ch_key]).transform(\"mean\")\n",
        "er_sd = eng_rank.groupby(master[ch_key]).transform(\"std\").replace(0, 1)\n",
        "user_eng = (eng_rank - er_mu) / er_sd\n",
        "user_eng = user_eng.fillna(0)\n",
        "\n",
        "# platform quality\n",
        "ch_mu = master.groupby(ch_key)[\"views_log\"].transform(\"mean\")\n",
        "ch_sd = master.groupby(ch_key)[\"views_log\"].transform(\"std\").replace(0, 1)\n",
        "z_ch  = (master[\"views_log\"] - ch_mu) / ch_sd\n",
        "\n",
        "wk_mu = master.groupby(\"_week\")[\"views_log\"].transform(\"mean\")\n",
        "res   = master[\"views_log\"] - wk_mu\n",
        "rw_mu = res.groupby(master[ch_key]).transform(\"mean\")\n",
        "rw_sd = res.groupby(master[ch_key]).transform(\"std\").replace(0, 1)\n",
        "plat_qual = (res - rw_mu) / rw_sd\n",
        "plat_qual = plat_qual.fillna(z_ch)\n",
        "\n",
        "# blend + winsorize + standardize\n",
        "qual_final = 0.6 * plat_qual + 0.4 * user_eng\n",
        "lo, hi = qual_final.quantile([0.01, 0.99])\n",
        "qual_final = qual_final.clip(lo, hi)\n",
        "\n",
        "def standardize(x: pd.Series) -> pd.Series:\n",
        "    m, s = x.mean(), x.std()\n",
        "    return (x - m) / (s if s > 0 else 1)\n",
        "\n",
        "master[\"user_engagement_signal\"]  = standardize(user_eng).astype(\"float32\")\n",
        "master[\"platform_quality_signal\"] = standardize(plat_qual).astype(\"float32\")\n",
        "master[\"quality_final\"]           = standardize(qual_final).astype(\"float32\")\n",
        "\n",
        "# clean temp cols\n",
        "for col in [\"_channel\", \"_week\", \"views_log\", \"engagement_rate\"]:\n",
        "    if col in master.columns:\n",
        "        master.drop(columns=[col], inplace=True)\n",
        "\n",
        "print(\"✓ Quality signals computed\")\n",
        "print(f\"  Samples: {len(master):,}\")\n",
        "print(\"  Signals: user_engagement, platform_quality, quality_final\")\n",
        "\n",
        "# ---------------- Save ----------------\n",
        "print(\"\\n[6/6] Saving master metadata...\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "output_file = OUTPUT_DIR / \"META_master_4k.parquet\"\n",
        "master.to_parquet(output_file, index=False)\n",
        "\n",
        "TARGETS = [\"user_engagement_signal\", \"platform_quality_signal\", \"quality_final\"]\n",
        "config[\"master_file\"]  = str(output_file)\n",
        "config[\"master_rows\"]  = int(len(master))\n",
        "config[\"targets\"]      = TARGETS\n",
        "\n",
        "with open(OUTPUT_DIR / \"config.json\", \"w\") as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"METADATA COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Samples:  {len(master):,}\")\n",
        "print(f\"Targets:  {TARGETS}\")\n",
        "print(f\"Output:   {output_file}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nTarget statistics:\")\n",
        "for t in TARGETS:\n",
        "    s = master[t]\n",
        "    print(f\"  {t}: mean={s.mean():.3f}  std={s.std():.3f}  min={s.min():.3f}  max={s.max():.3f}\")\n",
        "print(\"\\n✅ Cell 3 Complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ4pt9hMHeR9",
        "outputId": "9b7a2023-3edd-4dee-bdd1-a683cd1cf178"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CELL 3.5b: Tight tolerance (±0.5s) & in-place enrichment\n",
            "======================================================================\n",
            "Loaded master: 9,578 rows\n",
            "SHA1 with duration: 5,866\n",
            "Matched: 5,740  (diff<0.5s: 5,740)\n",
            "\n",
            "======================================================================\n",
            "ENRICHMENT (±0.5s) COMPLETE\n",
            "======================================================================\n",
            "Master rows (before): 9,578\n",
            "Master rows (after) : 9,578\n",
            "Filled targets now  : 8,965 with all three\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CELL 3.5b — Tight tolerance (±0.5s) + IN-PLACE ENRICHMENT\n",
        "# Re-run duration matching, then FILL missing targets in master.\n",
        "# Only append rows if the feature_path isn't already in master.\n",
        "# ============================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "import re, glob\n",
        "\n",
        "FEATURE_DIR = Path(\"/content/aivideo-dataset/features_logmel_sr16k_v1\")\n",
        "KAGGLE_CSV  = Path(\"/content/drive/My Drive/STA 160/Spotify Youtube Dataset.csv\")\n",
        "OUTDIR      = Path(\"/content/models/run_01\")\n",
        "MASTER_PATH = OUTDIR / \"META_final_clean.parquet\"\n",
        "TRAIN_OUT   = OUTDIR / \"META_training_ready.parquet\"\n",
        "\n",
        "TOLERANCE_SEC = 0.5  # ← tighten window\n",
        "\n",
        "def extract_video_id(url):\n",
        "    if pd.isna(url): return None\n",
        "    try:\n",
        "        url = str(url)\n",
        "        if \"youtube.com/watch\" in url:\n",
        "            q = parse_qs(urlparse(url).query); return q.get(\"v\", [None])[0]\n",
        "        if \"youtu.be/\" in url:\n",
        "            return url.split(\"youtu.be/\")[-1].split(\"?\")[0]\n",
        "        m = re.search(r\"[?&]v=([^&]+)\", url)\n",
        "        if m: return m.group(1)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "def find_col(df, candidates):\n",
        "    for c in candidates:\n",
        "        if c in df.columns: return c\n",
        "    return None\n",
        "\n",
        "def coerce_numeric(df, cols):\n",
        "    for c in cols:\n",
        "        if c in df.columns:\n",
        "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CELL 3.5b: Tight tolerance (±0.5s) & in-place enrichment\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# --- Load master\n",
        "master = pd.read_parquet(MASTER_PATH)\n",
        "already_paths = set(master.get(\"feature_path\", pd.Series(dtype=str)).astype(str))\n",
        "print(f\"Loaded master: {len(master):,} rows\")\n",
        "\n",
        "# --- Gather sha1 files & their durations\n",
        "sha1_files = sorted(glob.glob(str(FEATURE_DIR / \"sha1_*.npz\")))\n",
        "rows = []\n",
        "for i, fpath in enumerate(sha1_files):\n",
        "    try:\n",
        "        with np.load(fpath, allow_pickle=True) as data:\n",
        "            dur = float(data[\"duration_sec\"]) if \"duration_sec\" in data else np.nan\n",
        "        rows.append({\"feature_path\": fpath, \"npz_basename\": Path(fpath).name,\n",
        "                     \"duration_sec_npz\": dur})\n",
        "    except Exception:\n",
        "        pass\n",
        "df_npz = pd.DataFrame(rows).dropna(subset=[\"duration_sec_npz\"])\n",
        "print(f\"SHA1 with duration: {len(df_npz):,}\")\n",
        "\n",
        "# --- Load Kaggle & normalize columns\n",
        "kaggle = pd.read_csv(KAGGLE_CSV)\n",
        "dur_col  = find_col(kaggle, [\"Duration_ms\",\"duration_ms\",\"duration_sec\",\"Duration_sec\"])\n",
        "if dur_col is None:\n",
        "    raise RuntimeError(\"Need Duration_ms or duration_sec in Kaggle CSV\")\n",
        "kaggle[\"duration_sec\"] = (kaggle[dur_col] / 1000.0) if dur_col.lower().endswith(\"_ms\") \\\n",
        "                         else pd.to_numeric(kaggle[dur_col], errors=\"coerce\")\n",
        "\n",
        "url_col = find_col(kaggle, [\"Url_youtube\",\"url_youtube\",\"YouTube URL\",\"youtube_url\",\"yt_url\",\"url\"])\n",
        "if url_col is None:\n",
        "    raise RuntimeError(\"Need a YouTube URL column in Kaggle CSV (e.g., Url_youtube)\")\n",
        "kaggle[\"video_id_upper\"] = kaggle[url_col].apply(extract_video_id)\n",
        "kaggle[\"video_id_upper\"] = kaggle[\"video_id_upper\"].astype(str).str.upper()\n",
        "\n",
        "views_col    = find_col(kaggle, [\"Views\",\"views\",\"view_count\",\"View Count\",\"yt_views\"])\n",
        "likes_col    = find_col(kaggle, [\"Likes\",\"likes\",\"like_count\",\"Like Count\",\"yt_likes\"])\n",
        "comments_col = find_col(kaggle, [\"Comments\",\"comments\",\"comment_count\",\"Comment Count\",\"yt_comments\"])\n",
        "artist_col   = find_col(kaggle, [\"Artist\",\"artist\",\"ArtistName\",\"artist_name\"])\n",
        "track_col    = find_col(kaggle, [\"Track\",\"track\",\"Title\",\"title\",\"song\",\"Song\"])\n",
        "\n",
        "keep = [\"video_id_upper\",\"duration_sec\"]\n",
        "for c in [views_col, likes_col, comments_col, artist_col, track_col]:\n",
        "    if c: keep.append(c)\n",
        "kg = kaggle[keep].dropna(subset=[\"video_id_upper\",\"duration_sec\"]).drop_duplicates(subset=[\"video_id_upper\"]).copy()\n",
        "kg = kg.rename(columns={views_col:\"views\", likes_col:\"likes\", comments_col:\"comments\",\n",
        "                        artist_col:\"Artist\", track_col:\"Track\"} if views_col or likes_col or comments_col else {})\n",
        "coerce_numeric(kg, [\"views\",\"likes\",\"comments\"])\n",
        "\n",
        "# --- Duration match with tight window\n",
        "npz = df_npz.copy(); npz[\"bin\"] = npz[\"duration_sec_npz\"].round().astype(int)\n",
        "kg2 = kg.copy();     kg2[\"bin\"] = kg2[\"duration_sec\"].round().astype(int)\n",
        "\n",
        "cand = npz.merge(kg2, on=\"bin\", how=\"inner\", suffixes=(\"\",\"_k\"))\n",
        "cand = cand[(cand[\"duration_sec\"].sub(cand[\"duration_sec_npz\"]).abs() <= TOLERANCE_SEC)].copy()\n",
        "if cand.empty:\n",
        "    print(\"No candidates within ±0.5s.\"); raise SystemExit\n",
        "\n",
        "cand[\"abs_diff\"] = (cand[\"duration_sec\"] - cand[\"duration_sec_npz\"]).abs()\n",
        "cand = cand.sort_values([\"feature_path\",\"abs_diff\"])\n",
        "best = cand.drop_duplicates(subset=[\"feature_path\"], keep=\"first\").copy()\n",
        "\n",
        "print(f\"Matched: {len(best):,}  (diff<0.5s: {(best['abs_diff'] < 0.5).sum():,})\")\n",
        "\n",
        "# --- Build fill/append frames\n",
        "fill_cols = [\"views\",\"likes\",\"comments\",\"Artist\",\"Track\"]\n",
        "for c in fill_cols:\n",
        "    if c not in best.columns:\n",
        "        best[c] = np.nan\n",
        "\n",
        "best = best.rename(columns={\"video_id_upper\":\"video_id\"})\n",
        "best[\"video_id\"] = best[\"video_id\"].astype(str).str.upper()\n",
        "\n",
        "# Update existing rows’ missing targets by feature_path\n",
        "m = master.merge(best[[\"feature_path\",\"video_id\"] + fill_cols],\n",
        "                 on=\"feature_path\", how=\"left\", suffixes=(\"\",\"_kag\"))\n",
        "# only fill if original is NA\n",
        "for tgt in [\"views\",\"likes\",\"comments\"]:\n",
        "    if tgt in m.columns and f\"{tgt}_kag\" in m.columns:\n",
        "        m[tgt] = m[tgt].fillna(m[f\"{tgt}_kag\"])\n",
        "\n",
        "# Fill optional metadata\n",
        "for opt in [\"Artist\",\"Track\"]:\n",
        "    if opt in m.columns and f\"{opt}_kag\" in m.columns:\n",
        "        m[opt] = m[opt].fillna(m[f\"{opt}_kag\"])\n",
        "\n",
        "# Clean helper cols\n",
        "drop_helper = [c for c in m.columns if c.endswith(\"_kag\")]\n",
        "m.drop(columns=drop_helper, inplace=True)\n",
        "\n",
        "# Append only those matched features not already in master\n",
        "to_append = best[~best[\"feature_path\"].isin(already_paths)].copy()\n",
        "append_cols = [c for c in m.columns if c in to_append.columns]\n",
        "m_final = pd.concat([m, to_append[append_cols]], ignore_index=True)\n",
        "\n",
        "# Save\n",
        "m_final.to_parquet(MASTER_PATH, index=False)\n",
        "has_all = m_final[[\"views\",\"likes\",\"comments\"]].notna().all(axis=1) \\\n",
        "          if all(c in m_final.columns for c in [\"views\",\"likes\",\"comments\"]) else pd.Series(False, index=m_final.index)\n",
        "m_final.loc[has_all].to_parquet(TRAIN_OUT, index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ENRICHMENT (±0.5s) COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Master rows (before): {len(master):,}\")\n",
        "print(f\"Master rows (after) : {len(m_final):,}\")\n",
        "print(f\"Filled targets now  : {has_all.sum():,} with all three\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3KB0OR87VJJ",
        "outputId": "c3cdf57d-7217-420c-bdba-58c200d7affe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== HYBRID 3.9 ===\n",
            "strict rows   : 1,376 (META_master_4k.parquet)\n",
            "enriched rows : 9,578 (META_final_clean.parquet)\n",
            "union rows (pre-file-check): 9,565\n",
            "rows after file-exists check: 9,565\n",
            "\n",
            "=== OUTPUT ===\n",
            "Final master : /content/models/run_01/META_master_postenrich.parquet  (rows=9,565)\n",
            "Training set : /content/models/run_01/META_training_ready.parquet      (rows=8,965)\n",
            "\n",
            "VIEWS: count=8,965  mean=94,252,260.65  std=275,194,939.90  min=26.00  max=5,773,797,147.00\n",
            "\n",
            "LIKES: count=8,965  mean=689,817.86  std=1,767,627.86  min=0.00  max=40,147,618.00\n",
            "\n",
            "COMMENTS: count=8,965  mean=28,585.15  std=126,413.90  min=0.00  max=5,331,537.00\n",
            "\n",
            "✅ Hybrid 3.9 complete.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# HYBRID 3.9 → Union strict (Cell 3) with enriched (3.5b), enforce file-exists,\n",
        "#               coalesce targets, compute signals, finalize & make train split.\n",
        "# ==============================================================================\n",
        "\n",
        "import os, json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "OUTDIR = Path(\"/content/models/run_01\")\n",
        "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Inputs (adjust names if yours differ)\n",
        "STRICT_MASTER    = OUTDIR / \"META_master_4k.parquet\"        # from Cell 3 (feature-strict)\n",
        "ENRICHED_MASTER  = OUTDIR / \"META_final_clean.parquet\"      # from Cell 3.5b (duration/Kaggle)\n",
        "META_PATH        = Path(\"/content/aivideo-dataset/META.parquet\")\n",
        "\n",
        "# Outputs\n",
        "FINAL_MASTER     = OUTDIR / \"META_master_postenrich.parquet\"\n",
        "TRAIN_OUT        = OUTDIR / \"META_training_ready.parquet\"\n",
        "STATS_OUT        = OUTDIR / \"target_statistics.json\"\n",
        "\n",
        "# ---- load config\n",
        "with open(OUTDIR / \"config.json\", \"r\") as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "def _load_df(p: Path) -> pd.DataFrame:\n",
        "    if p.exists():\n",
        "        df = pd.read_parquet(p)\n",
        "        # normalize key columns if present\n",
        "        if \"video_id\" in df.columns:\n",
        "            df[\"video_id\"] = df[\"video_id\"].astype(str).str.upper()\n",
        "        if \"feature_path\" in df.columns:\n",
        "            df[\"feature_path\"] = df[\"feature_path\"].astype(str)\n",
        "        # ensure numeric for targets (if present)\n",
        "        for c in [\"views\",\"likes\",\"comments\"]:\n",
        "            if c in df.columns:\n",
        "                df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "        return df\n",
        "    return pd.DataFrame()\n",
        "\n",
        "# ---- 1) Load both masters\n",
        "strict   = _load_df(STRICT_MASTER)\n",
        "enriched = _load_df(ENRICHED_MASTER)\n",
        "\n",
        "print(\"=== HYBRID 3.9 ===\")\n",
        "print(f\"strict rows   : {len(strict):,} ({STRICT_MASTER.name})\")\n",
        "print(f\"enriched rows : {len(enriched):,} ({ENRICHED_MASTER.name})\")\n",
        "\n",
        "if strict.empty and enriched.empty:\n",
        "    raise RuntimeError(\"No inputs to merge. Make sure Cell 3 and/or 3.5b ran.\")\n",
        "\n",
        "# ---- 2) Minimal column set we care about\n",
        "base_cols = [\"feature_path\",\"video_id\",\"views\",\"likes\",\"comments\"]\n",
        "extra_cols = [c for c in [\"artist\",\"track\",\"title\",\"channel\",\"yt_channel\",\"published_date\"]\n",
        "              if (c in strict.columns) or (c in enriched.columns)]\n",
        "want_cols = base_cols + extra_cols\n",
        "\n",
        "strict   = strict.reindex(columns=sorted(set(strict.columns)   | set(want_cols)))\n",
        "enriched = enriched.reindex(columns=sorted(set(enriched.columns) | set(want_cols)))\n",
        "\n",
        "# ---- 3) Union on feature_path, preferring enriched values when present\n",
        "# concat then drop_duplicates keeps the FIRST; so put enriched first\n",
        "both = pd.concat([enriched, strict], ignore_index=True, sort=False)\n",
        "\n",
        "# keep first by feature_path (enriched has precedence)\n",
        "if \"feature_path\" not in both.columns:\n",
        "    raise RuntimeError(\"Missing 'feature_path' after union.\")\n",
        "both = both.dropna(subset=[\"feature_path\"])\n",
        "both = both.drop_duplicates(subset=[\"feature_path\"], keep=\"first\").copy()\n",
        "\n",
        "# coerce types again\n",
        "if \"video_id\" in both.columns:\n",
        "    both[\"video_id\"] = both[\"video_id\"].astype(str).str.upper()\n",
        "for c in [\"views\",\"likes\",\"comments\"]:\n",
        "    if c in both.columns:\n",
        "        both[c] = pd.to_numeric(both[c], errors=\"coerce\")\n",
        "\n",
        "print(f\"union rows (pre-file-check): {len(both):,}\")\n",
        "\n",
        "# ---- 4) Enforce feature file exists\n",
        "exists_mask = both[\"feature_path\"].map(os.path.exists)\n",
        "missing = int((~exists_mask).sum())\n",
        "if missing > 0:\n",
        "    print(f\"• dropping {missing:,} rows (feature_path not found on disk)\")\n",
        "both = both[exists_mask].copy()\n",
        "print(f\"rows after file-exists check: {len(both):,}\")\n",
        "\n",
        "# ---- 5) Bring descriptive extras from META (left merge; no row adds)\n",
        "if META_PATH.exists():\n",
        "    meta = pd.read_parquet(META_PATH)\n",
        "    if \"video_id\" not in meta.columns and \"id\" in meta.columns:\n",
        "        meta = meta.rename(columns={\"id\":\"video_id\"})\n",
        "    meta[\"video_id\"] = meta[\"video_id\"].astype(str).str.upper()\n",
        "\n",
        "    keep_extra = [c for c in [\"artist\",\"track\",\"title\",\"channel\",\"yt_channel\",\"published_date\"]\n",
        "                  if c in meta.columns]\n",
        "    if keep_extra:\n",
        "        meta_extra = meta[[\"video_id\"] + keep_extra].drop_duplicates(\"video_id\")\n",
        "        merged = both.merge(meta_extra, on=\"video_id\", how=\"left\", suffixes=(\"\",\"_meta\"))\n",
        "        # coalesce extras\n",
        "        for c in keep_extra:\n",
        "            cm = f\"{c}_meta\"\n",
        "            if c in merged.columns and cm in merged.columns:\n",
        "                merged[c] = merged[c].where(merged[c].notna(), merged[cm])\n",
        "                merged.drop(columns=[cm], inplace=True)\n",
        "        both = merged\n",
        "\n",
        "# ---- 6) Compute simple quality signals (optional; doesn’t gate training)\n",
        "v = pd.to_numeric(both.get(\"views\"), errors=\"coerce\")\n",
        "l = pd.to_numeric(both.get(\"likes\"), errors=\"coerce\")\n",
        "c = pd.to_numeric(both.get(\"comments\"), errors=\"coerce\")\n",
        "\n",
        "views_log = np.log1p(v.fillna(0))\n",
        "eng_rate  = 0.8 * (l.fillna(0) + 1) / (v.fillna(0) + 4.0) + 0.2 * (c.fillna(0) + 1) / (v.fillna(0) + 4.0)\n",
        "\n",
        "def zscore(x):\n",
        "    x = pd.to_numeric(x, errors=\"coerce\")\n",
        "    finite = x[np.isfinite(x)]\n",
        "    mu, sd = finite.mean(), finite.std()\n",
        "    if not np.isfinite(sd) or sd < 1e-6: sd = 1.0\n",
        "    return (x - mu) / sd\n",
        "\n",
        "both[\"platform_quality_signal\"] = zscore(views_log).astype(\"float32\")\n",
        "both[\"user_engagement_signal\"]  = zscore(eng_rate).astype(\"float32\")\n",
        "both[\"quality_final\"]           = (0.6*both[\"platform_quality_signal\"] +\n",
        "                                   0.4*both[\"user_engagement_signal\"]).astype(\"float32\")\n",
        "\n",
        "# ---- 7) Save final master + training subset (require the 3 raw counts)\n",
        "both.to_parquet(FINAL_MASTER, index=False)\n",
        "TARGETS = [\"views\",\"likes\",\"comments\"]\n",
        "has_all = both[TARGETS].notna().all(axis=1)\n",
        "train = both.loc[has_all].copy()\n",
        "train.to_parquet(TRAIN_OUT, index=False)\n",
        "\n",
        "print(\"\\n=== OUTPUT ===\")\n",
        "print(f\"Final master : {FINAL_MASTER}  (rows={len(both):,})\")\n",
        "print(f\"Training set : {TRAIN_OUT}      (rows={len(train):,})\")\n",
        "\n",
        "# ---- 8) Stats (counts only)\n",
        "stats = {}\n",
        "for t in TARGETS:\n",
        "    arr = pd.to_numeric(train[t], errors=\"coerce\").to_numpy()\n",
        "    stats[t] = {\n",
        "        \"count\": int(np.isfinite(arr).sum()),\n",
        "        \"mean\" : float(np.nanmean(arr)),\n",
        "        \"std\"  : float(np.nanstd(arr) or 1.0),\n",
        "        \"min\"  : float(np.nanmin(arr)),\n",
        "        \"max\"  : float(np.nanmax(arr)),\n",
        "    }\n",
        "    print(f\"\\n{t.upper()}: count={stats[t]['count']:,}  \"\n",
        "          f\"mean={stats[t]['mean']:,.2f}  std={stats[t]['std']:,.2f}  \"\n",
        "          f\"min={stats[t]['min']:,.2f}  max={stats[t]['max']:,.2f}\")\n",
        "\n",
        "with open(STATS_OUT, \"w\") as f:\n",
        "    json.dump(stats, f, indent=2)\n",
        "\n",
        "# keep config simple and stable\n",
        "config[\"master_file\"] = str(FINAL_MASTER)\n",
        "config[\"training_file\"] = str(TRAIN_OUT)\n",
        "config[\"targets\"] = TARGETS\n",
        "config[\"final_samples\"] = int(len(train))\n",
        "with open(OUTDIR / \"config.json\", \"w\") as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "\n",
        "print(\"\\n✅ Hybrid 3.9 complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyqIX-lQpxYY",
        "outputId": "00028388-76ca-425c-84a4-67fc7aaf4af6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CELL 4: Verify Data Quality\n",
            "======================================================================\n",
            "✓ Loaded 9,565 samples\n",
            "✓ Samples with all targets: 8,965\n",
            "\n",
            "Target Statistics:\n",
            "======================================================================\n",
            "\n",
            "VIEWS:\n",
            "  Mean: 94,252,260.65\n",
            "  Std:  275,194,939.90\n",
            "  Min:  26.00\n",
            "  Max:  5,773,797,147.00\n",
            "\n",
            "LIKES:\n",
            "  Mean: 689,817.86\n",
            "  Std:  1,767,627.86\n",
            "  Min:  0.00\n",
            "  Max:  40,147,618.00\n",
            "\n",
            "COMMENTS:\n",
            "  Mean: 28,585.15\n",
            "  Std:  126,413.90\n",
            "  Min:  0.00\n",
            "  Max:  5,331,537.00\n",
            "\n",
            "✅ Cell 4 Complete\n",
            "Statistics saved: /content/models/run_01/target_statistics.json\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# CELL 4: Verify Data Quality (1 minute)\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CELL 4: Verify Data Quality\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load config and master\n",
        "with open(OUTPUT_DIR / \"config.json\", 'r') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "master = pd.read_parquet(config['master_file'])\n",
        "TARGETS = config['targets']\n",
        "\n",
        "print(f\"✓ Loaded {len(master):,} samples\")\n",
        "\n",
        "# Check missing values\n",
        "master = master.dropna(subset=TARGETS, how='any').reset_index(drop=True)\n",
        "print(f\"✓ Samples with all targets: {len(master):,}\")\n",
        "\n",
        "# Compute target statistics\n",
        "print(\"\\nTarget Statistics:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "target_stats = {}\n",
        "for target in TARGETS:\n",
        "    values = master[target].values\n",
        "    stats = {\n",
        "        'mean': float(np.mean(values)),\n",
        "        'std': float(np.std(values)),\n",
        "        'min': float(np.min(values)),\n",
        "        'max': float(np.max(values))\n",
        "    }\n",
        "    if stats['std'] < 1e-8:\n",
        "        stats['std'] = 1.0\n",
        "\n",
        "    target_stats[target] = stats\n",
        "\n",
        "    print(f\"\\n{target.upper()}:\")\n",
        "    print(f\"  Mean: {stats['mean']:,.2f}\")\n",
        "    print(f\"  Std:  {stats['std']:,.2f}\")\n",
        "    print(f\"  Min:  {stats['min']:,.2f}\")\n",
        "    print(f\"  Max:  {stats['max']:,.2f}\")\n",
        "\n",
        "# Save statistics\n",
        "stats_file = OUTPUT_DIR / \"target_statistics.json\"\n",
        "with open(stats_file, 'w') as f:\n",
        "    json.dump(target_stats, f, indent=2)\n",
        "\n",
        "config['target_stats'] = target_stats\n",
        "config['final_samples'] = len(master)\n",
        "with open(OUTPUT_DIR / \"config.json\", 'w') as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "\n",
        "print(f\"\\n✅ Cell 4 Complete\")\n",
        "print(f\"Statistics saved: {stats_file}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaVCw9gxNAa5",
        "outputId": "f33f51bc-bd4a-4be4-fda8-83bbffe26550"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "TRAINING FILTER SUMMARY\n",
            "======================================================================\n",
            "Master rows:           9,565\n",
            "Feature file exists:   9,565/9,565\n",
            "Rejected rows total:   600\n",
            "Top rejection reasons:\n",
            "comments_missing      583\n",
            "comments_nonfinite    583\n",
            "likes_missing         529\n",
            "likes_nonfinite       529\n",
            "views_below_min       462\n",
            "views_missing         462\n",
            "views_nonfinite       462\n",
            "dtype: int64\n",
            "\n",
            "Kept (pre-dedupe):     8,965\n",
            "Kept (post-dedupe):    8,965\n",
            "Rows with ALL targets: 8,965/8,965\n",
            "\n",
            "Target stats on final training set:\n",
            "  views: count=8,965, min=26, p50=3635478, p90=281131541, max=5773797147\n",
            "  likes: count=8,965, min=0, p50=36177, p90=2188757, max=40147618\n",
            "  comments: count=8,965, min=0, p50=733, p90=67730, max=5331537\n",
            "\n",
            "✅ Wrote:\n",
            "  Clean training set : /content/models/run_01/META_training_clean.parquet\n",
            "  Reject report      : /content/models/run_01/META_training_rejects.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3634886728.py:134: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  all_targets_ok = train[TARGETS].notna().all(axis=1) & train[TARGETS].applymap(np.isfinite).all(axis=1)\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# CELL 4.1 — Strict training filter + reject report\n",
        "# Ensures: no NaNs, finite targets, non-negative, file exists, sane ratios, de-duped\n",
        "# Outputs:\n",
        "#   /content/models/run_01/META_training_clean.parquet\n",
        "#   /content/models/run_01/META_training_rejects.csv\n",
        "# ==============================================================================\n",
        "\n",
        "import os, json, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "OUTDIR = Path(\"/content/models/run_01\")\n",
        "CONF = OUTDIR / \"config.json\"\n",
        "\n",
        "# --- Load master from config (fallback to postenrich/master you used) ---\n",
        "with open(CONF, \"r\") as f:\n",
        "    cfg = json.load(f)\n",
        "\n",
        "master_path = Path(cfg.get(\"master_file\", OUTDIR / \"META_training_ready.parquet\"))\n",
        "if not master_path.exists():\n",
        "    raise FileNotFoundError(f\"Master not found: {master_path}\")\n",
        "\n",
        "TARGETS = cfg.get(\"targets\", [\"views\",\"likes\",\"comments\"])\n",
        "df = pd.read_parquet(master_path).copy()\n",
        "\n",
        "# Normalize columns\n",
        "df[\"video_id\"] = df[\"video_id\"].astype(str).str.upper()\n",
        "for c in TARGETS:\n",
        "    if c in df.columns:\n",
        "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "# Some pipelines store the feature path under different names — normalize that too\n",
        "feat_col = None\n",
        "for cand in [\"feature_path\",\"feature\",\"path\",\"feat_path\"]:\n",
        "    if cand in df.columns:\n",
        "        feat_col = cand\n",
        "        break\n",
        "if feat_col is None:\n",
        "    raise RuntimeError(\"No feature path column found (expected one of: feature_path, feature, path, feat_path).\")\n",
        "\n",
        "# --- Helper flags ---\n",
        "def is_finite(x):\n",
        "    return np.isfinite(x)\n",
        "\n",
        "def safe_ratio(num, den):\n",
        "    num = float(num) if np.isfinite(num) else np.nan\n",
        "    den = float(den) if np.isfinite(den) else np.nan\n",
        "    if not np.isfinite(num) or not np.isfinite(den) or den <= 0:\n",
        "        return np.nan\n",
        "    return num/den\n",
        "\n",
        "# --- Build rejection reasons per row ---\n",
        "reasons = []\n",
        "\n",
        "# Thresholds (conservative defaults; tweak if you like)\n",
        "MIN_VIEWS = 1            # require at least 1 view\n",
        "MAX_LIKE_RATE = 1.0      # likes <= views (per-sample)\n",
        "MAX_COMM_RATE = 2.0      # comments <= 2x views (very lax; protects data entry issues)\n",
        "\n",
        "exists_mask = df[feat_col].map(lambda p: Path(str(p)).exists())\n",
        "reasons.append(np.where(~exists_mask, \"missing_feature_file\", \"\"))\n",
        "\n",
        "# Missing or non-finite targets\n",
        "for t in TARGETS:\n",
        "    miss = ~df[t].notna()\n",
        "    nonfin = ~df[t].map(is_finite)\n",
        "    neg = df[t] < 0\n",
        "    reasons.append(np.where(miss, f\"{t}_missing\", \"\"))\n",
        "    reasons.append(np.where(nonfin, f\"{t}_nonfinite\", \"\"))\n",
        "    reasons.append(np.where(neg, f\"{t}_negative\", \"\"))\n",
        "\n",
        "# Basic sanity constraints\n",
        "views = df[\"views\"]\n",
        "likes = df[\"likes\"]\n",
        "comments = df[\"comments\"]\n",
        "\n",
        "low_views = views.fillna(-1) < MIN_VIEWS\n",
        "reasons.append(np.where(low_views, \"views_below_min\", \"\"))\n",
        "\n",
        "like_rate = [safe_ratio(l, v) for l, v in zip(likes, views)]\n",
        "comm_rate = [safe_ratio(c, v) for c, v in zip(comments, views)]\n",
        "\n",
        "reasons.append(np.where(pd.Series(like_rate) > MAX_LIKE_RATE, \"likes>views\", \"\"))\n",
        "reasons.append(np.where(pd.Series(comm_rate) > MAX_COMM_RATE, \"comments>2xviews\", \"\"))\n",
        "\n",
        "# Aggregate reasons\n",
        "reason_df = pd.DataFrame({f\"r{i}\": r for i, r in enumerate(reasons)})\n",
        "df[\"reject_reasons\"] = reason_df.apply(lambda row: \",\".join([x for x in row if x]), axis=1)\n",
        "df[\"reject_reasons\"] = df[\"reject_reasons\"].str.strip(\",\")\n",
        "\n",
        "# Keep rows with NO reasons\n",
        "ok_mask = df[\"reject_reasons\"] == \"\"\n",
        "df_ok = df[ok_mask].copy()\n",
        "df_bad = df[~ok_mask].copy()\n",
        "\n",
        "# --- Deduplicate by video_id (keep the most complete & largest views, file exists) ---\n",
        "def completeness_score(row):\n",
        "    score = 0\n",
        "    for t in TARGETS:\n",
        "        score += int(pd.notna(row[t]) and np.isfinite(row[t]))\n",
        "    score += int(Path(str(row[feat_col])).exists())\n",
        "    # prefer larger views if ties\n",
        "    v = row[\"views\"]\n",
        "    try:\n",
        "        score = (score, float(v) if np.isfinite(v) else -1.0)\n",
        "    except Exception:\n",
        "        score = (score, -1.0)\n",
        "    return score\n",
        "\n",
        "df_ok[\"_score\"] = df_ok.apply(completeness_score, axis=1)\n",
        "df_ok = df_ok.sort_values([\"video_id\",\"_score\"], ascending=[True, False])\n",
        "df_ok = df_ok[~df_ok.duplicated(subset=[\"video_id\"], keep=\"first\")].drop(columns=[\"_score\"])\n",
        "\n",
        "# --- Final training set ---\n",
        "train = df_ok.copy()\n",
        "\n",
        "# --- Prints & saves ---\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING FILTER SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Master rows:           {len(df):,}\")\n",
        "print(f\"Feature file exists:   {exists_mask.sum():,}/{len(df):,}\")\n",
        "print(f\"Rejected rows total:   {len(df_bad):,}\")\n",
        "if len(df_bad):\n",
        "    print(\"Top rejection reasons:\")\n",
        "    print(df_bad[\"reject_reasons\"].str.get_dummies(sep=\",\").sum().sort_values(ascending=False).head(10))\n",
        "\n",
        "print(f\"\\nKept (pre-dedupe):     {ok_mask.sum():,}\")\n",
        "print(f\"Kept (post-dedupe):    {len(train):,}\")\n",
        "\n",
        "# Target completeness in final set\n",
        "all_targets_ok = train[TARGETS].notna().all(axis=1) & train[TARGETS].applymap(np.isfinite).all(axis=1)\n",
        "print(f\"Rows with ALL targets: {all_targets_ok.sum():,}/{len(train):,}\")\n",
        "\n",
        "# Basic target stats on final set\n",
        "print(\"\\nTarget stats on final training set:\")\n",
        "for t in TARGETS:\n",
        "    x = pd.to_numeric(train[t], errors=\"coerce\")\n",
        "    print(f\"  {t}: count={x.notna().sum():,}, min={x.min():.0f}, p50={x.quantile(0.5):.0f}, p90={x.quantile(0.9):.0f}, max={x.max():.0f}\")\n",
        "\n",
        "# Save artifacts\n",
        "clean_path   = OUTDIR / \"META_training_clean.parquet\"\n",
        "rejects_path = OUTDIR / \"META_training_rejects.csv\"\n",
        "train.to_parquet(clean_path, index=False)\n",
        "df_bad.to_csv(rejects_path, index=False)\n",
        "\n",
        "# Update config pointers\n",
        "cfg[\"master_file_clean\"] = str(clean_path)\n",
        "cfg[\"final_samples_clean\"] = int(len(train))\n",
        "with open(CONF, \"w\") as f:\n",
        "    json.dump(cfg, f, indent=2)\n",
        "\n",
        "print(\"\\n✅ Wrote:\")\n",
        "print(f\"  Clean training set : {clean_path}\")\n",
        "print(f\"  Reject report      : {rejects_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjtSH8YMp0hB",
        "outputId": "414e07c0-7000-4b47-8a05-487ed1ada579"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CELL 5: Model Definition\n",
            "======================================================================\n",
            "✓ Model defined\n",
            "  Parameters: 451,203\n",
            "  ✓ No Sigmoid in output!\n",
            "\n",
            "✅ Cell 5 Complete\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# CELL 5: Define Model (1 minute)\n",
        "# ==============================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CELL 5: Model Definition\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, padding):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.act = nn.SiLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.act(self.bn(self.conv(x)))\n",
        "\n",
        "class AudioBackbone(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.stem = ConvBlock(1, 32, (3,7), (1,3))\n",
        "        self.block1 = ConvBlock(32, 64, (3,5), (1,2))\n",
        "        self.block2 = ConvBlock(64, 128, (3,5), (1,2))\n",
        "        self.block3 = ConvBlock(128, 192, (3,3), (1,1))\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        return self.pool(x).flatten(1)\n",
        "\n",
        "class MultiTaskModel(nn.Module):\n",
        "    def __init__(self, n_targets, embedding_dim=192):\n",
        "        super().__init__()\n",
        "        self.n_targets = n_targets\n",
        "        self.backbone = AudioBackbone()\n",
        "        self.heads = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(embedding_dim, 128),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(0.3),\n",
        "                nn.Linear(128, 1)\n",
        "                # NO Sigmoid - regression not classification!\n",
        "            )\n",
        "            for _ in range(n_targets)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x)\n",
        "        outputs = [head(features).squeeze(1) for head in self.heads]\n",
        "        return torch.stack(outputs, dim=1)\n",
        "\n",
        "# Test model\n",
        "test_model = MultiTaskModel(n_targets=3)\n",
        "total_params = sum(p.numel() for p in test_model.parameters())\n",
        "print(f\"✓ Model defined\")\n",
        "print(f\"  Parameters: {total_params:,}\")\n",
        "print(f\"  ✓ No Sigmoid in output!\")\n",
        "\n",
        "print(f\"\\n✅ Cell 5 Complete\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILnJBYc_o3X8",
        "outputId": "550e8b59-64bb-4e38-f713-bd9fc2296129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CELL 5: Model Definition\n",
            "======================================================================\n",
            "✓ Model defined\n",
            "  Parameters: 451,203\n",
            "  ✓ No Sigmoid in output!\n",
            "\n",
            "✅ Cell 5 Complete\n"
          ]
        }
      ],
      "source": [
        "# CELL 5: Model Definition\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CELL 5: Model Definition\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, padding):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.act = nn.SiLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.act(self.bn(self.conv(x)))\n",
        "\n",
        "class AudioBackbone(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.stem = ConvBlock(1, 32, (3,7), (1,3))\n",
        "        self.block1 = ConvBlock(32, 64, (3,5), (1,2))\n",
        "        self.block2 = ConvBlock(64, 128, (3,5), (1,2))\n",
        "        self.block3 = ConvBlock(128, 192, (3,3), (1,1))\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        return self.pool(x).flatten(1)\n",
        "\n",
        "class MultiTaskModel(nn.Module):\n",
        "    def __init__(self, n_targets, embedding_dim=192):\n",
        "        super().__init__()\n",
        "        self.n_targets = n_targets\n",
        "        self.backbone = AudioBackbone()\n",
        "        self.heads = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(embedding_dim, 128),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(0.3),\n",
        "                nn.Linear(128, 1)\n",
        "                # NO Sigmoid - regression not classification!\n",
        "            )\n",
        "            for _ in range(n_targets)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x)\n",
        "        outputs = [head(features).squeeze(1) for head in self.heads]\n",
        "        return torch.stack(outputs, dim=1)\n",
        "\n",
        "# Test model\n",
        "test_model = MultiTaskModel(n_targets=3)\n",
        "total_params = sum(p.numel() for p in test_model.parameters())\n",
        "print(f\"✓ Model defined\")\n",
        "print(f\"  Parameters: {total_params:,}\")\n",
        "print(f\"  ✓ No Sigmoid in output!\")\n",
        "\n",
        "print(f\"\\n✅ Cell 5 Complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcV8J_uhpBs2",
        "outputId": "f1b6f67b-f810-4b9d-a071-dbf512d71dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['feature_path', 'basename', 'filename', 'stem', 'video_id', 'video_id_upper', 'views', 'likes', 'comments', 'channel', 'published_date', 'user_engagement_signal', 'platform_quality_signal', 'quality_final']\n"
          ]
        }
      ],
      "source": [
        "# Check what columns you have\n",
        "import pandas as pd\n",
        "master = pd.read_parquet(\"/content/models/run_01/META_master_4k.parquet\")\n",
        "print(master.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bI2qclWP4q4V",
        "outputId": "fc5694bc-794f-42b2-e3dd-37cc29fa725e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CREATING LOG-TRANSFORMED TARGETS (Alternative Approach)\n",
            "======================================================================\n",
            "Input:  /content/models/run_01/META_training_ready.parquet\n",
            "Output: /content/drive/MyDrive/STA 160/models/run_01/META_log_targets.parquet\n",
            "\n",
            "✓ Loaded 8,965 rows\n",
            "\n",
            "======================================================================\n",
            "CREATING LOG TARGETS:\n",
            "======================================================================\n",
            "\n",
            "views → views_log:\n",
            "  Original range: [26, 5773797147]\n",
            "  Log range:      [3.30, 22.48]\n",
            "  Log mean:       14.87\n",
            "  Log std:        3.58\n",
            "\n",
            "likes → likes_log:\n",
            "  Original range: [0, 40147618]\n",
            "  Log range:      [0.00, 17.51]\n",
            "  Log mean:       10.35\n",
            "  Log std:        3.29\n",
            "\n",
            "comments → comments_log:\n",
            "  Original range: [0, 5331537]\n",
            "  Log range:      [0.00, 15.49]\n",
            "  Log mean:       6.40\n",
            "  Log std:        3.66\n",
            "\n",
            "======================================================================\n",
            "LOG TARGET STATISTICS:\n",
            "======================================================================\n",
            "\n",
            "views_log:\n",
            "  mean: 14.866\n",
            "  std:  3.578\n",
            "  min:  3.296\n",
            "  25%:  12.328\n",
            "  50%:  15.106\n",
            "  75%:  17.626\n",
            "  max:  22.477\n",
            "\n",
            "likes_log:\n",
            "  mean: 10.348\n",
            "  std:  3.291\n",
            "  min:  0.000\n",
            "  25%:  8.123\n",
            "  50%:  10.496\n",
            "  75%:  12.965\n",
            "  max:  17.508\n",
            "\n",
            "comments_log:\n",
            "  mean: 6.400\n",
            "  std:  3.660\n",
            "  min:  0.000\n",
            "  25%:  3.807\n",
            "  50%:  6.599\n",
            "  75%:  9.343\n",
            "  max:  15.489\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE CONVERSIONS (Log → Real):\n",
            "======================================================================\n",
            "\n",
            "views_log → actual views:\n",
            "  10 →      22K  (Low popularity)\n",
            "  12 →     163K  (Below average)\n",
            "  14 →     1.2M  (Average)\n",
            "  16 →     8.9M  (Above average)\n",
            "  18 →    65.7M  (Popular)\n",
            "  20 →   485.2M  (Very popular)\n",
            "  22 →  3584.9M  (Viral hit)\n",
            "\n",
            "✓ Saved log-target data: /content/drive/MyDrive/STA 160/models/run_01/META_log_targets.parquet\n",
            "✓ Updated config.json\n",
            "\n",
            "======================================================================\n",
            "NEXT STEPS:\n",
            "======================================================================\n",
            "1. Update Cell 6:\n",
            "   a. Change master_file path\n",
            "   b. Change TARGETS = ['views_log', 'likes_log', 'comments_log']\n",
            "2. Retrain for 30-50 epochs\n",
            "3. Predictions will be in log scale (interpretable!)\n",
            "4. Convert back: actual_views = np.expm1(prediction)\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "ADVANTAGES OF LOG TARGETS:\n",
            "======================================================================\n",
            "✓ Full dynamic range preserved (no compression)\n",
            "✓ Directly interpretable (can convert to real numbers)\n",
            "✓ No z-score confusion\n",
            "✓ More robust to outliers (log dampens extremes)\n",
            "✓ Industry standard for popularity prediction\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# Alternative: Use Raw Log-Transformed Targets (Most Interpretable!)\n",
        "# ================================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CREATING LOG-TRANSFORMED TARGETS (Alternative Approach)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ---------- Paths ----------\n",
        "MASTER_FILE = Path(\"/content/models/run_01/META_training_ready.parquet\")\n",
        "OUTPUT_FILE = Path(\"/content/drive/MyDrive/STA 160/models/run_01/META_log_targets.parquet\")\n",
        "\n",
        "print(f\"Input:  {MASTER_FILE}\")\n",
        "print(f\"Output: {OUTPUT_FILE}\")\n",
        "\n",
        "# ---------- Load data ----------\n",
        "df = pd.read_parquet(MASTER_FILE)\n",
        "print(f\"\\n✓ Loaded {len(df):,} rows\")\n",
        "\n",
        "# ---------- Create log-transformed targets ----------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CREATING LOG TARGETS:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Ensure we have the raw metrics\n",
        "for col in ['views', 'likes', 'comments']:\n",
        "    if col not in df.columns:\n",
        "        print(f\"⚠️ Missing column: {col}\")\n",
        "        continue\n",
        "\n",
        "    # Log transform (handles zeros)\n",
        "    log_col = f'{col}_log'\n",
        "    df[log_col] = np.log1p(df[col].fillna(0))\n",
        "\n",
        "    print(f\"\\n{col} → {log_col}:\")\n",
        "    print(f\"  Original range: [{df[col].min():.0f}, {df[col].max():.0f}]\")\n",
        "    print(f\"  Log range:      [{df[log_col].min():.2f}, {df[log_col].max():.2f}]\")\n",
        "    print(f\"  Log mean:       {df[log_col].mean():.2f}\")\n",
        "    print(f\"  Log std:        {df[log_col].std():.2f}\")\n",
        "\n",
        "# ---------- Statistics ----------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"LOG TARGET STATISTICS:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for col in ['views_log', 'likes_log', 'comments_log']:\n",
        "    if col in df.columns:\n",
        "        s = df[col]\n",
        "        print(f\"\\n{col}:\")\n",
        "        print(f\"  mean: {s.mean():.3f}\")\n",
        "        print(f\"  std:  {s.std():.3f}\")\n",
        "        print(f\"  min:  {s.min():.3f}\")\n",
        "        print(f\"  25%:  {s.quantile(0.25):.3f}\")\n",
        "        print(f\"  50%:  {s.quantile(0.50):.3f}\")\n",
        "        print(f\"  75%:  {s.quantile(0.75):.3f}\")\n",
        "        print(f\"  max:  {s.max():.3f}\")\n",
        "\n",
        "# ---------- Examples ----------\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EXAMPLE CONVERSIONS (Log → Real):\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "examples = [\n",
        "    (\"Low popularity\", 10),\n",
        "    (\"Below average\", 12),\n",
        "    (\"Average\", 14),\n",
        "    (\"Above average\", 16),\n",
        "    (\"Popular\", 18),\n",
        "    (\"Very popular\", 20),\n",
        "    (\"Viral hit\", 22),\n",
        "]\n",
        "\n",
        "print(\"\\nviews_log → actual views:\")\n",
        "for label, log_val in examples:\n",
        "    actual = np.expm1(log_val)\n",
        "    if actual >= 1e6:\n",
        "        display = f\"{actual/1e6:.1f}M\"\n",
        "    elif actual >= 1e3:\n",
        "        display = f\"{actual/1e3:.0f}K\"\n",
        "    else:\n",
        "        display = f\"{actual:.0f}\"\n",
        "    print(f\"  {log_val:2.0f} → {display:>8s}  ({label})\")\n",
        "\n",
        "# ---------- Save ----------\n",
        "OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
        "df.to_parquet(OUTPUT_FILE, index=False)\n",
        "\n",
        "print(f\"\\n✓ Saved log-target data: {OUTPUT_FILE}\")\n",
        "\n",
        "# ---------- Update config ----------\n",
        "import json\n",
        "config_path = OUTPUT_FILE.parent / \"config.json\"\n",
        "if config_path.exists():\n",
        "    with open(config_path, 'r') as f:\n",
        "        config = json.load(f)\n",
        "else:\n",
        "    config = {}\n",
        "\n",
        "config['master_file'] = str(OUTPUT_FILE)\n",
        "config['use_log_targets'] = True\n",
        "config['log_target_stats'] = {\n",
        "    col: {\n",
        "        'mean': float(df[col].mean()),\n",
        "        'std': float(df[col].std()),\n",
        "        'min': float(df[col].min()),\n",
        "        'max': float(df[col].max())\n",
        "    }\n",
        "    for col in ['views_log', 'likes_log', 'comments_log'] if col in df.columns\n",
        "}\n",
        "\n",
        "with open(config_path, 'w') as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "\n",
        "print(f\"✓ Updated config.json\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"NEXT STEPS:\")\n",
        "print(\"=\"*70)\n",
        "print(\"1. Update Cell 6:\")\n",
        "print(\"   a. Change master_file path\")\n",
        "print(\"   b. Change TARGETS = ['views_log', 'likes_log', 'comments_log']\")\n",
        "print(\"2. Retrain for 30-50 epochs\")\n",
        "print(\"3. Predictions will be in log scale (interpretable!)\")\n",
        "print(\"4. Convert back: actual_views = np.expm1(prediction)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ADVANTAGES OF LOG TARGETS:\")\n",
        "print(\"=\"*70)\n",
        "print(\"✓ Full dynamic range preserved (no compression)\")\n",
        "print(\"✓ Directly interpretable (can convert to real numbers)\")\n",
        "print(\"✓ No z-score confusion\")\n",
        "print(\"✓ More robust to outliers (log dampens extremes)\")\n",
        "print(\"✓ Industry standard for popularity prediction\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRR2a5IQqD_m",
        "outputId": "8eac9375-cdcd-481b-a9a6-72ac8ea90ddb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CELL 6 — Fast, Robust Trainer (Google Drive Autosave)\n",
            "======================================================================\n",
            "✓ Output directory: /content/drive/MyDrive/STA 160/models/run_01\n",
            "✓ Using master: /content/drive/MyDrive/STA 160/models/run_01/META_log_targets.parquet\n",
            "✓ Loaded 8,965 master rows\n",
            "✓ Targets: ['views_log', 'likes_log', 'comments_log']\n",
            "✓ Train: 7,620 | Val: 1,345\n",
            "\n",
            "Creating train/val datasets (fast & robust)…\n",
            "✓ Train batches: 158 | Val batches: 29\n",
            "✓ Model created: 8,055,171 trainable parameters (total: 8,055,171)\n",
            "\n",
            "Training…\n",
            "======================================================================\n",
            "Output dir: /content/drive/MyDrive/STA 160/models/run_01\n",
            "Patience: 10 epochs (early stopping)\n",
            "======================================================================\n",
            "Epoch 01/30 | Train 20.9186 | Val 20.9258 | LR 1.0e-03 | 109s\n",
            "  ✓ New best 20.9258 — saved to Google Drive: /content/drive/MyDrive/STA 160/models/run_01/best_model_robust.pt\n",
            "Epoch 02/30 | Train 13.1405 | Val 13.2261 | LR 1.0e-03 | 123s\n",
            "  ✓ New best 13.2261 — saved to Google Drive: /content/drive/MyDrive/STA 160/models/run_01/best_model_robust.pt\n",
            "Epoch 03/30 | Train 12.9762 | Val 12.6015 | LR 1.0e-03 | 110s\n",
            "  ✓ New best 12.6015 — saved to Google Drive: /content/drive/MyDrive/STA 160/models/run_01/best_model_robust.pt\n",
            "Epoch 04/30 | Train 12.9330 | Val 12.7478 | LR 1.0e-03 | 107s\n",
            "Epoch 05/30 | Train 12.8078 | Val 12.4745 | LR 1.0e-03 | 105s\n",
            "  ✓ New best 12.4745 — saved to Google Drive: /content/drive/MyDrive/STA 160/models/run_01/best_model_robust.pt\n",
            "Epoch 06/30 | Train 12.8680 | Val 12.5503 | LR 1.0e-03 | 114s\n",
            "Epoch 07/30 | Train 12.8450 | Val 13.2543 | LR 1.0e-03 | 115s\n",
            "Epoch 08/30 | Train 12.7130 | Val 12.6794 | LR 1.0e-03 | 116s\n",
            "Epoch 09/30 | Train 12.7234 | Val 12.4500 | LR 1.0e-03 | 100s\n",
            "  ✓ New best 12.4500 — saved to Google Drive: /content/drive/MyDrive/STA 160/models/run_01/best_model_robust.pt\n",
            "Epoch 10/30 | Train 12.7449 | Val 12.5678 | LR 1.0e-03 | 119s\n",
            "Epoch 11/30 | Train 12.7876 | Val 12.6696 | LR 1.0e-03 | 112s\n",
            "Epoch 12/30 | Train 12.6475 | Val 12.4222 | LR 1.0e-03 | 109s\n",
            "  ✓ New best 12.4222 — saved to Google Drive: /content/drive/MyDrive/STA 160/models/run_01/best_model_robust.pt\n",
            "Epoch 13/30 | Train 12.6814 | Val 12.4029 | LR 1.0e-03 | 109s\n",
            "  ✓ New best 12.4029 — saved to Google Drive: /content/drive/MyDrive/STA 160/models/run_01/best_model_robust.pt\n",
            "Epoch 14/30 | Train 12.5809 | Val 12.4889 | LR 1.0e-03 | 107s\n",
            "Epoch 15/30 | Train 12.6475 | Val 12.4597 | LR 1.0e-03 | 106s\n",
            "Epoch 16/30 | Train 12.6303 | Val 12.3947 | LR 1.0e-03 | 117s\n",
            "  ✓ New best 12.3947 — saved to Google Drive: /content/drive/MyDrive/STA 160/models/run_01/best_model_robust.pt\n",
            "Epoch 17/30 | Train 12.6304 | Val 12.5685 | LR 1.0e-03 | 111s\n",
            "Epoch 18/30 | Train 12.5661 | Val 12.3883 | LR 1.0e-03 | 113s\n",
            "  ✓ New best 12.3883 — saved to Google Drive: /content/drive/MyDrive/STA 160/models/run_01/best_model_robust.pt\n",
            "Epoch 19/30 | Train 12.6299 | Val 12.3811 | LR 1.0e-03 | 105s\n",
            "  ✓ New best 12.3811 — saved to Google Drive: /content/drive/MyDrive/STA 160/models/run_01/best_model_robust.pt\n",
            "Epoch 20/30 | Train 12.6280 | Val 12.5532 | LR 1.0e-03 | 114s\n",
            "Epoch 21/30 | Train 12.5467 | Val 12.5040 | LR 1.0e-03 | 105s\n",
            "Epoch 22/30 | Train 12.6359 | Val 12.6193 | LR 1.0e-03 | 103s\n",
            "Epoch 23/30 | Train 12.5978 | Val 12.4030 | LR 1.0e-03 | 105s\n",
            "Epoch 24/30 | Train 12.6497 | Val 12.5433 | LR 1.0e-03 | 104s\n",
            "Epoch 25/30 | Train 12.5844 | Val 12.3109 | LR 1.0e-03 | 112s\n",
            "  ✓ New best 12.3109 — saved to Google Drive: /content/drive/MyDrive/STA 160/models/run_01/best_model_robust.pt\n",
            "Epoch 26/30 | Train 12.4666 | Val 13.2334 | LR 1.0e-03 | 107s\n",
            "Epoch 27/30 | Train 12.6220 | Val 12.8198 | LR 1.0e-03 | 107s\n",
            "Epoch 28/30 | Train 12.5526 | Val 12.5842 | LR 1.0e-03 | 101s\n",
            "Epoch 29/30 | Train 12.6377 | Val 12.5871 | LR 1.0e-03 | 111s\n",
            "Epoch 30/30 | Train 12.6741 | Val 12.5339 | LR 1.0e-03 | 106s\n",
            "✓ Training history saved: /content/drive/MyDrive/STA 160/models/run_01/training_history_robust.csv\n",
            "✓ Config updated: /content/drive/MyDrive/STA 160/models/run_01/config.json\n",
            "\n",
            "======================================================================\n",
            "✅ Training complete!\n",
            "======================================================================\n",
            "Best val loss: 12.3109\n",
            "Total epochs: 30\n",
            "Best model saved to Google Drive: /content/drive/MyDrive/STA 160/models/run_01/best_model_robust.pt\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# CELL 6 — Fast, Robust Trainer (Google Drive Autosave + Improved Architecture)\n",
        "# ================================================================\n",
        "import os, time, json, random, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Optional, Tuple, List\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.amp import GradScaler, autocast\n",
        "\n",
        "# ---------- Paths / Config (NOW SAVES TO GOOGLE DRIVE!) ----------\n",
        "OUTDIR = Path(\"/content/drive/MyDrive/STA 160/models/run_01\")\n",
        "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "config_path = OUTDIR / \"config.json\"\n",
        "if config_path.exists():\n",
        "    with open(config_path, \"r\") as f:\n",
        "        config = json.load(f)\n",
        "else:\n",
        "    config = {}\n",
        "\n",
        "master_file = Path(config.get(\"master_file\", OUTDIR / \"META_log_targets.parquet\"))\n",
        "# Fallback search for master file\n",
        "if not master_file.exists():\n",
        "    for candidate in [\n",
        "        OUTDIR / \"META_training_ready.parquet\",\n",
        "        OUTDIR / \"META_master_postenrich.parquet\",\n",
        "        Path(\"/content/models/run_01/META_training_ready.parquet\"),\n",
        "        Path(\"/content/models/run_01/META_master_postenrich.parquet\"),\n",
        "    ]:\n",
        "        if candidate.exists():\n",
        "            master_file = candidate\n",
        "            break\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CELL 6 — Fast, Robust Trainer (Google Drive Autosave)\")\n",
        "print(\"=\"*70)\n",
        "print(f\"✓ Output directory: {OUTDIR}\")\n",
        "print(f\"✓ Using master: {master_file}\")\n",
        "\n",
        "# ---------- Hyperparams ----------\n",
        "MEL_BINS  = 128\n",
        "FRAMES    = 768\n",
        "VAL_SPLIT = 0.15\n",
        "BATCH_SIZE = 48\n",
        "EPOCHS     = 30  # Increased from 30\n",
        "LR, WD     = 1e-3, 1e-4\n",
        "MAX_GRAD_NORM = 1.0\n",
        "PATIENCE   = 10  # Early stopping patience\n",
        "SEED = 2025\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE   = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "AMP_EN   = USE_CUDA\n",
        "\n",
        "if USE_CUDA:\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "if USE_CUDA: torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# ---------- Load data ----------\n",
        "df = pd.read_parquet(master_file)\n",
        "print(f\"✓ Loaded {len(df):,} master rows\")\n",
        "\n",
        "# prefer signals, else counts\n",
        "CAND_SETS = [\n",
        "    [\"views_log\", \"likes_log\", \"comments_log\"],\n",
        "    [\"views\",\"likes\",\"comments\"],\n",
        "]\n",
        "for cand in CAND_SETS:\n",
        "    if all(c in df.columns for c in cand):\n",
        "        TARGETS = cand; break\n",
        "else:\n",
        "    raise RuntimeError(\"No valid target set in master file.\")\n",
        "print(f\"✓ Targets: {TARGETS}\")\n",
        "\n",
        "idx = np.arange(len(df)); np.random.shuffle(idx)\n",
        "cut = int(len(idx)*(1-VAL_SPLIT))\n",
        "df_train, df_val = df.iloc[idx[:cut]].reset_index(drop=True), df.iloc[idx[cut:]].reset_index(drop=True)\n",
        "print(f\"✓ Train: {len(df_train):,} | Val: {len(df_val):,}\")\n",
        "\n",
        "target_stats = {t: {\"mean\": float(pd.to_numeric(df[t], errors=\"coerce\").mean()),\n",
        "                    \"std\" : float(pd.to_numeric(df[t], errors=\"coerce\").std() or 1.0)}\n",
        "                for t in TARGETS}\n",
        "\n",
        "# ---------- Feature loader ----------\n",
        "def _finite(arr): return np.isfinite(arr).all()\n",
        "\n",
        "def load_feature(fp: str, frames: int = FRAMES, center: bool = False) -> Optional[np.ndarray]:\n",
        "    try:\n",
        "        with np.load(fp, allow_pickle=False, mmap_mode=\"r\" if USE_CUDA else None) as z:\n",
        "            key = next((k for k in (\"logmel\",\"log_mel\",\"mel\",\"features\",\"x\",\"S\") if k in z.files), None)\n",
        "            if key is None:\n",
        "                return None\n",
        "            x = z[key]\n",
        "\n",
        "        # Squeeze and orient to [F, T]\n",
        "        if x.ndim == 3:\n",
        "            x = x.squeeze()\n",
        "        if x.ndim != 2:\n",
        "            return None\n",
        "        if x.shape[0] != MEL_BINS and x.shape[1] == MEL_BINS:\n",
        "            x = x.T\n",
        "        if x.shape[0] != MEL_BINS:\n",
        "            return None\n",
        "\n",
        "        # Force a safe float dtype before any magnitude checks\n",
        "        if x.dtype != np.float32:\n",
        "            x = x.astype(np.float32, copy=False)\n",
        "\n",
        "        # Fast finite check first\n",
        "        if not np.isfinite(x).all():\n",
        "            return None\n",
        "\n",
        "        # Suppress noisy overflow warnings during the magnitude guard\n",
        "        with np.errstate(over=\"ignore\", invalid=\"ignore\"):\n",
        "            mx = np.nanmax(np.abs(x))\n",
        "        if not np.isfinite(mx) or mx > 1e6:\n",
        "            return None\n",
        "\n",
        "        # Center/Random crop or pad to FRAMES\n",
        "        T = x.shape[1]\n",
        "        if T >= frames:\n",
        "            start = (T - frames)//2 if center else np.random.randint(0, T - frames + 1)\n",
        "            x = x[:, start:start+frames]\n",
        "        else:\n",
        "            pad = frames - T\n",
        "            x = np.pad(x, ((0,0), (pad//2, pad - pad//2)), mode=\"constant\")\n",
        "\n",
        "        # Robust winsorize + standardize\n",
        "        lo, hi = np.percentile(x, [0.5, 99.5]).astype(np.float32)\n",
        "        x = np.clip(x, lo, hi)\n",
        "\n",
        "        m = float(np.mean(x, dtype=np.float64))\n",
        "        s = float(np.std(x,  dtype=np.float64))\n",
        "        if not np.isfinite(s) or s < 1e-6:\n",
        "            return None\n",
        "        x = (x - m) / s\n",
        "        x = np.clip(x, -10, 10)\n",
        "\n",
        "        if not np.isfinite(x).all():\n",
        "            return None\n",
        "\n",
        "        # [C=1, F, T]\n",
        "        return x.astype(np.float32, copy=False)[None, ...]\n",
        "\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "class FastAudioDS(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, targets: List[str], center: bool = False):\n",
        "        self.df = df.reset_index(drop=True); self.targets = targets; self.center = center\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i: int) -> Optional[Tuple[torch.Tensor, torch.Tensor]]:\n",
        "        r = self.df.iloc[i]\n",
        "        x = load_feature(r[\"feature_path\"], center=self.center)\n",
        "        if x is None: return None\n",
        "        y = np.array([float(r[t]) for t in self.targets], dtype=np.float32)\n",
        "        if not np.isfinite(y).all(): return None\n",
        "        return torch.from_numpy(x), torch.from_numpy(y)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch = [b for b in batch if b is not None]\n",
        "    if not batch: return None\n",
        "    X, y = zip(*batch); return torch.stack(X,0), torch.stack(y,0)\n",
        "\n",
        "# ---------- DataLoader factory ----------\n",
        "if not USE_CUDA:\n",
        "    BATCH_SIZE = min(BATCH_SIZE, 16)\n",
        "NUM_WORKERS = max(2, os.cpu_count()//2) if USE_CUDA else 0\n",
        "PIN = USE_CUDA\n",
        "\n",
        "def make_loader(dataset, shuffle, drop_last, workers=NUM_WORKERS):\n",
        "    kwargs = dict(batch_size=BATCH_SIZE, shuffle=shuffle, num_workers=workers,\n",
        "                  pin_memory=PIN, collate_fn=collate_fn, drop_last=drop_last)\n",
        "    if workers > 0:\n",
        "        kwargs.update(dict(persistent_workers=True, prefetch_factor=4))\n",
        "    return DataLoader(dataset, **kwargs)\n",
        "\n",
        "print(\"\\nCreating train/val datasets (fast & robust)…\")\n",
        "train_ds = FastAudioDS(df_train, TARGETS, center=False)\n",
        "val_ds   = FastAudioDS(df_val,   TARGETS, center=True)\n",
        "\n",
        "train_loader = make_loader(train_ds, shuffle=True,  drop_last=True)\n",
        "val_loader   = make_loader(val_ds,   shuffle=False, drop_last=False)\n",
        "print(f\"✓ Train batches: {len(train_loader)} | Val batches: {len(val_loader)}\")\n",
        "\n",
        "# ---------- IMPROVED Model Architecture (Fixed + Deeper) ----------\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, cin, cout, k=(3,7), s=(1,1), p=None):\n",
        "        super().__init__()\n",
        "        p = p or (k[0]//2, k[1]//2)\n",
        "        self.conv = nn.Conv2d(cin, cout, k, s, p)\n",
        "        self.bn = nn.BatchNorm2d(cout)\n",
        "        self.act = nn.SiLU()\n",
        "    def forward(self, x):\n",
        "        return self.act(self.bn(self.conv(x)))\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"Simple residual connection for same-channel blocks\"\"\"\n",
        "    def __init__(self, channels, k=(3,3)):\n",
        "        super().__init__()\n",
        "        p = (k[0]//2, k[1]//2)\n",
        "        self.conv1 = nn.Conv2d(channels, channels, k, padding=p)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.act1 = nn.SiLU()\n",
        "        self.conv2 = nn.Conv2d(channels, channels, k, padding=p)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "        self.act2 = nn.SiLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.act1(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out = out + identity  # Residual connection\n",
        "        return self.act2(out)\n",
        "\n",
        "class MultiTaskModel(nn.Module):\n",
        "    \"\"\"\n",
        "    FIXED Architecture - Now properly uses all 5 channel sizes with residual connections\n",
        "\n",
        "    Architecture:\n",
        "    - stem: 1 -> 32 (initial feature extraction)\n",
        "    - b1: 32 -> 64 + residual (low-level features)\n",
        "    - b2: 64 -> 128 + residual (mid-level features) + maxpool\n",
        "    - b3: 128 -> 256 + residual (high-level features) + maxpool\n",
        "    - b4: 256 -> 512 + residual (abstract features)\n",
        "    - head: 512 -> 256 -> n_targets (prediction)\n",
        "\n",
        "    Total depth: 5 stages (vs original 4)\n",
        "    Residual connections help gradient flow for deeper network\n",
        "    \"\"\"\n",
        "    def __init__(self, n_targets):\n",
        "        super().__init__()\n",
        "        C = [32, 64, 128, 256, 512]  # Now ALL channels are used!\n",
        "\n",
        "        # Initial feature extraction\n",
        "        self.stem = ConvBlock(1, C[0], (3,7))\n",
        "        self.res_stem = ResidualBlock(C[0], (3,3))\n",
        "\n",
        "        # Hierarchical feature learning\n",
        "        self.b1 = ConvBlock(C[0], C[1], (3,5))\n",
        "        self.res1 = ResidualBlock(C[1], (3,3))\n",
        "\n",
        "        self.b2 = ConvBlock(C[1], C[2], (3,5))\n",
        "        self.res2 = ResidualBlock(C[2], (3,3))\n",
        "\n",
        "        self.b3 = ConvBlock(C[2], C[3], (3,3))\n",
        "        self.res3 = ResidualBlock(C[3], (3,3))\n",
        "\n",
        "        self.b4 = ConvBlock(C[3], C[4], (3,3))  # NEW: Now using C[4]=512\n",
        "        self.res4 = ResidualBlock(C[4], (3,3))\n",
        "\n",
        "        # Global pooling\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "\n",
        "        # Prediction head (wider for more capacity)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(C[4], 256),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(0.3),  # Increased dropout for regularization\n",
        "            nn.Linear(256, n_targets)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Stage 1: Initial features\n",
        "        x = self.stem(x)\n",
        "        x = self.res_stem(x)\n",
        "\n",
        "        # Stage 2: Low-level features\n",
        "        x = self.b1(x)\n",
        "        x = self.res1(x)\n",
        "\n",
        "        # Stage 3: Mid-level features + downsample\n",
        "        x = self.b2(x)\n",
        "        x = self.res2(x)\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "\n",
        "        # Stage 4: High-level features + downsample\n",
        "        x = self.b3(x)\n",
        "        x = self.res3(x)\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "\n",
        "        # Stage 5: Abstract features (NEW)\n",
        "        x = self.b4(x)\n",
        "        x = self.res4(x)\n",
        "\n",
        "        # Global pooling + prediction\n",
        "        x = self.pool(x)\n",
        "        return self.head(x)\n",
        "\n",
        "model = MultiTaskModel(n_targets=len(TARGETS)).to(DEVICE)\n",
        "if USE_CUDA:\n",
        "    model = model.to(memory_format=torch.channels_last)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"✓ Model created: {trainable_params:,} trainable parameters (total: {total_params:,})\")\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
        "criterion = nn.MSELoss()\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=5)\n",
        "scaler = GradScaler(device=\"cuda\") if AMP_EN else None\n",
        "\n",
        "def to_dev(X, y):\n",
        "    if USE_CUDA:\n",
        "        X = X.to(DEVICE, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "    else:\n",
        "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "    return X, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate():\n",
        "    model.eval(); losses = []\n",
        "    for batch in val_loader:\n",
        "        if batch is None: continue\n",
        "        X, y = to_dev(*batch)\n",
        "        with autocast(device_type=\"cuda\", enabled=AMP_EN):\n",
        "            pred = model(X); loss = criterion(pred, y)\n",
        "        if torch.isfinite(loss): losses.append(loss.item())\n",
        "    return float(np.mean(losses)) if losses else float(\"inf\")\n",
        "\n",
        "# ---------- Train with Early Stopping (auto-save to Google Drive) ----------\n",
        "print(\"\\nTraining…\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Output dir: {OUTDIR}\")\n",
        "print(f\"Patience: {PATIENCE} epochs (early stopping)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "best_val, history = float(\"inf\"), []\n",
        "patience_counter = 0\n",
        "ckpt_path = OUTDIR / \"best_model_robust.pt\"\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    t0 = time.time(); model.train(); batch_losses = []\n",
        "\n",
        "    for batch in make_loader(train_ds, shuffle=True, drop_last=True):\n",
        "        if batch is None: continue\n",
        "        X, y = to_dev(*batch)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        if AMP_EN:\n",
        "            with autocast(device_type=\"cuda\", enabled=True):\n",
        "                pred = model(X); loss = criterion(pred, y)\n",
        "            if not torch.isfinite(loss): continue\n",
        "            scaler.scale(loss).backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
        "            scaler.step(optimizer); scaler.update()\n",
        "        else:\n",
        "            pred = model(X); loss = criterion(pred, y)\n",
        "            if not torch.isfinite(loss): continue\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
        "            optimizer.step()\n",
        "\n",
        "        batch_losses.append(loss.item())\n",
        "\n",
        "    train_loss = float(np.mean(batch_losses)) if batch_losses else float(\"inf\")\n",
        "    val_loss = evaluate()\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    print(f\"Epoch {epoch:02d}/{EPOCHS} | Train {train_loss:.4f} | Val {val_loss:.4f} | \"\n",
        "          f\"LR {current_lr:.1e} | {time.time()-t0:.0f}s\")\n",
        "\n",
        "    history.append({\n",
        "        \"epoch\": epoch,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"lr\": current_lr\n",
        "    })\n",
        "\n",
        "    # Save to Google Drive if new best\n",
        "    if np.isfinite(val_loss) and val_loss < best_val:\n",
        "        best_val = val_loss\n",
        "        patience_counter = 0\n",
        "\n",
        "        state = {k: v.detach().cpu() for k,v in model.state_dict().items()}\n",
        "        torch.save({\n",
        "            \"model_state_dict\": state,\n",
        "            \"targets\": TARGETS,\n",
        "            \"target_stats\": target_stats,\n",
        "            \"best_val_loss\": best_val,\n",
        "            \"epoch\": epoch,\n",
        "            \"config\": {\n",
        "                \"mel_bins\": MEL_BINS,\n",
        "                \"frames\": FRAMES,\n",
        "                \"batch_size\": BATCH_SIZE,\n",
        "                \"lr\": LR,\n",
        "                \"weight_decay\": WD,\n",
        "                \"architecture\": \"MultiTaskModel_v2_with_residuals\"\n",
        "            }\n",
        "        }, ckpt_path)\n",
        "\n",
        "        print(f\"  ✓ New best {best_val:.4f} — saved to Google Drive: {ckpt_path}\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(f\"\\n⚠️ Early stopping triggered after {epoch} epochs (no improvement for {PATIENCE} epochs)\")\n",
        "            break\n",
        "\n",
        "# Save history to Google Drive\n",
        "history_path = OUTDIR / \"training_history_robust.csv\"\n",
        "pd.DataFrame(history).to_csv(history_path, index=False)\n",
        "print(f\"✓ Training history saved: {history_path}\")\n",
        "\n",
        "# Update config in Google Drive\n",
        "config.update({\n",
        "    \"best_val_loss\": best_val,\n",
        "    \"targets\": TARGETS,\n",
        "    \"target_stats\": target_stats,\n",
        "    \"checkpoint_path\": str(ckpt_path),\n",
        "    \"training_complete\": True,\n",
        "    \"total_epochs\": len(history),\n",
        "    \"architecture\": \"MultiTaskModel_v2_with_residuals\"\n",
        "})\n",
        "with open(OUTDIR / \"config.json\", \"w\") as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "print(f\"✓ Config updated: {OUTDIR / 'config.json'}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ Training complete!\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Best val loss: {best_val:.4f}\")\n",
        "print(f\"Total epochs: {len(history)}\")\n",
        "print(f\"Best model saved to Google Drive: {ckpt_path}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im3EJoXEqT9K",
        "outputId": "967f2f45-5fa8-4c13-cdf8-3585511417bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing these files:\n",
            "  1. ✓ Adele_-_Hello_Original_-_yana_enik_(mp3.pm) (.mp3 6.7 MB)\n",
            "  2. ✓ DJ_Smash_feat._Ridley_-_The_Night_Is_Young_(mp3.pm) (.mp3 6.7 MB)\n",
            "  3. ✓ 《孤勇者》（《英雄聯盟：雙城之戰》動畫劇集中文主題曲）陳奕迅 Eason Chan [Official MV] (.mp3 4.2 MB)\n",
            "\n",
            "[1/4] Loading checkpoint...\n",
            "✓ Checkpoint loaded from Google Drive\n",
            "  Targets: ['views_log', 'likes_log', 'comments_log']\n",
            "  MEL_BINS: 128, FRAMES: 768\n",
            "\n",
            "[DEBUG] Sample checkpoint keys: ['stem.conv.weight', 'stem.conv.bias', 'stem.bn.weight', 'stem.bn.bias', 'stem.bn.running_mean', 'stem.bn.running_var', 'stem.bn.num_batches_tracked', 'res_stem.conv1.weight', 'res_stem.conv1.bias', 'res_stem.bn1.weight']...\n",
            "[arch] ✓ Detected MultiTaskModel_v2 (5 stages with residuals)\n",
            "✓ Model loaded: MultiTaskModel_v2 on cuda\n",
            "\n",
            "[2/4] Setting up audio processing...\n",
            "✓ Audio processing ready\n",
            "\n",
            "[3/4] Predicting quality for your songs...\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "SONG 1: Adele_-_Hello_Original_-_yana_enik_(mp3.pm)\n",
            "======================================================================\n",
            "  ✓ Loaded via: librosa\n",
            "\n",
            "VIEWS LOG:\n",
            "  Predicted:  14.373\n",
            "\n",
            "LIKES LOG:\n",
            "  Predicted:  10.044\n",
            "\n",
            "COMMENTS LOG:\n",
            "  Predicted:   6.185\n",
            "\n",
            "======================================================================\n",
            "SONG 2: DJ_Smash_feat._Ridley_-_The_Night_Is_Young_(mp3.pm)\n",
            "======================================================================\n",
            "  ✓ Loaded via: librosa\n",
            "\n",
            "VIEWS LOG:\n",
            "  Predicted:  15.005\n",
            "\n",
            "LIKES LOG:\n",
            "  Predicted:  10.498\n",
            "\n",
            "COMMENTS LOG:\n",
            "  Predicted:   6.538\n",
            "\n",
            "======================================================================\n",
            "SONG 3: 《孤勇者》（《英雄聯盟：雙城之戰》動畫劇集中文主題曲）陳奕迅 Eason Chan [Official MV]\n",
            "======================================================================\n",
            "  ✓ Loaded via: librosa\n",
            "\n",
            "VIEWS LOG:\n",
            "  Predicted:  14.452\n",
            "\n",
            "LIKES LOG:\n",
            "  Predicted:  10.092\n",
            "\n",
            "COMMENTS LOG:\n",
            "  Predicted:   6.206\n",
            "\n",
            "[4/4] Comparing your songs...\n",
            "======================================================================\n",
            "\n",
            "Song 1: Adele_-_Hello_Original_-_yana_enik_(mp3.pm)\n",
            "Song 2: DJ_Smash_feat._Ridley_-_The_Night_Is_Young_(mp3.pm)\n",
            "\n",
            "VIEWS LOG:\n",
            "  Song 1:  14.373\n",
            "  Song 2:  15.005\n",
            "  Diff:     0.632\n",
            "\n",
            "LIKES LOG:\n",
            "  Song 1:  10.044\n",
            "  Song 2:  10.498\n",
            "  Diff:     0.454\n",
            "\n",
            "COMMENTS LOG:\n",
            "  Song 1:   6.185\n",
            "  Song 2:   6.538\n",
            "  Diff:     0.353\n",
            "\n",
            "======================================================================\n",
            "AVERAGE DIFFERENCE: 0.480\n",
            "\n",
            "✓ Results saved to Google Drive: /content/drive/MyDrive/STA 160/models/run_01/custom_songs_test.json\n",
            "\n",
            "======================================================================\n",
            "✅ EVALUATION COMPLETE!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ======================================================================\n",
        "# CELL 8.5 — Model loader (Updated for improved architecture with residuals)\n",
        "# ======================================================================\n",
        "from pathlib import Path\n",
        "import torch, torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# --------------------------- discover test audio ---------------------------\n",
        "DRIVE_FOLDER = Path(\"/content/drive/MyDrive/STA 160/test\")\n",
        "candidates = sorted(\n",
        "    [*DRIVE_FOLDER.glob(\"*.mp3\"), *DRIVE_FOLDER.glob(\"*.wav\"),\n",
        "     *DRIVE_FOLDER.glob(\"*.m4a\"), *DRIVE_FOLDER.glob(\"*.flac\"),\n",
        "     *DRIVE_FOLDER.glob(\"*.ogg\")]\n",
        ")\n",
        "test_files = [p for p in candidates if not p.name.endswith(\".crdownload\") and p.stat().st_size > 0]\n",
        "song_names = [p.stem[:80] for p in test_files]\n",
        "\n",
        "print(\"Testing these files:\")\n",
        "for i, (p, name) in enumerate(zip(test_files, song_names), 1):\n",
        "    print(f\"  {i}. ✓ {name} ({p.suffix.lower()} {p.stat().st_size/1_048_576:.1f} MB)\")\n",
        "\n",
        "assert len(test_files) >= 2, (\n",
        "    \"Need at least 2 finalized audio files in /STA 160/test folder.\"\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Updated checkpoint path (now in Google Drive)\n",
        "ckpt_path = Path(\"/content/drive/MyDrive/STA 160/models/run_01/best_model_robust.pt\")\n",
        "\n",
        "# =============== MODEL ARCHITECTURES ===============\n",
        "\n",
        "# --- Basic building blocks ---\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, cin, cout, k=(3,7), s=(1,1), p=None):\n",
        "        super().__init__()\n",
        "        p = p or (k[0]//2, k[1]//2)\n",
        "        self.conv = nn.Conv2d(cin, cout, k, s, p)\n",
        "        self.bn = nn.BatchNorm2d(cout)\n",
        "        self.act = nn.SiLU()\n",
        "    def forward(self, x):\n",
        "        return self.act(self.bn(self.conv(x)))\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"Residual connection for improved gradient flow\"\"\"\n",
        "    def __init__(self, channels, k=(3,3)):\n",
        "        super().__init__()\n",
        "        p = (k[0]//2, k[1]//2)\n",
        "        self.conv1 = nn.Conv2d(channels, channels, k, padding=p)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.act1 = nn.SiLU()\n",
        "        self.conv2 = nn.Conv2d(channels, channels, k, padding=p)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "        self.act2 = nn.SiLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.act1(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out = out + identity\n",
        "        return self.act2(out)\n",
        "\n",
        "# --- NEW Improved Architecture (with residuals) ---\n",
        "class MultiTaskModel_v2(nn.Module):\n",
        "    \"\"\"\n",
        "    Improved architecture with residual connections\n",
        "    5 stages: stem -> b1 -> b2 -> b3 -> b4\n",
        "    Channels: [32, 64, 128, 256, 512]\n",
        "    \"\"\"\n",
        "    def __init__(self, n_targets):\n",
        "        super().__init__()\n",
        "        C = [32, 64, 128, 256, 512]\n",
        "\n",
        "        self.stem = ConvBlock(1, C[0], (3,7))\n",
        "        self.res_stem = ResidualBlock(C[0], (3,3))\n",
        "\n",
        "        self.b1 = ConvBlock(C[0], C[1], (3,5))\n",
        "        self.res1 = ResidualBlock(C[1], (3,3))\n",
        "\n",
        "        self.b2 = ConvBlock(C[1], C[2], (3,5))\n",
        "        self.res2 = ResidualBlock(C[2], (3,3))\n",
        "\n",
        "        self.b3 = ConvBlock(C[2], C[3], (3,3))\n",
        "        self.res3 = ResidualBlock(C[3], (3,3))\n",
        "\n",
        "        self.b4 = ConvBlock(C[3], C[4], (3,3))\n",
        "        self.res4 = ResidualBlock(C[4], (3,3))\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(C[4], 256),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, n_targets)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.res_stem(x)\n",
        "\n",
        "        x = self.b1(x)\n",
        "        x = self.res1(x)\n",
        "\n",
        "        x = self.b2(x)\n",
        "        x = self.res2(x)\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "\n",
        "        x = self.b3(x)\n",
        "        x = self.res3(x)\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "\n",
        "        x = self.b4(x)\n",
        "        x = self.res4(x)\n",
        "\n",
        "        x = self.pool(x)\n",
        "        return self.head(x)\n",
        "\n",
        "# --- Original Architecture (4 stages, no residuals) ---\n",
        "class MultiTaskModel_v1(nn.Module):\n",
        "    \"\"\"Original architecture from first training\"\"\"\n",
        "    def __init__(self, n_targets):\n",
        "        super().__init__()\n",
        "        C = [32, 64, 128, 192]\n",
        "        self.stem = ConvBlock(1, C[0], (3,7))\n",
        "        self.b1   = ConvBlock(C[0], C[1], (3,5))\n",
        "        self.b2   = ConvBlock(C[1], C[2], (3,5))\n",
        "        self.b3   = ConvBlock(C[2], C[3], (3,3))\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(C[3], 256),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, n_targets)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.b1(x)\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "        x = self.b2(x)\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "        x = self.b3(x)\n",
        "        x = self.pool(x)\n",
        "        return self.head(x)\n",
        "\n",
        "# --------------------------- safe checkpoint load ---------------------------\n",
        "def load_checkpoint_safe(path, device):\n",
        "    \"\"\"Try weights_only=True, then allowlist numpy, finally fallback\"\"\"\n",
        "    try:\n",
        "        return torch.load(path, map_location=device, weights_only=True)\n",
        "    except Exception:\n",
        "        try:\n",
        "            from torch.serialization import add_safe_globals\n",
        "            add_safe_globals([np._core.multiarray.scalar, np.dtype])\n",
        "            return torch.load(path, map_location=device, weights_only=True)\n",
        "        except Exception:\n",
        "            print(\"[warn] Falling back to weights_only=False (trusted local checkpoint).\")\n",
        "            return torch.load(path, map_location=device, weights_only=False)\n",
        "\n",
        "# ---------- robust checkpoint extraction ----------\n",
        "def extract_state_targets_cfg(ckpt):\n",
        "    \"\"\"Return (state_dict, targets:list[str], cfg:dict)\"\"\"\n",
        "    if isinstance(ckpt, torch.nn.Module):\n",
        "        return ckpt.state_dict(), [\"quality_final\"], {}\n",
        "\n",
        "    if not isinstance(ckpt, dict):\n",
        "        raise RuntimeError(f\"Unsupported checkpoint type: {type(ckpt)}\")\n",
        "\n",
        "    # Find state dict\n",
        "    candidate_keys = [\n",
        "        \"model_state_dict\", \"state_dict\", \"ema_state_dict\",\n",
        "        \"model\", \"net\", \"weights\", \"params\"\n",
        "    ]\n",
        "    state = None\n",
        "    for k in candidate_keys:\n",
        "        v = ckpt.get(k)\n",
        "        if isinstance(v, dict) and all(isinstance(x, torch.Tensor) for x in v.values()):\n",
        "            state = v\n",
        "            break\n",
        "\n",
        "    if state is None and all(isinstance(v, torch.Tensor) for v in ckpt.values()):\n",
        "        state = ckpt\n",
        "\n",
        "    if state is None:\n",
        "        raise RuntimeError(\"Could not locate model state_dict in checkpoint.\")\n",
        "\n",
        "    # Strip common prefixes\n",
        "    STRIP_PREFIXES = (\"module.\", \"_orig_mod.\", \"model.\", \"net.\")\n",
        "    def _strip(k: str) -> str:\n",
        "        for p in STRIP_PREFIXES:\n",
        "            if k.startswith(p):\n",
        "                return k[len(p):]\n",
        "        return k\n",
        "    state = {_strip(k): v for k, v in state.items()}\n",
        "\n",
        "    targets = ckpt.get(\"targets\") or ckpt.get(\"target_names\") or [\"quality_final\"]\n",
        "    cfg = ckpt.get(\"config\") or ckpt.get(\"cfg\") or {}\n",
        "\n",
        "    return state, targets, cfg\n",
        "\n",
        "# ---------------------- Load checkpoint ----------------------\n",
        "print(\"\\n[1/4] Loading checkpoint...\")\n",
        "checkpoint = load_checkpoint_safe(ckpt_path, device)\n",
        "state, TARGETS, cfg = extract_state_targets_cfg(checkpoint)\n",
        "\n",
        "# Get config values\n",
        "DEFAULT_MEL_BINS = 128\n",
        "DEFAULT_FRAMES   = 768\n",
        "MEL_BINS = int(cfg.get(\"mel_bins\", DEFAULT_MEL_BINS))\n",
        "FRAMES   = int(cfg.get(\"frames\", DEFAULT_FRAMES))\n",
        "\n",
        "print(f\"✓ Checkpoint loaded from Google Drive\")\n",
        "print(f\"  Targets: {TARGETS}\")\n",
        "print(f\"  MEL_BINS: {MEL_BINS}, FRAMES: {FRAMES}\")\n",
        "\n",
        "# ---------------------- Detect architecture ----------------------\n",
        "def _has_prefix_keys(sdict, prefix: str) -> bool:\n",
        "    return any(k.startswith(prefix) for k in sdict.keys())\n",
        "\n",
        "_sample_keys = list(state.keys())[:20]\n",
        "print(f\"\\n[DEBUG] Sample checkpoint keys: {_sample_keys[:10]}...\")\n",
        "\n",
        "# Auto-detect architecture based on checkpoint keys\n",
        "has_res_blocks = _has_prefix_keys(state, \"res_stem.\") or _has_prefix_keys(state, \"res1.\")\n",
        "has_b4 = _has_prefix_keys(state, \"b4.\")\n",
        "\n",
        "if has_res_blocks and has_b4:\n",
        "    print(\"[arch] ✓ Detected MultiTaskModel_v2 (5 stages with residuals)\")\n",
        "    model = MultiTaskModel_v2(n_targets=len(TARGETS))\n",
        "    strict = True\n",
        "elif _has_prefix_keys(state, \"stem.\") and _has_prefix_keys(state, \"head.\"):\n",
        "    if has_b4:\n",
        "        print(\"[arch] ✓ Detected MultiTaskModel with b4 (trying v2)\")\n",
        "        model = MultiTaskModel_v2(n_targets=len(TARGETS))\n",
        "        strict = False\n",
        "    else:\n",
        "        print(\"[arch] ✓ Detected MultiTaskModel_v1 (4 stages, no residuals)\")\n",
        "        model = MultiTaskModel_v1(n_targets=len(TARGETS))\n",
        "        strict = True\n",
        "else:\n",
        "    print(\"[arch] ⚠️ Unknown architecture, trying v2 as fallback\")\n",
        "    model = MultiTaskModel_v2(n_targets=len(TARGETS))\n",
        "    strict = False\n",
        "\n",
        "# Load weights\n",
        "missing, unexpected = model.load_state_dict(state, strict=strict)\n",
        "\n",
        "if missing:\n",
        "    print(f\"[warn] Missing keys ({len(missing)}): {missing[:5]}\")\n",
        "if unexpected:\n",
        "    print(f\"[warn] Unexpected keys ({len(unexpected)}): {unexpected[:5]}\")\n",
        "\n",
        "model.to(device).eval()\n",
        "print(f\"✓ Model loaded: {model.__class__.__name__} on {device}\")\n",
        "\n",
        "# ==================== AUDIO PROCESSING ====================\n",
        "print(\"\\n[2/4] Setting up audio processing...\")\n",
        "\n",
        "import librosa, tempfile, subprocess, os\n",
        "\n",
        "SAMPLE_RATE = 16000\n",
        "N_FFT = 2048\n",
        "HOP_LENGTH = 512\n",
        "\n",
        "def _convert_to_wav_ffmpeg(audio_path):\n",
        "    tmp = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
        "    tmp.close()\n",
        "    cmd = [\"ffmpeg\", \"-y\", \"-i\", str(audio_path), \"-ac\", \"1\", \"-ar\", str(SAMPLE_RATE), tmp.name]\n",
        "    try:\n",
        "        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)\n",
        "        return tmp.name\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        raise RuntimeError(f\"ffmpeg failed: {e}\") from e\n",
        "\n",
        "def safe_load_audio(path):\n",
        "    try:\n",
        "        y, sr = librosa.load(path, sr=SAMPLE_RATE, mono=True)\n",
        "        if y is None or len(y) == 0:\n",
        "            raise RuntimeError(\"empty audio\")\n",
        "        return y, sr, \"librosa\"\n",
        "    except Exception:\n",
        "        wav = None\n",
        "        try:\n",
        "            wav = _convert_to_wav_ffmpeg(path)\n",
        "            y, sr = librosa.load(wav, sr=SAMPLE_RATE, mono=True)\n",
        "            if y is None or len(y) == 0:\n",
        "                raise RuntimeError(\"empty audio after ffmpeg\")\n",
        "            return y, sr, \"ffmpeg->librosa\"\n",
        "        finally:\n",
        "            if wav and os.path.exists(wav):\n",
        "                try:\n",
        "                    os.unlink(wav)\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "def make_logmel(y, sr=SAMPLE_RATE):\n",
        "    S = librosa.feature.melspectrogram(\n",
        "        y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=MEL_BINS, power=2.0\n",
        "    )\n",
        "    S_db = librosa.power_to_db(S, ref=np.max)\n",
        "\n",
        "    # Crop/pad to FRAMES\n",
        "    T = S_db.shape[1]\n",
        "    if T >= FRAMES:\n",
        "        start = max(0, (T - FRAMES)//2)\n",
        "        S_db = S_db[:, start:start+FRAMES]\n",
        "    else:\n",
        "        pad = FRAMES - T\n",
        "        S_db = np.pad(S_db, ((0,0),(pad//2, pad - pad//2)), mode=\"edge\")\n",
        "\n",
        "    # Normalize\n",
        "    m = float(np.mean(S_db))\n",
        "    s = float(np.std(S_db))\n",
        "    if not np.isfinite(m) or not np.isfinite(s) or s < 1e-6:\n",
        "        s = 1.0\n",
        "    Z = (S_db - m) / s\n",
        "    np.clip(Z, -10, 10, out=Z)\n",
        "\n",
        "    if not np.isfinite(Z).all():\n",
        "        raise RuntimeError(\"non-finite after normalization\")\n",
        "\n",
        "    return torch.from_numpy(Z.astype(np.float32)).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "print(\"✓ Audio processing ready\")\n",
        "\n",
        "# ==================== PREDICT ====================\n",
        "print(\"\\n[3/4] Predicting quality for your songs...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_one(audio_path: Path):\n",
        "    y, sr, how = safe_load_audio(str(audio_path))\n",
        "    x = make_logmel(y, sr).to(device)\n",
        "    pred = model(x).cpu().numpy()[0]\n",
        "    return pred, how\n",
        "\n",
        "results = []\n",
        "errors  = []\n",
        "\n",
        "for i, (audio_file, nice_name) in enumerate(zip(test_files, song_names), 1):\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"SONG {i}: {nice_name}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    try:\n",
        "        pred, how = predict_one(audio_file)\n",
        "        print(f\"  ✓ Loaded via: {how}\")\n",
        "\n",
        "        for j, t in enumerate(TARGETS):\n",
        "            val = float(pred[j])\n",
        "            print(f\"\\n{t.upper().replace('_',' ')}:\\n  Predicted: {val:7.3f}\")\n",
        "\n",
        "        results.append({\n",
        "            \"song\": nice_name,\n",
        "            \"file\": audio_file.name,\n",
        "            \"pred\": pred.tolist()\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed: {audio_file.name} — {e}\")\n",
        "        errors.append((audio_file.name, str(e)))\n",
        "\n",
        "# ==================== COMPARE ====================\n",
        "print(\"\\n[4/4] Comparing your songs...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if len(results) >= 2:\n",
        "    a, b = results[0], results[1]\n",
        "    print(f\"\\nSong 1: {a['song']}\\nSong 2: {b['song']}\")\n",
        "\n",
        "    diffs = []\n",
        "    for j, t in enumerate(TARGETS):\n",
        "        v1, v2 = a[\"pred\"][j], b[\"pred\"][j]\n",
        "        diff = abs(v1 - v2)\n",
        "        diffs.append(diff)\n",
        "        print(f\"\\n{t.upper().replace('_',' ')}:\")\n",
        "        print(f\"  Song 1: {v1:7.3f}\")\n",
        "        print(f\"  Song 2: {v2:7.3f}\")\n",
        "        print(f\"  Diff:   {diff:7.3f}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"AVERAGE DIFFERENCE: {np.mean(diffs):.3f}\")\n",
        "\n",
        "elif len(results) == 1:\n",
        "    print(\"\\n⚠️ Only 1 song processed successfully — add another file for comparison.\")\n",
        "else:\n",
        "    print(\"\\n❌ No songs processed — see errors above.\")\n",
        "\n",
        "# Save results to Google Drive\n",
        "if results:\n",
        "    import json\n",
        "    outp = Path(\"/content/drive/MyDrive/STA 160/models/run_01/custom_songs_test.json\")\n",
        "    outp.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(outp, \"w\") as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    print(f\"\\n✓ Results saved to Google Drive: {outp}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ EVALUATION COMPLETE!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgBVaMblHIDZ",
        "outputId": "d3516e1f-771b-445f-fcfc-bece808dd5f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "[BONUS] Converting Log Predictions to Real Numbers\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "SONG 1: Adele_-_Hello_Original_-_yana_enik_(mp3.pm)\n",
            "======================================================================\n",
            "\n",
            "📊 VIEWS:\n",
            "  Log value:    14.373\n",
            "  Actual views:      1.75M  (1,745,879)\n",
            "\n",
            "👍 LIKES:\n",
            "  Log value:    10.044\n",
            "  Actual likes:      23.0K  (23,017)\n",
            "\n",
            "💬 COMMENTS:\n",
            "  Log value:       6.185\n",
            "  Actual comments:        484  (484)\n",
            "\n",
            "📈 ENGAGEMENT:\n",
            "  Like ratio: 1.32%\n",
            "\n",
            "======================================================================\n",
            "SONG 2: DJ_Smash_feat._Ridley_-_The_Night_Is_Young_(mp3.pm)\n",
            "======================================================================\n",
            "\n",
            "📊 VIEWS:\n",
            "  Log value:    15.005\n",
            "  Actual views:      3.29M  (3,285,917)\n",
            "\n",
            "👍 LIKES:\n",
            "  Log value:    10.498\n",
            "  Actual likes:      36.3K  (36,259)\n",
            "\n",
            "💬 COMMENTS:\n",
            "  Log value:       6.538\n",
            "  Actual comments:        690  (690)\n",
            "\n",
            "📈 ENGAGEMENT:\n",
            "  Like ratio: 1.10%\n",
            "\n",
            "======================================================================\n",
            "SONG 3: 《孤勇者》（《英雄聯盟：雙城之戰》動畫劇集中文主題曲）陳奕迅 Eason Chan [Official MV]\n",
            "======================================================================\n",
            "\n",
            "📊 VIEWS:\n",
            "  Log value:    14.452\n",
            "  Actual views:      1.89M  (1,889,662)\n",
            "\n",
            "👍 LIKES:\n",
            "  Log value:    10.092\n",
            "  Actual likes:      24.2K  (24,157)\n",
            "\n",
            "💬 COMMENTS:\n",
            "  Log value:       6.206\n",
            "  Actual comments:        495  (495)\n",
            "\n",
            "📈 ENGAGEMENT:\n",
            "  Like ratio: 1.28%\n",
            "\n",
            "======================================================================\n",
            "POPULARITY COMPARISON\n",
            "======================================================================\n",
            "\n",
            "Ranked by Predicted Views:\n",
            "  1. DJ_Smash_feat._Ridley_-_The_Night_Is_Young_(mp3.pm      3.29M\n",
            "  2. 《孤勇者》（《英雄聯盟：雙城之戰》動畫劇集中文主題曲）陳奕迅 Eason Chan [Officia      1.89M\n",
            "  3. Adele_-_Hello_Original_-_yana_enik_(mp3.pm)             1.75M\n",
            "\n",
            "📊 Spread Analysis:\n",
            "  Most popular: 3.29M views\n",
            "  Least popular: 1.75M views\n",
            "  Ratio: 1.88x\n",
            "  Verdict: Clear winner (1 standout song)\n",
            "\n",
            "======================================================================\n",
            "✅ EVALUATION COMPLETE!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Add this to the END of your Cell 8.5 (after the comparison section)\n",
        "\n",
        "# ==================== BONUS: CONVERT TO REAL NUMBERS ====================\n",
        "if any('_log' in t for t in TARGETS):\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"[BONUS] Converting Log Predictions to Real Numbers\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    for i, res in enumerate(results, 1):\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"SONG {i}: {res['song']}\")\n",
        "        print('='*70)\n",
        "\n",
        "        # Find indices\n",
        "        views_idx = TARGETS.index('views_log') if 'views_log' in TARGETS else None\n",
        "        likes_idx = TARGETS.index('likes_log') if 'likes_log' in TARGETS else None\n",
        "        comments_idx = TARGETS.index('comments_log') if 'comments_log' in TARGETS else None\n",
        "\n",
        "        # Convert and display\n",
        "        if views_idx is not None:\n",
        "            log_val = res['pred'][views_idx]\n",
        "            actual = np.expm1(log_val)\n",
        "\n",
        "            if actual >= 1e9:\n",
        "                display = f\"{actual/1e9:.2f}B\"\n",
        "            elif actual >= 1e6:\n",
        "                display = f\"{actual/1e6:.2f}M\"\n",
        "            elif actual >= 1e3:\n",
        "                display = f\"{actual/1e3:.0f}K\"\n",
        "            else:\n",
        "                display = f\"{actual:.0f}\"\n",
        "\n",
        "            print(f\"\\n📊 VIEWS:\")\n",
        "            print(f\"  Log value:    {log_val:.3f}\")\n",
        "            print(f\"  Actual views: {display:>10s}  ({actual:,.0f})\")\n",
        "\n",
        "        if likes_idx is not None:\n",
        "            log_val = res['pred'][likes_idx]\n",
        "            actual = np.expm1(log_val)\n",
        "\n",
        "            if actual >= 1e6:\n",
        "                display = f\"{actual/1e6:.2f}M\"\n",
        "            elif actual >= 1e3:\n",
        "                display = f\"{actual/1e3:.1f}K\"\n",
        "            else:\n",
        "                display = f\"{actual:.0f}\"\n",
        "\n",
        "            print(f\"\\n👍 LIKES:\")\n",
        "            print(f\"  Log value:    {log_val:.3f}\")\n",
        "            print(f\"  Actual likes: {display:>10s}  ({actual:,.0f})\")\n",
        "\n",
        "        if comments_idx is not None:\n",
        "            log_val = res['pred'][comments_idx]\n",
        "            actual = np.expm1(log_val)\n",
        "\n",
        "            if actual >= 1e3:\n",
        "                display = f\"{actual/1e3:.1f}K\"\n",
        "            else:\n",
        "                display = f\"{actual:.0f}\"\n",
        "\n",
        "            print(f\"\\n💬 COMMENTS:\")\n",
        "            print(f\"  Log value:       {log_val:.3f}\")\n",
        "            print(f\"  Actual comments: {display:>10s}  ({actual:,.0f})\")\n",
        "\n",
        "        # Engagement ratio\n",
        "        if views_idx is not None and likes_idx is not None:\n",
        "            views_actual = np.expm1(res['pred'][views_idx])\n",
        "            likes_actual = np.expm1(res['pred'][likes_idx])\n",
        "            ratio = (likes_actual / views_actual * 100) if views_actual > 0 else 0\n",
        "            print(f\"\\n📈 ENGAGEMENT:\")\n",
        "            print(f\"  Like ratio: {ratio:.2f}%\")\n",
        "\n",
        "    # Summary comparison\n",
        "    if len(results) >= 2:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"POPULARITY COMPARISON\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        if views_idx is not None:\n",
        "            views_actual = [np.expm1(r['pred'][views_idx]) for r in results]\n",
        "\n",
        "            # Sort by views\n",
        "            sorted_idx = sorted(range(len(results)), key=lambda i: views_actual[i], reverse=True)\n",
        "\n",
        "            print(\"\\nRanked by Predicted Views:\")\n",
        "            for rank, idx in enumerate(sorted_idx, 1):\n",
        "                actual = views_actual[idx]\n",
        "                if actual >= 1e6:\n",
        "                    display = f\"{actual/1e6:.2f}M\"\n",
        "                elif actual >= 1e3:\n",
        "                    display = f\"{actual/1e3:.0f}K\"\n",
        "                else:\n",
        "                    display = f\"{actual:.0f}\"\n",
        "\n",
        "                name = results[idx]['song'][:50]  # Truncate long names\n",
        "                print(f\"  {rank}. {name:<50s} {display:>10s}\")\n",
        "\n",
        "            # Range\n",
        "            max_views = max(views_actual)\n",
        "            min_views = min(views_actual)\n",
        "            ratio = max_views / min_views if min_views > 0 else float('inf')\n",
        "\n",
        "            print(f\"\\n📊 Spread Analysis:\")\n",
        "            print(f\"  Most popular: {max_views/1e6:.2f}M views\")\n",
        "            print(f\"  Least popular: {min_views/1e6:.2f}M views\")\n",
        "            print(f\"  Ratio: {ratio:.2f}x\")\n",
        "\n",
        "            if ratio < 1.5:\n",
        "                verdict = \"Similar popularity (all average)\"\n",
        "            elif ratio < 3:\n",
        "                verdict = \"Clear winner (1 standout song)\"\n",
        "            elif ratio < 10:\n",
        "                verdict = \"Very different (wide popularity gap)\"\n",
        "            else:\n",
        "                verdict = \"Extreme difference (viral vs unknown)\"\n",
        "\n",
        "            print(f\"  Verdict: {verdict}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ EVALUATION COMPLETE!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "OKgw-Y1WWlrY",
        "outputId": "70c68b76-be42-412a-e281-b4ae095aa383"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "MODEL EVALUATION - SIMPLIFIED\n",
            "======================================================================\n",
            "Using device: cpu\n",
            "\n",
            "[1/5] Loading model...\n",
            "======================================================================\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/STA 160/models/run_01/best_model_robust.pt'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3980249738.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0mTARGETS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"targets\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"views_log\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"likes_log\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"comments_log\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFileLike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/STA 160/models/run_01/best_model_robust.pt'"
          ]
        }
      ],
      "source": [
        "# ======================================================================\n",
        "# CELL 9 — Comprehensive Model Validation & Metrics\n",
        "# ======================================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error, mean_absolute_error, r2_score,\n",
        "    precision_score, recall_score, f1_score, accuracy_score,\n",
        "    confusion_matrix, classification_report\n",
        ")\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"COMPREHENSIVE MODEL VALIDATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ---------- Configuration ----------\n",
        "DRIVE_BASE = Path(\"/content/drive/MyDrive/STA 160\")\n",
        "MODEL_DIR = DRIVE_BASE / \"models/audio_features\"\n",
        "ckpt_path = MODEL_DIR / \"/models/run_01/best_model_robust.pt\"\n",
        "\n",
        "# Load validation data (ground truth)\n",
        "val_data_path = DRIVE_BASE / \"models/run_01/META_audio_features.parquet\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ======================== LOAD MODEL ========================\n",
        "\n",
        "print(\"\\n[1/6] Loading model...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Import model architecture (same as training)\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, cin, cout, k=(3,7), s=(1,1), p=None):\n",
        "        super().__init__()\n",
        "        p = p or (k[0]//2, k[1]//2)\n",
        "        self.conv = nn.Conv2d(cin, cout, k, s, p)\n",
        "        self.bn = nn.BatchNorm2d(cout)\n",
        "        self.act = nn.SiLU()\n",
        "    def forward(self, x):\n",
        "        return self.act(self.bn(self.conv(x)))\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels, k=(3,3)):\n",
        "        super().__init__()\n",
        "        p = (k[0]//2, k[1]//2)\n",
        "        self.conv1 = nn.Conv2d(channels, channels, k, padding=p)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.act1 = nn.SiLU()\n",
        "        self.conv2 = nn.Conv2d(channels, channels, k, padding=p)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "        self.act2 = nn.SiLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.act1(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out = out + identity\n",
        "        return self.act2(out)\n",
        "\n",
        "class AudioFeatureModel(nn.Module):\n",
        "    def __init__(self, n_targets):\n",
        "        super().__init__()\n",
        "        C = [32, 64, 128, 256, 512]\n",
        "\n",
        "        self.stem = ConvBlock(1, C[0], (3,7))\n",
        "        self.res_stem = ResidualBlock(C[0], (3,3))\n",
        "\n",
        "        self.b1 = ConvBlock(C[0], C[1], (3,5))\n",
        "        self.res1 = ResidualBlock(C[1], (3,3))\n",
        "\n",
        "        self.b2 = ConvBlock(C[1], C[2], (3,5))\n",
        "        self.res2 = ResidualBlock(C[2], (3,3))\n",
        "\n",
        "        self.b3 = ConvBlock(C[2], C[3], (3,3))\n",
        "        self.res3 = ResidualBlock(C[3], (3,3))\n",
        "\n",
        "        self.b4 = ConvBlock(C[3], C[4], (3,3))\n",
        "        self.res4 = ResidualBlock(C[4], (3,3))\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(C[4], 256),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, n_targets),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.res_stem(x)\n",
        "\n",
        "        x = self.b1(x)\n",
        "        x = self.res1(x)\n",
        "\n",
        "        x = self.b2(x)\n",
        "        x = self.res2(x)\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "\n",
        "        x = self.b3(x)\n",
        "        x = self.res3(x)\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "\n",
        "        x = self.b4(x)\n",
        "        x = self.res4(x)\n",
        "\n",
        "        x = self.pool(x)\n",
        "        return self.head(x)\n",
        "\n",
        "# Load checkpoint\n",
        "def load_checkpoint_safe(path, device):\n",
        "    try:\n",
        "        return torch.load(path, map_location=device, weights_only=True)\n",
        "    except Exception:\n",
        "        try:\n",
        "            from torch.serialization import add_safe_globals\n",
        "            add_safe_globals([np._core.multiarray.scalar, np.dtype])\n",
        "            return torch.load(path, map_location=device, weights_only=True)\n",
        "        except Exception:\n",
        "            return torch.load(path, map_location=device, weights_only=False)\n",
        "\n",
        "checkpoint = load_checkpoint_safe(ckpt_path, device)\n",
        "state = checkpoint.get(\"model_state_dict\", checkpoint)\n",
        "TARGETS = checkpoint.get(\"targets\", [])\n",
        "cfg = checkpoint.get(\"config\", {})\n",
        "\n",
        "MEL_BINS = int(cfg.get(\"mel_bins\", 128))\n",
        "FRAMES = int(cfg.get(\"frames\", 768))\n",
        "\n",
        "model = AudioFeatureModel(n_targets=len(TARGETS)).to(device)\n",
        "model.load_state_dict(state)\n",
        "model.eval()\n",
        "\n",
        "print(f\"✓ Model loaded: {len(TARGETS)} targets\")\n",
        "print(f\"  Targets: {TARGETS}\")\n",
        "\n",
        "# ======================== LOAD VALIDATION DATA ========================\n",
        "\n",
        "print(\"\\n[2/6] Loading validation data...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "df = pd.read_parquet(val_data_path)\n",
        "\n",
        "# Split into train/val (use same seed as training)\n",
        "np.random.seed(2025)\n",
        "idx = np.arange(len(df))\n",
        "np.random.shuffle(idx)\n",
        "val_split = 0.15\n",
        "cut = int(len(idx) * (1 - val_split))\n",
        "val_idx = idx[cut:]\n",
        "\n",
        "df_val = df.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "# Filter: must have feature_path and all targets\n",
        "has_features = df_val['feature_path'].notna()\n",
        "has_all_targets = df_val[TARGETS].notna().all(axis=1)\n",
        "df_val = df_val[has_features & has_all_targets].copy()\n",
        "\n",
        "print(f\"✓ Validation samples: {len(df_val):,}\")\n",
        "\n",
        "# ======================== AUDIO PROCESSING ========================\n",
        "\n",
        "print(\"\\n[3/6] Setting up audio processing...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "import librosa\n",
        "\n",
        "SAMPLE_RATE = 16000\n",
        "N_FFT = 2048\n",
        "HOP_LENGTH = 512\n",
        "\n",
        "def make_logmel(audio_path, sr=SAMPLE_RATE):\n",
        "    try:\n",
        "        y, _ = librosa.load(audio_path, sr=sr, mono=True)\n",
        "\n",
        "        S = librosa.feature.melspectrogram(\n",
        "            y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH,\n",
        "            n_mels=MEL_BINS, power=2.0\n",
        "        )\n",
        "        S_db = librosa.power_to_db(S, ref=np.max)\n",
        "\n",
        "        T = S_db.shape[1]\n",
        "        if T >= FRAMES:\n",
        "            start = max(0, (T - FRAMES)//2)\n",
        "            S_db = S_db[:, start:start+FRAMES]\n",
        "        else:\n",
        "            pad = FRAMES - T\n",
        "            S_db = np.pad(S_db, ((0,0),(pad//2, pad - pad//2)), mode=\"edge\")\n",
        "\n",
        "        m = float(np.mean(S_db))\n",
        "        s = float(np.std(S_db))\n",
        "        if not np.isfinite(s) or s < 1e-6:\n",
        "            s = 1.0\n",
        "        Z = (S_db - m) / s\n",
        "        np.clip(Z, -10, 10, out=Z)\n",
        "\n",
        "        return torch.from_numpy(Z.astype(np.float32)).unsqueeze(0).unsqueeze(0)\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "print(\"✓ Audio processing ready\")\n",
        "\n",
        "# ======================== MAKE PREDICTIONS ========================\n",
        "\n",
        "print(\"\\n[4/6] Making predictions on validation set...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "predictions = []\n",
        "ground_truth = []\n",
        "failed = 0\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "for idx, row in tqdm(df_val.iterrows(), total=len(df_val), desc=\"Predicting\"):\n",
        "    audio_path = row['feature_path']\n",
        "\n",
        "    # Load audio and predict\n",
        "    x = make_logmel(audio_path)\n",
        "    if x is None:\n",
        "        failed += 1\n",
        "        continue\n",
        "\n",
        "    with torch.no_grad():\n",
        "        x = x.to(device)\n",
        "        pred = model(x).cpu().numpy()[0]\n",
        "\n",
        "    predictions.append(pred)\n",
        "    ground_truth.append([row[t] for t in TARGETS])\n",
        "\n",
        "predictions = np.array(predictions)\n",
        "ground_truth = np.array(ground_truth)\n",
        "\n",
        "print(f\"\\n✓ Predictions: {len(predictions):,} samples\")\n",
        "print(f\"✗ Failed: {failed} samples\")\n",
        "\n",
        "# ======================== COMPUTE METRICS ========================\n",
        "\n",
        "print(\"\\n[5/6] Computing metrics...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Feature name mapping\n",
        "FEATURE_NAMES = {\n",
        "    'danceability_norm': 'Danceability',\n",
        "    'energy_norm': 'Energy',\n",
        "    'loudness_norm': 'Loudness',\n",
        "    'speechiness_norm': 'Speechiness',\n",
        "    'acousticness_norm': 'Acousticness',\n",
        "    'instrumentalness_norm': 'Instrumentalness',\n",
        "    'liveness_norm': 'Liveness',\n",
        "    'valence_norm': 'Valence',\n",
        "    'tempo_norm': 'Tempo',\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"REGRESSION METRICS (Per Feature)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for i, target in enumerate(TARGETS):\n",
        "    y_true = ground_truth[:, i]\n",
        "    y_pred = predictions[:, i]\n",
        "\n",
        "    # Regression metrics\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    # Correlation\n",
        "    pearson_r, pearson_p = pearsonr(y_true, y_pred)\n",
        "    spearman_r, spearman_p = spearmanr(y_true, y_pred)\n",
        "\n",
        "    # Custom: Within-tolerance accuracy\n",
        "    tolerance_5 = np.mean(np.abs(y_true - y_pred) < 0.05)\n",
        "    tolerance_10 = np.mean(np.abs(y_true - y_pred) < 0.10)\n",
        "    tolerance_15 = np.mean(np.abs(y_true - y_pred) < 0.15)\n",
        "\n",
        "    results[target] = {\n",
        "        'mse': mse,\n",
        "        'rmse': rmse,\n",
        "        'mae': mae,\n",
        "        'r2': r2,\n",
        "        'pearson_r': pearson_r,\n",
        "        'spearman_r': spearman_r,\n",
        "        'within_5%': tolerance_5,\n",
        "        'within_10%': tolerance_10,\n",
        "        'within_15%': tolerance_15,\n",
        "    }\n",
        "\n",
        "    nice_name = FEATURE_NAMES.get(target, target)\n",
        "\n",
        "    print(f\"\\n{nice_name}:\")\n",
        "    print(f\"  RMSE:  {rmse:.4f}  (lower is better)\")\n",
        "    print(f\"  MAE:   {mae:.4f}  (lower is better)\")\n",
        "    print(f\"  R²:    {r2:.4f}  (higher is better, max=1.0)\")\n",
        "    print(f\"  Pearson r:  {pearson_r:.4f}\")\n",
        "    print(f\"  Spearman r: {spearman_r:.4f}\")\n",
        "    print(f\"  Within ±0.05: {tolerance_5*100:.1f}%\")\n",
        "    print(f\"  Within ±0.10: {tolerance_10*100:.1f}%\")\n",
        "    print(f\"  Within ±0.15: {tolerance_15*100:.1f}%\")\n",
        "\n",
        "# Overall metrics\n",
        "overall_mse = mean_squared_error(ground_truth.flatten(), predictions.flatten())\n",
        "overall_rmse = np.sqrt(overall_mse)\n",
        "overall_mae = mean_absolute_error(ground_truth.flatten(), predictions.flatten())\n",
        "overall_r2 = r2_score(ground_truth.flatten(), predictions.flatten())\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"OVERALL METRICS (All Features)\")\n",
        "print(\"=\"*70)\n",
        "print(f\"RMSE:  {overall_rmse:.4f}\")\n",
        "print(f\"MAE:   {overall_mae:.4f}\")\n",
        "print(f\"R²:    {overall_r2:.4f}\")\n",
        "\n",
        "# ======================== CLASSIFICATION METRICS ========================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CLASSIFICATION METRICS (Discretized)\")\n",
        "print(\"=\"*70)\n",
        "print(\"(Binning: Low=0-0.33, Medium=0.33-0.67, High=0.67-1.0)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "def discretize(values):\n",
        "    \"\"\"Convert continuous 0-1 to Low/Medium/High\"\"\"\n",
        "    return np.select(\n",
        "        [values < 0.33, values < 0.67],\n",
        "        [0, 1],  # 0=Low, 1=Medium, 2=High\n",
        "        default=2\n",
        "    )\n",
        "\n",
        "for i, target in enumerate(TARGETS):\n",
        "    y_true = ground_truth[:, i]\n",
        "    y_pred = predictions[:, i]\n",
        "\n",
        "    y_true_class = discretize(y_true)\n",
        "    y_pred_class = discretize(y_pred)\n",
        "\n",
        "    # Classification metrics\n",
        "    accuracy = accuracy_score(y_true_class, y_pred_class)\n",
        "    precision = precision_score(y_true_class, y_pred_class, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_true_class, y_pred_class, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_true_class, y_pred_class, average='weighted', zero_division=0)\n",
        "\n",
        "    nice_name = FEATURE_NAMES.get(target, target)\n",
        "\n",
        "    print(f\"\\n{nice_name}:\")\n",
        "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Recall:    {recall:.4f}\")\n",
        "    print(f\"  F1-Score:  {f1:.4f}\")\n",
        "\n",
        "# Overall classification metrics\n",
        "y_true_all_class = discretize(ground_truth.flatten())\n",
        "y_pred_all_class = discretize(predictions.flatten())\n",
        "\n",
        "overall_accuracy = accuracy_score(y_true_all_class, y_pred_all_class)\n",
        "overall_precision = precision_score(y_true_all_class, y_pred_all_class, average='weighted')\n",
        "overall_recall = recall_score(y_true_all_class, y_pred_all_class, average='weighted')\n",
        "overall_f1 = f1_score(y_true_all_class, y_pred_all_class, average='weighted')\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"OVERALL CLASSIFICATION METRICS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Accuracy:  {overall_accuracy:.4f}\")\n",
        "print(f\"Precision: {overall_precision:.4f}\")\n",
        "print(f\"Recall:    {overall_recall:.4f}\")\n",
        "print(f\"F1-Score:  {overall_f1:.4f}\")\n",
        "\n",
        "# ======================== VISUALIZATIONS ========================\n",
        "\n",
        "print(\"\\n[6/6] Creating visualizations...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create figure with subplots\n",
        "n_features = len(TARGETS)\n",
        "n_cols = 3\n",
        "n_rows = (n_features + n_cols - 1) // n_cols\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
        "axes = axes.flatten() if n_rows > 1 else [axes]\n",
        "\n",
        "for i, target in enumerate(TARGETS):\n",
        "    y_true = ground_truth[:, i]\n",
        "    y_pred = predictions[:, i]\n",
        "\n",
        "    ax = axes[i]\n",
        "\n",
        "    # Scatter plot with regression line\n",
        "    ax.scatter(y_true, y_pred, alpha=0.3, s=10)\n",
        "    ax.plot([0, 1], [0, 1], 'r--', linewidth=2, label='Perfect prediction')\n",
        "\n",
        "    # Add trend line\n",
        "    z = np.polyfit(y_true, y_pred, 1)\n",
        "    p = np.poly1d(z)\n",
        "    ax.plot([0, 1], p([0, 1]), \"b-\", linewidth=2, alpha=0.5, label=f'Trend')\n",
        "\n",
        "    nice_name = FEATURE_NAMES.get(target, target)\n",
        "    r2 = results[target]['r2']\n",
        "    mae = results[target]['mae']\n",
        "\n",
        "    ax.set_xlabel('True Value')\n",
        "    ax.set_ylabel('Predicted Value')\n",
        "    ax.set_title(f'{nice_name}\\nR²={r2:.3f}, MAE={mae:.3f}')\n",
        "    ax.legend(fontsize=8)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.set_xlim(-0.05, 1.05)\n",
        "    ax.set_ylim(-0.05, 1.05)\n",
        "\n",
        "# Hide extra subplots\n",
        "for i in range(n_features, len(axes)):\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plot_path = MODEL_DIR / \"validation_scatter_plots.png\"\n",
        "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
        "print(f\"✓ Saved scatter plots: {plot_path}\")\n",
        "plt.close()\n",
        "\n",
        "# ======================== ERROR ANALYSIS ========================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ERROR ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "errors = np.abs(ground_truth - predictions)\n",
        "\n",
        "print(\"\\nWorst predictions by feature:\")\n",
        "for i, target in enumerate(TARGETS):\n",
        "    nice_name = FEATURE_NAMES.get(target, target)\n",
        "    max_error = errors[:, i].max()\n",
        "    mean_error = errors[:, i].mean()\n",
        "    median_error = np.median(errors[:, i])\n",
        "\n",
        "    print(f\"\\n{nice_name}:\")\n",
        "    print(f\"  Mean error:   {mean_error:.4f}\")\n",
        "    print(f\"  Median error: {median_error:.4f}\")\n",
        "    print(f\"  Max error:    {max_error:.4f}\")\n",
        "\n",
        "    # Find worst prediction\n",
        "    worst_idx = errors[:, i].argmax()\n",
        "    print(f\"  Worst case:\")\n",
        "    print(f\"    True:  {ground_truth[worst_idx, i]:.3f}\")\n",
        "    print(f\"    Pred:  {predictions[worst_idx, i]:.3f}\")\n",
        "    print(f\"    Error: {errors[worst_idx, i]:.3f}\")\n",
        "\n",
        "# ======================== SAVE RESULTS ========================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SAVING RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save metrics to CSV\n",
        "metrics_df = pd.DataFrame(results).T\n",
        "metrics_df.index.name = 'feature'\n",
        "metrics_csv_path = MODEL_DIR / \"validation_metrics.csv\"\n",
        "metrics_df.to_csv(metrics_csv_path)\n",
        "print(f\"✓ Saved metrics: {metrics_csv_path}\")\n",
        "\n",
        "# Save detailed results\n",
        "detailed_results = {\n",
        "    'predictions': predictions.tolist(),\n",
        "    'ground_truth': ground_truth.tolist(),\n",
        "    'targets': TARGETS,\n",
        "    'overall_metrics': {\n",
        "        'rmse': float(overall_rmse),\n",
        "        'mae': float(overall_mae),\n",
        "        'r2': float(overall_r2),\n",
        "        'accuracy': float(overall_accuracy),\n",
        "        'precision': float(overall_precision),\n",
        "        'recall': float(overall_recall),\n",
        "        'f1_score': float(overall_f1),\n",
        "    },\n",
        "    'per_feature_metrics': {\n",
        "        target: {k: float(v) for k, v in metrics.items()}\n",
        "        for target, metrics in results.items()\n",
        "    }\n",
        "}\n",
        "\n",
        "import json\n",
        "results_json_path = MODEL_DIR / \"validation_results.json\"\n",
        "with open(results_json_path, 'w') as f:\n",
        "    json.dump(detailed_results, f, indent=2)\n",
        "print(f\"✓ Saved detailed results: {results_json_path}\")\n",
        "\n",
        "# ======================== SUMMARY ========================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"VALIDATION SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\n📊 Dataset:\")\n",
        "print(f\"  Validation samples: {len(predictions):,}\")\n",
        "print(f\"  Features evaluated: {len(TARGETS)}\")\n",
        "\n",
        "print(f\"\\n📈 Overall Performance:\")\n",
        "print(f\"  RMSE:      {overall_rmse:.4f}  {'✓ Excellent' if overall_rmse < 0.05 else '✓ Good' if overall_rmse < 0.10 else '⚠ Needs improvement'}\")\n",
        "print(f\"  MAE:       {overall_mae:.4f}  {'✓ Excellent' if overall_mae < 0.04 else '✓ Good' if overall_mae < 0.08 else '⚠ Needs improvement'}\")\n",
        "print(f\"  R²:        {overall_r2:.4f}  {'✓ Excellent' if overall_r2 > 0.85 else '✓ Good' if overall_r2 > 0.70 else '⚠ Needs improvement'}\")\n",
        "print(f\"  F1-Score:  {overall_f1:.4f}  {'✓ Excellent' if overall_f1 > 0.85 else '✓ Good' if overall_f1 > 0.70 else '⚠ Needs improvement'}\")\n",
        "\n",
        "print(f\"\\n🎯 Best Performing Features (by R²):\")\n",
        "sorted_features = sorted(results.items(), key=lambda x: x[1]['r2'], reverse=True)\n",
        "for target, metrics in sorted_features[:3]:\n",
        "    nice_name = FEATURE_NAMES.get(target, target)\n",
        "    print(f\"  {nice_name}: R²={metrics['r2']:.4f}, MAE={metrics['mae']:.4f}\")\n",
        "\n",
        "print(f\"\\n⚠️ Needs Improvement (by R²):\")\n",
        "for target, metrics in sorted_features[-3:]:\n",
        "    nice_name = FEATURE_NAMES.get(target, target)\n",
        "    print(f\"  {nice_name}: R²={metrics['r2']:.4f}, MAE={metrics['mae']:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ VALIDATION COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nFiles saved:\")\n",
        "print(f\"  • Metrics CSV: {metrics_csv_path}\")\n",
        "print(f\"  • Results JSON: {results_json_path}\")\n",
        "print(f\"  • Scatter plots: {plot_path}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx1RSd6mqVwW"
      },
      "source": [
        "below are old version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "9sfuWMng9802",
        "outputId": "53768c7a-1518-481a-a887-ca5d61e31405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CELL 6 — Fast, Robust Trainer\n",
            "======================================================================\n",
            "Using master: /content/models/run_01/META_master_postenrich.parquet\n",
            "✓ Loaded 9,565 master rows\n",
            "✓ Targets: ['user_engagement_signal', 'platform_quality_signal', 'quality_final']\n",
            "✓ Train: 8,130 | Val: 1,435\n",
            "\n",
            "Creating train/val datasets (fast & robust)…\n",
            "✓ Train batches: 169 | Val batches: 30\n",
            "\n",
            "Training…\n",
            "======================================================================\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2185017733.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mbatch_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmake_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# fresh shuffles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_dev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1492\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# CELL 6 — Fast, Robust Trainer (prefetch_factor-safe + autosave)\n",
        "# ================================================================\n",
        "import os, time, json, random, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Optional, Tuple, List\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.amp import GradScaler, autocast\n",
        "\n",
        "# ---------- Paths / Config ----------\n",
        "OUTDIR = Path(\"/content/models/run_01\"); OUTDIR.mkdir(parents=True, exist_ok=True)\n",
        "with open(OUTDIR / \"config.json\", \"r\") as f: config = json.load(f)\n",
        "\n",
        "master_file = Path(config.get(\"master_file\", OUTDIR / \"META_training_ready.parquet\"))\n",
        "if not master_file.exists() and (OUTDIR / \"META_training_ready.parquet\").exists():\n",
        "    master_file = OUTDIR / \"META_training_ready.parquet\"\n",
        "\n",
        "print(\"=\"*70); print(\"CELL 6 — Fast, Robust Trainer\"); print(\"=\"*70)\n",
        "print(f\"Using master: {master_file}\")\n",
        "\n",
        "# ---------- Hyperparams ----------\n",
        "MEL_BINS  = 128\n",
        "FRAMES    = 768\n",
        "VAL_SPLIT = 0.15\n",
        "BATCH_SIZE = 48\n",
        "EPOCHS     = 30\n",
        "LR, WD     = 1e-3, 1e-4\n",
        "MAX_GRAD_NORM = 1.0\n",
        "SEED = 2025\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE   = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "AMP_EN   = USE_CUDA\n",
        "\n",
        "if USE_CUDA:\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "if USE_CUDA: torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# ---------- Load data ----------\n",
        "df = pd.read_parquet(master_file)\n",
        "print(f\"✓ Loaded {len(df):,} master rows\")\n",
        "\n",
        "# prefer signals, else counts\n",
        "CAND_SETS = [\n",
        "    [\"user_engagement_signal\",\"platform_quality_signal\",\"quality_final\"],\n",
        "    [\"views\",\"likes\",\"comments\"],\n",
        "]\n",
        "for cand in CAND_SETS:\n",
        "    if all(c in df.columns for c in cand):\n",
        "        TARGETS = cand; break\n",
        "else:\n",
        "    raise RuntimeError(\"No valid target set in master file.\")\n",
        "print(f\"✓ Targets: {TARGETS}\")\n",
        "\n",
        "idx = np.arange(len(df)); np.random.shuffle(idx)\n",
        "cut = int(len(idx)*(1-VAL_SPLIT))\n",
        "df_train, df_val = df.iloc[idx[:cut]].reset_index(drop=True), df.iloc[idx[cut:]].reset_index(drop=True)\n",
        "print(f\"✓ Train: {len(df_train):,} | Val: {len(df_val):,}\")\n",
        "\n",
        "target_stats = {t: {\"mean\": float(pd.to_numeric(df[t], errors=\"coerce\").mean()),\n",
        "                    \"std\" : float(pd.to_numeric(df[t], errors=\"coerce\").std() or 1.0)}\n",
        "                for t in TARGETS}\n",
        "\n",
        "# ---------- Feature loader ----------\n",
        "def _finite(arr): return np.isfinite(arr).all()\n",
        "\n",
        "def load_feature(fp: str, frames: int = FRAMES, center: bool = False) -> Optional[np.ndarray]:\n",
        "    try:\n",
        "        with np.load(fp, allow_pickle=False, mmap_mode=\"r\" if USE_CUDA else None) as z:\n",
        "            key = next((k for k in (\"logmel\",\"log_mel\",\"mel\",\"features\",\"x\",\"S\") if k in z.files), None)\n",
        "            if key is None:\n",
        "                return None\n",
        "            x = z[key]\n",
        "\n",
        "        # Squeeze and orient to [F, T]\n",
        "        if x.ndim == 3:\n",
        "            x = x.squeeze()\n",
        "        if x.ndim != 2:\n",
        "            return None\n",
        "        if x.shape[0] != MEL_BINS and x.shape[1] == MEL_BINS:\n",
        "            x = x.T\n",
        "        if x.shape[0] != MEL_BINS:\n",
        "            return None\n",
        "\n",
        "        # --- Key changes start here ---\n",
        "        # Force a safe float dtype before any magnitude checks\n",
        "        if x.dtype != np.float32:\n",
        "            x = x.astype(np.float32, copy=False)\n",
        "\n",
        "        # Fast finite check first\n",
        "        if not np.isfinite(x).all():\n",
        "            return None\n",
        "\n",
        "        # Suppress noisy overflow warnings during the magnitude guard\n",
        "        with np.errstate(over=\"ignore\", invalid=\"ignore\"):\n",
        "            mx = np.nanmax(np.abs(x))\n",
        "        if not np.isfinite(mx) or mx > 1e6:\n",
        "            return None\n",
        "        # --- Key changes end here ---\n",
        "\n",
        "        # Center/Random crop or pad to FRAMES\n",
        "        T = x.shape[1]\n",
        "        if T >= frames:\n",
        "            start = (T - frames)//2 if center else np.random.randint(0, T - frames + 1)\n",
        "            x = x[:, start:start+frames]\n",
        "        else:\n",
        "            pad = frames - T\n",
        "            x = np.pad(x, ((0,0), (pad//2, pad - pad//2)), mode=\"constant\")\n",
        "\n",
        "        # Robust winsorize + standardize\n",
        "        lo, hi = np.percentile(x, [0.5, 99.5]).astype(np.float32)\n",
        "        x = np.clip(x, lo, hi)\n",
        "\n",
        "        m = float(np.mean(x, dtype=np.float64))\n",
        "        s = float(np.std(x,  dtype=np.float64))\n",
        "        if not np.isfinite(s) or s < 1e-6:\n",
        "            return None\n",
        "        x = (x - m) / s\n",
        "        x = np.clip(x, -10, 10)\n",
        "\n",
        "        if not np.isfinite(x).all():\n",
        "            return None\n",
        "\n",
        "        # [C=1, F, T]\n",
        "        return x.astype(np.float32, copy=False)[None, ...]\n",
        "\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "class FastAudioDS(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, targets: List[str], center: bool = False):\n",
        "        self.df = df.reset_index(drop=True); self.targets = targets; self.center = center\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i: int) -> Optional[Tuple[torch.Tensor, torch.Tensor]]:\n",
        "        r = self.df.iloc[i]\n",
        "        x = load_feature(r[\"feature_path\"], center=self.center)\n",
        "        if x is None: return None\n",
        "        y = np.array([float(r[t]) for t in self.targets], dtype=np.float32)\n",
        "        if not np.isfinite(y).all(): return None\n",
        "        return torch.from_numpy(x), torch.from_numpy(y)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch = [b for b in batch if b is not None]\n",
        "    if not batch: return None\n",
        "    X, y = zip(*batch); return torch.stack(X,0), torch.stack(y,0)\n",
        "\n",
        "# ---------- DataLoader factory (fixes your error) ----------\n",
        "# If NUM_WORKERS == 0 -> DO NOT pass prefetch_factor/persistent_workers\n",
        "if not USE_CUDA:\n",
        "    BATCH_SIZE = min(BATCH_SIZE, 16)\n",
        "NUM_WORKERS = max(2, os.cpu_count()//2) if USE_CUDA else 0\n",
        "PIN = USE_CUDA\n",
        "\n",
        "def make_loader(dataset, shuffle, drop_last, workers=NUM_WORKERS):\n",
        "    kwargs = dict(batch_size=BATCH_SIZE, shuffle=shuffle, num_workers=workers,\n",
        "                  pin_memory=PIN, collate_fn=collate_fn, drop_last=drop_last)\n",
        "    if workers > 0:\n",
        "        kwargs.update(dict(persistent_workers=True, prefetch_factor=4))\n",
        "    return DataLoader(dataset, **kwargs)\n",
        "\n",
        "print(\"\\nCreating train/val datasets (fast & robust)…\")\n",
        "train_ds = FastAudioDS(df_train, TARGETS, center=False)\n",
        "val_ds   = FastAudioDS(df_val,   TARGETS, center=True)\n",
        "\n",
        "train_loader = make_loader(train_ds, shuffle=True,  drop_last=True)\n",
        "val_loader   = make_loader(val_ds,   shuffle=False, drop_last=False)\n",
        "print(f\"✓ Train batches: {len(train_loader)} | Val batches: {len(val_loader)}\")\n",
        "\n",
        "# ---------- Model ----------\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, cin, cout, k=(3,7), s=(1,1), p=None):\n",
        "        super().__init__()\n",
        "        p = p or (k[0]//2, k[1]//2)\n",
        "        self.conv = nn.Conv2d(cin, cout, k, s, p); self.bn = nn.BatchNorm2d(cout); self.act = nn.SiLU()\n",
        "    def forward(self, x): return self.act(self.bn(self.conv(x)))\n",
        "\n",
        "class MultiTaskModel(nn.Module):\n",
        "    def __init__(self, n_targets):\n",
        "        super().__init__()\n",
        "        C = [32, 64, 128, 256, 512]\n",
        "        self.stem = ConvBlock(1, C[0], (3,7))\n",
        "        self.b1   = ConvBlock(C[0], C[1], (3,5))\n",
        "        self.b2   = ConvBlock(C[1], C[2], (3,5))\n",
        "        self.b3   = ConvBlock(C[2], C[3], (3,3))\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.head = nn.Sequential(nn.Flatten(), nn.Linear(C[3], 256), nn.SiLU(), nn.Dropout(0.2), nn.Linear(256, n_targets))\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x); x = self.b1(x); x = nn.functional.max_pool2d(x, 2)\n",
        "        x = self.b2(x);  x = nn.functional.max_pool2d(x, 2)\n",
        "        x = self.b3(x);  x = self.pool(x)\n",
        "        return self.head(x)\n",
        "\n",
        "model = MultiTaskModel(n_targets=len(TARGETS)).to(DEVICE)\n",
        "if USE_CUDA: model = model.to(memory_format=torch.channels_last)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
        "criterion = nn.MSELoss()\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=3)\n",
        "scaler = GradScaler(device=\"cuda\") if AMP_EN else None\n",
        "\n",
        "def to_dev(X, y):\n",
        "    if USE_CUDA:\n",
        "        X = X.to(DEVICE, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "        y = y.to(DEVICE, non_blocking=True)\n",
        "    else:\n",
        "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "    return X, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate():\n",
        "    model.eval(); losses = []\n",
        "    for batch in val_loader:\n",
        "        if batch is None: continue\n",
        "        X, y = to_dev(*batch)\n",
        "        with autocast(device_type=\"cuda\", enabled=AMP_EN):\n",
        "            pred = model(X); loss = criterion(pred, y)\n",
        "        if torch.isfinite(loss): losses.append(loss.item())\n",
        "    return float(np.mean(losses)) if losses else float(\"inf\")\n",
        "\n",
        "# ---------- Train (auto-save best) ----------\n",
        "print(\"\\nTraining…\"); print(\"=\"*70)\n",
        "best_val, history = float(\"inf\"), []\n",
        "ckpt_path = OUTDIR / \"best_model_robust.pt\"\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    t0 = time.time(); model.train(); batch_losses = []\n",
        "    for batch in make_loader(train_ds, shuffle=True, drop_last=True):  # fresh shuffles\n",
        "        if batch is None: continue\n",
        "        X, y = to_dev(*batch)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if AMP_EN:\n",
        "            with autocast(device_type=\"cuda\", enabled=True):\n",
        "                pred = model(X); loss = criterion(pred, y)\n",
        "            if not torch.isfinite(loss): continue\n",
        "            scaler.scale(loss).backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
        "            scaler.step(optimizer); scaler.update()\n",
        "        else:\n",
        "            pred = model(X); loss = criterion(pred, y)\n",
        "            if not torch.isfinite(loss): continue\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
        "            optimizer.step()\n",
        "        batch_losses.append(loss.item())\n",
        "\n",
        "    train_loss = float(np.mean(batch_losses)) if batch_losses else float(\"inf\")\n",
        "    val_loss = evaluate(); scheduler.step(val_loss)\n",
        "    print(f\"Epoch {epoch:02d} | Train {train_loss:.4f} | Val {val_loss:.4f} | {time.time()-t0:.0f}s\")\n",
        "    history.append({\"epoch\": epoch, \"train_loss\": train_loss, \"val_loss\": val_loss})\n",
        "\n",
        "    if np.isfinite(val_loss) and val_loss < best_val:\n",
        "        best_val = val_loss\n",
        "        state = {k: v.detach().cpu() for k,v in model.state_dict().items()}\n",
        "        torch.save({\n",
        "            \"model_state_dict\": state,\n",
        "            \"targets\": TARGETS,\n",
        "            \"target_stats\": target_stats,\n",
        "            \"best_val_loss\": best_val,\n",
        "            \"epoch\": epoch,\n",
        "            \"config\": {\"mel_bins\": MEL_BINS, \"frames\": FRAMES,\n",
        "                       \"batch_size\": BATCH_SIZE, \"lr\": LR, \"weight_decay\": WD}\n",
        "        }, ckpt_path)\n",
        "        print(f\"  ✓ New best {best_val:.4f} — saved to {ckpt_path}\")\n",
        "\n",
        "# Save history + update config\n",
        "pd.DataFrame(history).to_csv(OUTDIR / \"training_history_robust.csv\", index=False)\n",
        "config.update({\n",
        "    \"best_val_loss\": best_val,\n",
        "    \"targets\": TARGETS,\n",
        "    \"target_stats\": target_stats,\n",
        "    \"checkpoint_path\": str(ckpt_path),\n",
        "})\n",
        "with open(OUTDIR / \"config.json\", \"w\") as f: json.dump(config, f, indent=2)\n",
        "\n",
        "print(\"\\n✅ Training complete\")\n",
        "print(f\"Best val loss: {best_val:.4f}\")\n",
        "print(f\"Best model: {ckpt_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA8umv1Sncfs",
        "outputId": "b82fcb33-ec3b-4199-93c3-2def3cf63bcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target statistics:\n",
            "\n",
            "user_engagement_signal:\n",
            "count    9.565000e+03\n",
            "mean     9.571639e-09\n",
            "std      1.000001e+00\n",
            "min     -4.611747e-01\n",
            "25%     -3.681757e-01\n",
            "50%     -2.923262e-01\n",
            "75%     -1.100938e-01\n",
            "max      4.270350e+00\n",
            "Name: user_engagement_signal, dtype: float64\n",
            "\n",
            "platform_quality_signal:\n",
            "count    9.565000e+03\n",
            "mean    -6.381093e-09\n",
            "std      1.000001e+00\n",
            "min     -2.991015e+00\n",
            "25%     -4.720244e-01\n",
            "50%      1.550676e-01\n",
            "75%      7.101693e-01\n",
            "max      1.763698e+00\n",
            "Name: platform_quality_signal, dtype: float64\n",
            "\n",
            "quality_final:\n",
            "count    9.565000e+03\n",
            "mean     3.988183e-09\n",
            "std      4.167075e-01\n",
            "min     -1.336446e+00\n",
            "25%     -2.801811e-01\n",
            "50%     -7.660054e-03\n",
            "75%      2.961998e-01\n",
            "max      1.284194e+00\n",
            "Name: quality_final, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# In a new cell:\n",
        "import pandas as pd\n",
        "df = pd.read_parquet(\"/content/models/run_01/META_master_postenrich.parquet\")\n",
        "\n",
        "print(\"Target statistics:\")\n",
        "for col in ['user_engagement_signal', 'platform_quality_signal', 'quality_final']:\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(df[col].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFjbZO7iCD6w",
        "outputId": "9a352d39-c38a-43ad-feab-351be09abdb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing these files:\n",
            "  1. ✓ Adele_-_Hello_Original_-_yana_enik_(mp3.pm) (.mp3 6.7 MB)\n",
            "  2. ✓ DJ_Smash_feat._Ridley_-_The_Night_Is_Young_(mp3.pm) (.mp3 6.7 MB)\n",
            "  3. ✓ 《孤勇者》（《英雄聯盟：雙城之戰》動畫劇集中文主題曲）陳奕迅 Eason Chan [Official MV] (.mp3 4.2 MB)\n",
            "\n",
            "[1/4] Loading checkpoint...\n",
            "✓ Checkpoint loaded\n",
            "  Targets: ['user_engagement_signal', 'platform_quality_signal', 'quality_final']\n",
            "  MEL_BINS: 128, FRAMES: 768\n",
            "\n",
            "[DEBUG] Sample checkpoint keys: ['stem.conv.weight', 'stem.conv.bias', 'stem.bn.weight', 'stem.bn.bias', 'stem.bn.running_mean', 'stem.bn.running_var', 'stem.bn.num_batches_tracked', 'b1.conv.weight', 'b1.conv.bias', 'b1.bn.weight', 'b1.bn.bias', 'b1.bn.running_mean', 'b1.bn.running_var', 'b1.bn.num_batches_tracked', 'b2.conv.weight']\n",
            "[arch] ✓ Detected Cell 6 MultiTaskModel (stem.* + head.*)\n",
            "✓ Model loaded: MultiTaskModel on cuda\n",
            "\n",
            "[2/4] Setting up audio processing...\n",
            "✓ Audio processing ready\n",
            "\n",
            "[3/4] Predicting quality for your songs...\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "SONG 1: Adele_-_Hello_Original_-_yana_enik_(mp3.pm)\n",
            "======================================================================\n",
            "  ✓ Loaded via: librosa\n",
            "\n",
            "USER ENGAGEMENT SIGNAL:\n",
            "  Predicted:  -0.052\n",
            "\n",
            "PLATFORM QUALITY SIGNAL:\n",
            "  Predicted:   0.077\n",
            "\n",
            "QUALITY FINAL:\n",
            "  Predicted:   0.037\n",
            "\n",
            "======================================================================\n",
            "SONG 2: DJ_Smash_feat._Ridley_-_The_Night_Is_Young_(mp3.pm)\n",
            "======================================================================\n",
            "  ✓ Loaded via: librosa\n",
            "\n",
            "USER ENGAGEMENT SIGNAL:\n",
            "  Predicted:  -0.166\n",
            "\n",
            "PLATFORM QUALITY SIGNAL:\n",
            "  Predicted:   0.221\n",
            "\n",
            "QUALITY FINAL:\n",
            "  Predicted:   0.079\n",
            "\n",
            "======================================================================\n",
            "SONG 3: 《孤勇者》（《英雄聯盟：雙城之戰》動畫劇集中文主題曲）陳奕迅 Eason Chan [Official MV]\n",
            "======================================================================\n",
            "  ✓ Loaded via: librosa\n",
            "\n",
            "USER ENGAGEMENT SIGNAL:\n",
            "  Predicted:  -0.010\n",
            "\n",
            "PLATFORM QUALITY SIGNAL:\n",
            "  Predicted:   0.041\n",
            "\n",
            "QUALITY FINAL:\n",
            "  Predicted:   0.027\n",
            "\n",
            "[4/4] Comparing your songs...\n",
            "======================================================================\n",
            "\n",
            "Song 1: Adele_-_Hello_Original_-_yana_enik_(mp3.pm)\n",
            "Song 2: DJ_Smash_feat._Ridley_-_The_Night_Is_Young_(mp3.pm)\n",
            "\n",
            "USER ENGAGEMENT SIGNAL:\n",
            "  Song 1:  -0.052\n",
            "  Song 2:  -0.166\n",
            "  Diff:     0.114\n",
            "\n",
            "PLATFORM QUALITY SIGNAL:\n",
            "  Song 1:   0.077\n",
            "  Song 2:   0.221\n",
            "  Diff:     0.144\n",
            "\n",
            "QUALITY FINAL:\n",
            "  Song 1:   0.037\n",
            "  Song 2:   0.079\n",
            "  Diff:     0.041\n",
            "\n",
            "======================================================================\n",
            "AVERAGE DIFFERENCE: 0.100\n",
            "\n",
            "✓ Results saved: /content/drive/MyDrive/STA 160/models/run_01/custom_songs_test.json\n",
            "\n",
            "======================================================================\n",
            "✅ EVALUATION COMPLETE!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ======================================================================\n",
        "# CELL 8.5 — Model loader (FIXED to match Cell 6 architecture)\n",
        "# ======================================================================\n",
        "from pathlib import Path\n",
        "import torch, torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# --------------------------- discover test audio ---------------------------\n",
        "DRIVE_FOLDER = Path(\"/content/drive/MyDrive/STA 160/test\")\n",
        "candidates = sorted(\n",
        "    [*DRIVE_FOLDER.glob(\"*.mp3\"), *DRIVE_FOLDER.glob(\"*.wav\"),\n",
        "     *DRIVE_FOLDER.glob(\"*.m4a\"), *DRIVE_FOLDER.glob(\"*.flac\"),\n",
        "     *DRIVE_FOLDER.glob(\"*.ogg\")]\n",
        ")\n",
        "test_files = [p for p in candidates if not p.name.endswith(\".crdownload\") and p.stat().st_size > 0]\n",
        "song_names = [p.stem[:80] for p in test_files]\n",
        "\n",
        "print(\"Testing these files:\")\n",
        "for i, (p, name) in enumerate(zip(test_files, song_names), 1):\n",
        "    print(f\"  {i}. ✓ {name} ({p.suffix.lower()} {p.stat().st_size/1_048_576:.1f} MB)\")\n",
        "\n",
        "assert len(test_files) >= 2, (\n",
        "    \"Need at least 2 finalized audio files in /STA 160/test folder.\"\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "ckpt_path = Path(\"/content/models/run_01/best_model_robust.pt\")\n",
        "\n",
        "# =============== MODEL ARCHITECTURES (including Cell 6's MultiTaskModel) ===============\n",
        "\n",
        "# --- Cell 6 Architecture (THE ONE YOU ACTUALLY TRAINED) ---\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, cin, cout, k=(3,7), s=(1,1), p=None):\n",
        "        super().__init__()\n",
        "        p = p or (k[0]//2, k[1]//2)\n",
        "        self.conv = nn.Conv2d(cin, cout, k, s, p)\n",
        "        self.bn = nn.BatchNorm2d(cout)\n",
        "        self.act = nn.SiLU()\n",
        "    def forward(self, x):\n",
        "        return self.act(self.bn(self.conv(x)))\n",
        "\n",
        "class MultiTaskModel(nn.Module):\n",
        "    \"\"\"This is the EXACT architecture from Cell 6\"\"\"\n",
        "    def __init__(self, n_targets):\n",
        "        super().__init__()\n",
        "        C = [32, 64, 128, 192]\n",
        "        self.stem = ConvBlock(1, C[0], (3,7))\n",
        "        self.b1   = ConvBlock(C[0], C[1], (3,5))\n",
        "        self.b2   = ConvBlock(C[1], C[2], (3,5))\n",
        "        self.b3   = ConvBlock(C[2], C[3], (3,3))\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(C[3], 256),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, n_targets)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.b1(x)\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "        x = self.b2(x)\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "        x = self.b3(x)\n",
        "        x = self.pool(x)\n",
        "        return self.head(x)\n",
        "\n",
        "# --- Legacy architectures (keep for backwards compatibility) ---\n",
        "class LegacyConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, k=(3,3), p=(1,1)):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size=k, padding=p)\n",
        "        self.bn = nn.BatchNorm2d(out_ch)\n",
        "        self.act = nn.ReLU(inplace=True)\n",
        "    def forward(self, x):\n",
        "        return self.act(self.bn(self.conv(x)))\n",
        "\n",
        "class AudioBackbone(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.stem   = LegacyConvBlock(1,   32, (3,7), (1,3))\n",
        "        self.block1 = LegacyConvBlock(32,  64, (3,5), (1,2))\n",
        "        self.block2 = LegacyConvBlock(64, 128, (3,5), (1,2))\n",
        "        self.block3 = LegacyConvBlock(128,192, (3,3), (1,1))\n",
        "        self.pool   = nn.AdaptiveAvgPool2d((1,1))\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        return self.pool(x).flatten(1)\n",
        "\n",
        "class MultiTask_Backbone(nn.Module):\n",
        "    def __init__(self, n_targets):\n",
        "        super().__init__()\n",
        "        self.backbone = AudioBackbone()\n",
        "        self.heads = nn.ModuleList([\n",
        "            nn.Sequential(nn.Linear(192,128), nn.ReLU(True), nn.Dropout(0.3), nn.Linear(128,1))\n",
        "            for _ in range(n_targets)\n",
        "        ])\n",
        "    def forward(self, x):\n",
        "        f = self.backbone(x)\n",
        "        outs = [h(f).squeeze(1) for h in self.heads]\n",
        "        return torch.stack(outs, dim=1)\n",
        "\n",
        "# --------------------------- safe checkpoint load ---------------------------\n",
        "def load_checkpoint_safe(path, device):\n",
        "    \"\"\"Try weights_only=True, then allowlist numpy, finally fallback\"\"\"\n",
        "    try:\n",
        "        return torch.load(path, map_location=device, weights_only=True)\n",
        "    except Exception:\n",
        "        try:\n",
        "            from torch.serialization import add_safe_globals\n",
        "            add_safe_globals([np._core.multiarray.scalar, np.dtype])\n",
        "            return torch.load(path, map_location=device, weights_only=True)\n",
        "        except Exception:\n",
        "            print(\"[warn] Falling back to weights_only=False (trusted local checkpoint).\")\n",
        "            return torch.load(path, map_location=device, weights_only=False)\n",
        "\n",
        "# ---------- robust checkpoint extraction ----------\n",
        "def extract_state_targets_cfg(ckpt):\n",
        "    \"\"\"Return (state_dict, targets:list[str], cfg:dict)\"\"\"\n",
        "    if isinstance(ckpt, torch.nn.Module):\n",
        "        return ckpt.state_dict(), [\"quality_final\"], {}\n",
        "\n",
        "    if not isinstance(ckpt, dict):\n",
        "        raise RuntimeError(f\"Unsupported checkpoint type: {type(ckpt)}\")\n",
        "\n",
        "    # Find state dict\n",
        "    candidate_keys = [\n",
        "        \"model_state_dict\", \"state_dict\", \"ema_state_dict\",\n",
        "        \"model\", \"net\", \"weights\", \"params\"\n",
        "    ]\n",
        "    state = None\n",
        "    for k in candidate_keys:\n",
        "        v = ckpt.get(k)\n",
        "        if isinstance(v, dict) and all(isinstance(x, torch.Tensor) for x in v.values()):\n",
        "            state = v\n",
        "            break\n",
        "\n",
        "    if state is None and all(isinstance(v, torch.Tensor) for v in ckpt.values()):\n",
        "        state = ckpt\n",
        "\n",
        "    if state is None:\n",
        "        raise RuntimeError(\"Could not locate model state_dict in checkpoint.\")\n",
        "\n",
        "    # Strip common prefixes\n",
        "    STRIP_PREFIXES = (\"module.\", \"_orig_mod.\", \"model.\", \"net.\")\n",
        "    def _strip(k: str) -> str:\n",
        "        for p in STRIP_PREFIXES:\n",
        "            if k.startswith(p):\n",
        "                return k[len(p):]\n",
        "        return k\n",
        "    state = {_strip(k): v for k, v in state.items()}\n",
        "\n",
        "    targets = ckpt.get(\"targets\") or ckpt.get(\"target_names\") or [\"quality_final\"]\n",
        "    cfg = ckpt.get(\"config\") or ckpt.get(\"cfg\") or {}\n",
        "\n",
        "    return state, targets, cfg\n",
        "\n",
        "# ---------------------- Load checkpoint ----------------------\n",
        "print(\"\\n[1/4] Loading checkpoint...\")\n",
        "checkpoint = load_checkpoint_safe(ckpt_path, device)\n",
        "state, TARGETS, cfg = extract_state_targets_cfg(checkpoint)\n",
        "\n",
        "# Get config values\n",
        "DEFAULT_MEL_BINS = 128\n",
        "DEFAULT_FRAMES   = 768  # Cell 6 uses 768\n",
        "MEL_BINS = int(cfg.get(\"mel_bins\", DEFAULT_MEL_BINS))\n",
        "FRAMES   = int(cfg.get(\"frames\", DEFAULT_FRAMES))\n",
        "\n",
        "print(f\"✓ Checkpoint loaded\")\n",
        "print(f\"  Targets: {TARGETS}\")\n",
        "print(f\"  MEL_BINS: {MEL_BINS}, FRAMES: {FRAMES}\")\n",
        "\n",
        "# ---------------------- Detect architecture ----------------------\n",
        "def _has_prefix_keys(sdict, prefix: str) -> bool:\n",
        "    return any(k.startswith(prefix) for k in sdict.keys())\n",
        "\n",
        "_sample_keys = list(state.keys())[:15]\n",
        "print(f\"\\n[DEBUG] Sample checkpoint keys: {_sample_keys}\")\n",
        "\n",
        "# Architecture detection with Cell 6 support\n",
        "if _has_prefix_keys(state, \"stem.\") and _has_prefix_keys(state, \"head.\"):\n",
        "    print(\"[arch] ✓ Detected Cell 6 MultiTaskModel (stem.* + head.*)\")\n",
        "    model = MultiTaskModel(n_targets=len(TARGETS))\n",
        "    strict = True\n",
        "elif _has_prefix_keys(state, \"backbone.\"):\n",
        "    print(\"[arch] Detected MultiTask_Backbone\")\n",
        "    model = MultiTask_Backbone(n_targets=len(TARGETS))\n",
        "    strict = True\n",
        "else:\n",
        "    print(\"[arch] ⚠️ Unknown architecture, trying Cell 6 MultiTaskModel as fallback\")\n",
        "    model = MultiTaskModel(n_targets=len(TARGETS))\n",
        "    strict = False\n",
        "\n",
        "# Load weights\n",
        "missing, unexpected = model.load_state_dict(state, strict=strict)\n",
        "\n",
        "if missing:\n",
        "    print(f\"[warn] Missing keys ({len(missing)}): {missing[:5]}\")\n",
        "if unexpected:\n",
        "    print(f\"[warn] Unexpected keys ({len(unexpected)}): {unexpected[:5]}\")\n",
        "\n",
        "model.to(device).eval()\n",
        "print(f\"✓ Model loaded: {model.__class__.__name__} on {device}\")\n",
        "\n",
        "# ==================== AUDIO PROCESSING ====================\n",
        "print(\"\\n[2/4] Setting up audio processing...\")\n",
        "\n",
        "import librosa, tempfile, subprocess, os\n",
        "\n",
        "SAMPLE_RATE = 16000\n",
        "N_FFT = 2048\n",
        "HOP_LENGTH = 512\n",
        "\n",
        "def _convert_to_wav_ffmpeg(audio_path):\n",
        "    tmp = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
        "    tmp.close()\n",
        "    cmd = [\"ffmpeg\", \"-y\", \"-i\", str(audio_path), \"-ac\", \"1\", \"-ar\", str(SAMPLE_RATE), tmp.name]\n",
        "    try:\n",
        "        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)\n",
        "        return tmp.name\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        raise RuntimeError(f\"ffmpeg failed: {e}\") from e\n",
        "\n",
        "def safe_load_audio(path):\n",
        "    try:\n",
        "        y, sr = librosa.load(path, sr=SAMPLE_RATE, mono=True)\n",
        "        if y is None or len(y) == 0:\n",
        "            raise RuntimeError(\"empty audio\")\n",
        "        return y, sr, \"librosa\"\n",
        "    except Exception:\n",
        "        wav = None\n",
        "        try:\n",
        "            wav = _convert_to_wav_ffmpeg(path)\n",
        "            y, sr = librosa.load(wav, sr=SAMPLE_RATE, mono=True)\n",
        "            if y is None or len(y) == 0:\n",
        "                raise RuntimeError(\"empty audio after ffmpeg\")\n",
        "            return y, sr, \"ffmpeg->librosa\"\n",
        "        finally:\n",
        "            if wav and os.path.exists(wav):\n",
        "                try:\n",
        "                    os.unlink(wav)\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "def make_logmel(y, sr=SAMPLE_RATE):\n",
        "    S = librosa.feature.melspectrogram(\n",
        "        y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=MEL_BINS, power=2.0\n",
        "    )\n",
        "    S_db = librosa.power_to_db(S, ref=np.max)\n",
        "\n",
        "    # Crop/pad to FRAMES\n",
        "    T = S_db.shape[1]\n",
        "    if T >= FRAMES:\n",
        "        start = max(0, (T - FRAMES)//2)\n",
        "        S_db = S_db[:, start:start+FRAMES]\n",
        "    else:\n",
        "        pad = FRAMES - T\n",
        "        S_db = np.pad(S_db, ((0,0),(pad//2, pad - pad//2)), mode=\"edge\")\n",
        "\n",
        "    # Normalize\n",
        "    m = float(np.mean(S_db))\n",
        "    s = float(np.std(S_db))\n",
        "    if not np.isfinite(m) or not np.isfinite(s) or s < 1e-6:\n",
        "        s = 1.0\n",
        "    Z = (S_db - m) / s\n",
        "    np.clip(Z, -10, 10, out=Z)\n",
        "\n",
        "    if not np.isfinite(Z).all():\n",
        "        raise RuntimeError(\"non-finite after normalization\")\n",
        "\n",
        "    return torch.from_numpy(Z.astype(np.float32)).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "print(\"✓ Audio processing ready\")\n",
        "\n",
        "# ==================== PREDICT ====================\n",
        "print(\"\\n[3/4] Predicting quality for your songs...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_one(audio_path: Path):\n",
        "    y, sr, how = safe_load_audio(str(audio_path))\n",
        "    x = make_logmel(y, sr).to(device)\n",
        "    pred = model(x).cpu().numpy()[0]\n",
        "    return pred, how\n",
        "\n",
        "results = []\n",
        "errors  = []\n",
        "\n",
        "for i, (audio_file, nice_name) in enumerate(zip(test_files, song_names), 1):\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"SONG {i}: {nice_name}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    try:\n",
        "        pred, how = predict_one(audio_file)\n",
        "        print(f\"  ✓ Loaded via: {how}\")\n",
        "\n",
        "        for j, t in enumerate(TARGETS):\n",
        "            val = float(pred[j])\n",
        "            print(f\"\\n{t.upper().replace('_',' ')}:\\n  Predicted: {val:7.3f}\")\n",
        "\n",
        "        results.append({\n",
        "            \"song\": nice_name,\n",
        "            \"file\": audio_file.name,\n",
        "            \"pred\": pred.tolist()\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed: {audio_file.name} — {e}\")\n",
        "        errors.append((audio_file.name, str(e)))\n",
        "\n",
        "# ==================== COMPARE ====================\n",
        "print(\"\\n[4/4] Comparing your songs...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if len(results) >= 2:\n",
        "    a, b = results[0], results[1]\n",
        "    print(f\"\\nSong 1: {a['song']}\\nSong 2: {b['song']}\")\n",
        "\n",
        "    diffs = []\n",
        "    for j, t in enumerate(TARGETS):\n",
        "        v1, v2 = a[\"pred\"][j], b[\"pred\"][j]\n",
        "        diff = abs(v1 - v2)\n",
        "        diffs.append(diff)\n",
        "        print(f\"\\n{t.upper().replace('_',' ')}:\")\n",
        "        print(f\"  Song 1: {v1:7.3f}\")\n",
        "        print(f\"  Song 2: {v2:7.3f}\")\n",
        "        print(f\"  Diff:   {diff:7.3f}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"AVERAGE DIFFERENCE: {np.mean(diffs):.3f}\")\n",
        "\n",
        "elif len(results) == 1:\n",
        "    print(\"\\n⚠️ Only 1 song processed successfully — add another file for comparison.\")\n",
        "else:\n",
        "    print(\"\\n❌ No songs processed — see errors above.\")\n",
        "\n",
        "# Save results\n",
        "if results:\n",
        "    import json\n",
        "    outp = Path(\"/content/drive/MyDrive/STA 160/models/run_01/custom_songs_test.json\")\n",
        "    outp.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(outp, \"w\") as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    print(f\"\\n✓ Results saved: {outp}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✅ EVALUATION COMPLETE!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjieGbpBp8tp"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CELL 7: Save Model (FIXED - Saves Best Model)\n",
        "# ==============================================================================\n",
        "\n",
        "import json\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CELL 7: Save Best Model\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "OUTPUT_DIR = Path(\"/content/models/run_01\")\n",
        "\n",
        "# Load config\n",
        "with open(OUTPUT_DIR / \"config.json\", 'r') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "print(f\"\\n[1/3] Checking training status...\")\n",
        "\n",
        "# Check if training completed\n",
        "if 'best_val_loss' not in config:\n",
        "    print(\"⚠️  Warning: Training may not have completed\")\n",
        "    print(\"   Saving current model anyway...\")\n",
        "\n",
        "best_val_loss = config.get('best_val_loss', None)\n",
        "if best_val_loss:\n",
        "    print(f\"✓ Best validation loss: {best_val_loss:.4f}\")\n",
        "\n",
        "# Get targets and stats\n",
        "TARGETS = config.get('targets', ['user_engagement_signal', 'platform_quality_signal', 'quality_final'])\n",
        "target_stats = config.get('target_stats', {})\n",
        "\n",
        "print(f\"✓ Targets: {TARGETS}\")\n",
        "print(f\"✓ Target stats loaded: {len(target_stats)} targets\")\n",
        "\n",
        "# Check if model exists in memory\n",
        "if 'model' not in globals():\n",
        "    print(\"\\n⚠️  WARNING: Model not found in memory!\")\n",
        "    print(\"   Did Cell 6 (training) complete?\")\n",
        "    print(\"   You may need to re-run Cell 6 first.\")\n",
        "    raise NameError(\"Model not defined. Run Cell 6 first.\")\n",
        "\n",
        "print(f\"\\n[2/3] Creating checkpoint...\")\n",
        "\n",
        "# Create checkpoint\n",
        "checkpoint = {\n",
        "    # Model\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'model_architecture': 'MultiTaskModel',\n",
        "\n",
        "    # Targets\n",
        "    'targets': TARGETS,\n",
        "    'n_targets': len(TARGETS),\n",
        "\n",
        "    # Statistics (CRITICAL for denormalization!)\n",
        "    'target_stats': target_stats,\n",
        "\n",
        "    # Training info\n",
        "    'best_val_loss': best_val_loss,\n",
        "    'epochs_trained': config.get('epochs_trained', None),\n",
        "\n",
        "    # Configuration\n",
        "    'config': {\n",
        "        'mel_bins': 128,\n",
        "        'frames': 1024,\n",
        "        'batch_size': 32,\n",
        "        'learning_rate': 1e-3,\n",
        "        'seed': 2025\n",
        "    },\n",
        "\n",
        "    # Metadata\n",
        "    'training_samples': config.get('final_samples', len(target_stats) if target_stats else None),\n",
        "}\n",
        "\n",
        "print(\"✓ Checkpoint created\")\n",
        "print(f\"  Keys: {list(checkpoint.keys())}\")\n",
        "\n",
        "# Verify critical components\n",
        "critical_keys = ['model_state_dict', 'target_stats', 'targets']\n",
        "for key in critical_keys:\n",
        "    if key in checkpoint and checkpoint[key]:\n",
        "        print(f\"  ✓ {key}: present\")\n",
        "    else:\n",
        "        print(f\"  ⚠️  {key}: MISSING or empty!\")\n",
        "\n",
        "print(f\"\\n[3/3] Saving checkpoint...\")\n",
        "\n",
        "# Save\n",
        "checkpoint_path = OUTPUT_DIR / \"best_model.pt\"\n",
        "torch.save(checkpoint, checkpoint_path)\n",
        "\n",
        "file_size = checkpoint_path.stat().st_size / (1024 * 1024)\n",
        "print(f\"✓ Saved to: {checkpoint_path}\")\n",
        "print(f\"  File size: {file_size:.2f} MB\")\n",
        "\n",
        "if file_size < 0.5:\n",
        "    print(\"  ⚠️  Warning: File seems small, may be incomplete\")\n",
        "\n",
        "# Verify checkpoint can be loaded\n",
        "print(\"\\nVerifying checkpoint...\")\n",
        "try:\n",
        "    loaded = torch.load(checkpoint_path, map_location='cpu')\n",
        "    print(\"✓ Checkpoint can be loaded\")\n",
        "    print(f\"  Keys: {list(loaded.keys())}\")\n",
        "\n",
        "    if 'target_stats' in loaded:\n",
        "        print(f\"  ✓ target_stats: {len(loaded['target_stats'])} targets\")\n",
        "        for target, stats in loaded['target_stats'].items():\n",
        "            print(f\"    {target}: mean={stats['mean']:.4f}, std={stats['std']:.4f}\")\n",
        "\n",
        "    if 'model_state_dict' in loaded:\n",
        "        print(f\"  ✓ model_state_dict: {len(loaded['model_state_dict'])} parameters\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"  ✗ Verification failed: {e}\")\n",
        "    raise\n",
        "\n",
        "# Update config\n",
        "config['checkpoint_path'] = str(checkpoint_path)\n",
        "config['checkpoint_saved'] = True\n",
        "\n",
        "with open(OUTPUT_DIR / \"config.json\", 'w') as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL SAVED SUCCESSFULLY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Location:     {checkpoint_path}\")\n",
        "print(f\"Size:         {file_size:.2f} MB\")\n",
        "print(f\"Targets:      {TARGETS}\")\n",
        "print(f\"Best val loss: {best_val_loss if best_val_loss else 'N/A'}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n✅ Cell 7 Complete - Ready for Cell 8 (Testing)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26AC-8-KGk7x",
        "outputId": "f0ca405f-1e66-47f9-d13c-9957d4eb760f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❌ No training history found\n"
          ]
        }
      ],
      "source": [
        "# Check training history\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "OUTPUT_DIR = Path(\"/content/models/run_01\")\n",
        "history_file = OUTPUT_DIR / \"training_history.csv\"\n",
        "\n",
        "if history_file.exists():\n",
        "    history = pd.read_csv(history_file)\n",
        "\n",
        "    print(\"COMPLETE TRAINING HISTORY\")\n",
        "    print(\"=\"*70)\n",
        "    print(history.to_string(index=False))\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ANALYSIS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    best_epoch = history.loc[history['val_loss'].idxmin()]\n",
        "    last_epoch = history.iloc[-1]\n",
        "\n",
        "    print(f\"\\nBest Epoch: {int(best_epoch['epoch'])}\")\n",
        "    print(f\"  Train Loss: {best_epoch['train_loss']:.4f}\")\n",
        "    print(f\"  Val Loss:   {best_epoch['val_loss']:.4f}\")\n",
        "\n",
        "    print(f\"\\nLast Epoch: {int(last_epoch['epoch'])}\")\n",
        "    print(f\"  Train Loss: {last_epoch['train_loss']:.4f}\")\n",
        "    print(f\"  Val Loss:   {last_epoch['val_loss']:.4f}\")\n",
        "\n",
        "    print(f\"\\nSaved Model Val Loss: 0.9822\")\n",
        "\n",
        "    if abs(last_epoch['val_loss'] - 0.9822) < 0.01:\n",
        "        print(\"\\n⚠️  PROBLEM: Saved LAST epoch model (not best!)\")\n",
        "        print(f\"   You should have saved epoch {int(best_epoch['epoch'])} instead\")\n",
        "        print(f\"   Lost improvement: {0.9822 - best_epoch['val_loss']:.4f}\")\n",
        "    elif abs(best_epoch['val_loss'] - 0.9822) < 0.01:\n",
        "        print(\"\\n✓ Saved the BEST epoch model\")\n",
        "    else:\n",
        "        print(\"\\n🤔 Unclear which epoch was saved\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ No training history found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 971
        },
        "id": "ollRiHJpp_bN",
        "outputId": "75eaa6b0-ff2e-42e7-9cb4-46ec2f819b26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CELL 8: Comprehensive Model Testing\n",
            "======================================================================\n",
            "\n",
            "This cell tests TWO approaches:\n",
            "  1. Quality Signals (normalized, z-scores)\n",
            "  2. Percentage Scores (0-100%, with Sigmoid)\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "APPROACH 1: Quality Signal Predictions\n",
            "======================================================================\n",
            "✓ Targets: ['user_engagement_signal', 'platform_quality_signal', 'quality_final']\n",
            "✓ These are normalized quality signals (z-scores)\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for MultiTaskModel:\n\tMissing key(s) in state_dict: \"backbone.stem.conv.weight\", \"backbone.stem.conv.bias\", \"backbone.stem.bn.weight\", \"backbone.stem.bn.bias\", \"backbone.stem.bn.running_mean\", \"backbone.stem.bn.running_var\", \"backbone.block1.conv.weight\", \"backbone.block1.conv.bias\", \"backbone.block1.bn.weight\", \"backbone.block1.bn.bias\", \"backbone.block1.bn.running_mean\", \"backbone.block1.bn.running_var\", \"backbone.block2.conv.weight\", \"backbone.block2.conv.bias\", \"backbone.block2.bn.weight\", \"backbone.block2.bn.bias\", \"backbone.block2.bn.running_mean\", \"backbone.block2.bn.running_var\", \"backbone.block3.conv.weight\", \"backbone.block3.conv.bias\", \"backbone.block3.bn.weight\", \"backbone.block3.bn.bias\", \"backbone.block3.bn.running_mean\", \"backbone.block3.bn.running_var\", \"heads.0.0.weight\", \"heads.0.0.bias\", \"heads.0.3.weight\", \"heads.0.3.bias\", \"heads.1.0.weight\", \"heads.1.0.bias\", \"heads.1.3.weight\", \"heads.1.3.bias\", \"heads.2.0.weight\", \"heads.2.0.bias\", \"heads.2.3.weight\", \"heads.2.3.bias\". \n\tUnexpected key(s) in state_dict: \"stem.conv.weight\", \"stem.conv.bias\", \"stem.bn.weight\", \"stem.bn.bias\", \"stem.bn.running_mean\", \"stem.bn.running_var\", \"stem.bn.num_batches_tracked\", \"b1.conv.weight\", \"b1.conv.bias\", \"b1.bn.weight\", \"b1.bn.bias\", \"b1.bn.running_mean\", \"b1.bn.running_var\", \"b1.bn.num_batches_tracked\", \"b2.conv.weight\", \"b2.conv.bias\", \"b2.bn.weight\", \"b2.bn.bias\", \"b2.bn.running_mean\", \"b2.bn.running_var\", \"b2.bn.num_batches_tracked\", \"b3.conv.weight\", \"b3.conv.bias\", \"b3.bn.weight\", \"b3.bn.bias\", \"b3.bn.running_mean\", \"b3.bn.running_var\", \"b3.bn.num_batches_tracked\", \"head.1.weight\", \"head.1.bias\", \"head.4.weight\", \"head.4.bias\". ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-18285331.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;31m# Load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0mmodel_quality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiTaskModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_targets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTARGETS_QUALITY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0mmodel_quality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0mmodel_quality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0mmodel_quality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2623\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2624\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2625\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2626\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MultiTaskModel:\n\tMissing key(s) in state_dict: \"backbone.stem.conv.weight\", \"backbone.stem.conv.bias\", \"backbone.stem.bn.weight\", \"backbone.stem.bn.bias\", \"backbone.stem.bn.running_mean\", \"backbone.stem.bn.running_var\", \"backbone.block1.conv.weight\", \"backbone.block1.conv.bias\", \"backbone.block1.bn.weight\", \"backbone.block1.bn.bias\", \"backbone.block1.bn.running_mean\", \"backbone.block1.bn.running_var\", \"backbone.block2.conv.weight\", \"backbone.block2.conv.bias\", \"backbone.block2.bn.weight\", \"backbone.block2.bn.bias\", \"backbone.block2.bn.running_mean\", \"backbone.block2.bn.running_var\", \"backbone.block3.conv.weight\", \"backbone.block3.conv.bias\", \"backbone.block3.bn.weight\", \"backbone.block3.bn.bias\", \"backbone.block3.bn.running_mean\", \"backbone.block3.bn.running_var\", \"heads.0.0.weight\", \"heads.0.0.bias\", \"heads.0.3.weight\", \"heads.0.3.bias\", \"heads.1.0.weight\", \"heads.1.0.bias\", \"heads.1.3.weight\", \"heads.1.3.bias\", \"heads.2.0.weight\", \"heads.2.0.bias\", \"heads.2.3.weight\", \"heads.2.3.bias\". \n\tUnexpected key(s) in state_dict: \"stem.conv.weight\", \"stem.conv.bias\", \"stem.bn.weight\", \"stem.bn.bias\", \"stem.bn.running_mean\", \"stem.bn.running_var\", \"stem.bn.num_batches_tracked\", \"b1.conv.weight\", \"b1.conv.bias\", \"b1.bn.weight\", \"b1.bn.bias\", \"b1.bn.running_mean\", \"b1.bn.running_var\", \"b1.bn.num_batches_tracked\", \"b2.conv.weight\", \"b2.conv.bias\", \"b2.bn.weight\", \"b2.bn.bias\", \"b2.bn.running_mean\", \"b2.bn.running_var\", \"b2.bn.num_batches_tracked\", \"b3.conv.weight\", \"b3.conv.bias\", \"b3.bn.weight\", \"b3.bn.bias\", \"b3.bn.running_mean\", \"b3.bn.running_var\", \"b3.bn.num_batches_tracked\", \"head.1.weight\", \"head.1.bias\", \"head.4.weight\", \"head.4.bias\". "
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# CELL 8: Comprehensive Testing - Both Approaches\n",
        "# ==============================================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import tempfile\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CELL 8: Comprehensive Model Testing\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nThis cell tests TWO approaches:\")\n",
        "print(\"  1. Quality Signals (normalized, z-scores)\")\n",
        "print(\"  2. Percentage Scores (0-100%, with Sigmoid)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ==================== SETUP ====================\n",
        "OUTPUT_DIR = Path(\"/content/models/run_01\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ==================== APPROACH 1: Quality Signals ====================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"APPROACH 1: Quality Signal Predictions\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load config\n",
        "with open(OUTPUT_DIR / \"config.json\", 'r') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "checkpoint_path = Path(config['checkpoint_path'])\n",
        "checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "\n",
        "TARGETS_QUALITY = checkpoint['targets']\n",
        "target_stats = checkpoint['target_stats']\n",
        "\n",
        "print(f\"✓ Targets: {TARGETS_QUALITY}\")\n",
        "print(f\"✓ These are normalized quality signals (z-scores)\")\n",
        "\n",
        "# Model definition (NO Sigmoid)\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel, padding):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size=kernel, padding=padding)\n",
        "        self.bn = nn.BatchNorm2d(out_ch)\n",
        "        self.act = nn.SiLU(inplace=True)\n",
        "    def forward(self, x):\n",
        "        return self.act(self.bn(self.conv(x)))\n",
        "\n",
        "class AudioBackbone(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.stem = ConvBlock(1, 32, (3,7), (1,3))\n",
        "        self.block1 = ConvBlock(32, 64, (3,5), (1,2))\n",
        "        self.block2 = ConvBlock(64, 128, (3,5), (1,2))\n",
        "        self.block3 = ConvBlock(128, 192, (3,3), (1,1))\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        return self.pool(x).flatten(1)\n",
        "\n",
        "class MultiTaskModel(nn.Module):\n",
        "    def __init__(self, n_targets):\n",
        "        super().__init__()\n",
        "        self.backbone = AudioBackbone()\n",
        "        self.heads = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(192, 128),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(0.3),\n",
        "                nn.Linear(128, 1)\n",
        "                # NO Sigmoid!\n",
        "            )\n",
        "            for _ in range(n_targets)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x)\n",
        "        outputs = [head(features).squeeze(1) for head in self.heads]\n",
        "        return torch.stack(outputs, dim=1)\n",
        "\n",
        "# Load model\n",
        "model_quality = MultiTaskModel(n_targets=len(TARGETS_QUALITY))\n",
        "model_quality.load_state_dict(checkpoint['model_state_dict'])\n",
        "model_quality.to(device)\n",
        "model_quality.eval()\n",
        "\n",
        "print(f\"✓ Quality signal model loaded\")\n",
        "\n",
        "# ==================== APPROACH 2: Percentage Scores ====================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"APPROACH 2: Percentage Score Predictions\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Try to find a model with Sigmoid heads\n",
        "MODEL_PATH_PERCENT = None\n",
        "CANDIDATE_PATHS = [\n",
        "    OUTPUT_DIR / \"best_model_sigmoid.pt\",\n",
        "    OUTPUT_DIR / \"phase1_best.pt\",\n",
        "    Path(\"/content/drive/MyDrive/models/phase1/phase1_model.pth\"),\n",
        "]\n",
        "\n",
        "for path in CANDIDATE_PATHS:\n",
        "    if path.exists():\n",
        "        MODEL_PATH_PERCENT = path\n",
        "        break\n",
        "\n",
        "if MODEL_PATH_PERCENT:\n",
        "    print(f\"✓ Found percentage model: {MODEL_PATH_PERCENT}\")\n",
        "\n",
        "    # Model with Sigmoid\n",
        "    class MultiTaskModelSigmoid(nn.Module):\n",
        "        def __init__(self, target_names):\n",
        "            super().__init__()\n",
        "            self.backbone = AudioBackbone()\n",
        "            self.heads = nn.ModuleDict({\n",
        "                name: nn.Sequential(\n",
        "                    nn.Linear(192, 128),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                    nn.Linear(128, 1),\n",
        "                    nn.Sigmoid()  # Output 0-1\n",
        "                )\n",
        "                for name in target_names\n",
        "            })\n",
        "\n",
        "        def forward(self, x):\n",
        "            z = self.backbone(x)\n",
        "            return {name: head(z).squeeze(-1) for name, head in self.heads.items()}\n",
        "\n",
        "    try:\n",
        "        ckpt_percent = torch.load(MODEL_PATH_PERCENT, map_location=device)\n",
        "\n",
        "        # Extract targets\n",
        "        TARGETS_PERCENT = ckpt_percent.get('targets', TARGETS_QUALITY)\n",
        "\n",
        "        model_percent = MultiTaskModelSigmoid(TARGETS_PERCENT)\n",
        "        state_dict = ckpt_percent.get('model_state_dict', ckpt_percent)\n",
        "        model_percent.load_state_dict(state_dict, strict=False)\n",
        "        model_percent.to(device)\n",
        "        model_percent.eval()\n",
        "\n",
        "        print(f\"✓ Percentage model loaded\")\n",
        "        print(f\"  Targets: {TARGETS_PERCENT}\")\n",
        "        HAS_PERCENT_MODEL = True\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️  Could not load percentage model: {e}\")\n",
        "        HAS_PERCENT_MODEL = False\n",
        "else:\n",
        "    print(\"⚠️  No percentage model found (optional)\")\n",
        "    HAS_PERCENT_MODEL = False\n",
        "\n",
        "# ==================== AUDIO PREPROCESSING ====================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Setting up audio preprocessing...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "MEL_BINS = 128\n",
        "FRAMES = 1024\n",
        "\n",
        "def load_feature(filepath):\n",
        "    \"\"\"Load preprocessed feature file\"\"\"\n",
        "    if str(filepath).endswith('.npy'):\n",
        "        arr = np.load(filepath, allow_pickle=False)\n",
        "    else:\n",
        "        with np.load(filepath, allow_pickle=False) as data:\n",
        "            arr = None\n",
        "            for key in ['logmel', 'log_mel', 'mel', 'features', 'x', 'S']:\n",
        "                if key in data:\n",
        "                    arr = data[key]\n",
        "                    break\n",
        "            if arr is None:\n",
        "                arr = data[data.files[0]]\n",
        "\n",
        "    if arr.ndim == 3 and 1 in arr.shape:\n",
        "        arr = arr.squeeze()\n",
        "\n",
        "    if arr.shape[0] != MEL_BINS and arr.shape[1] == MEL_BINS:\n",
        "        arr = arr.T\n",
        "\n",
        "    if arr.shape[1] > FRAMES:\n",
        "        start = (arr.shape[1] - FRAMES) // 2\n",
        "        arr = arr[:, start:start+FRAMES]\n",
        "    elif arr.shape[1] < FRAMES:\n",
        "        pad = FRAMES - arr.shape[1]\n",
        "        arr = np.pad(arr, ((0, 0), (pad//2, pad - pad//2)), mode='constant')\n",
        "\n",
        "    mean = arr.mean()\n",
        "    std = arr.std() + 1e-6\n",
        "    arr = (arr - mean) / std\n",
        "\n",
        "    return torch.from_numpy(arr.astype(np.float32)).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "print(\"✓ Preprocessing ready\")\n",
        "\n",
        "# ==================== PREDICTION FUNCTIONS ====================\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_quality_signals(feature_path):\n",
        "    \"\"\"Predict quality signals (normalized)\"\"\"\n",
        "    x = load_feature(feature_path).to(device)\n",
        "    pred_norm = model_quality(x).cpu().numpy()[0]\n",
        "\n",
        "    # Denormalize\n",
        "    pred_real = {}\n",
        "    for i, target in enumerate(TARGETS_QUALITY):\n",
        "        mean = target_stats[target]['mean']\n",
        "        std = target_stats[target]['std']\n",
        "        pred_real[target] = pred_norm[i] * std + mean\n",
        "\n",
        "    return pred_norm, pred_real\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_percentage_scores(feature_path):\n",
        "    \"\"\"Predict percentage scores (0-100%)\"\"\"\n",
        "    if not HAS_PERCENT_MODEL:\n",
        "        return None\n",
        "\n",
        "    x = load_feature(feature_path).to(device)\n",
        "    out = model_percent(x)\n",
        "\n",
        "    # Convert to percentage\n",
        "    return {t: float(v.item()) * 100.0 for t, v in out.items()}\n",
        "\n",
        "# ==================== DISPLAY FUNCTIONS ====================\n",
        "\n",
        "def display_quality_predictions(filename, pred_norm, pred_real, actual=None):\n",
        "    \"\"\"Display quality signal predictions\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"QUALITY SIGNALS: {filename}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    for target in pred_real.keys():\n",
        "        print(f\"\\n{target.upper().replace('_', ' ')}:\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        value = pred_real[target]\n",
        "        print(f\"  Predicted: {value:7.3f}\")\n",
        "\n",
        "        if actual and target in actual:\n",
        "            print(f\"  Actual:    {actual[target]:7.3f}\")\n",
        "            error = abs(value - actual[target])\n",
        "            print(f\"  Error:     {error:7.3f}\")\n",
        "\n",
        "        # Interpretation (z-score)\n",
        "        if value > 1.5:\n",
        "            print(f\"  → Exceptional (top 7%) ⭐⭐⭐⭐⭐\")\n",
        "        elif value > 0.5:\n",
        "            print(f\"  → Above average (top 31%) ⭐⭐⭐⭐\")\n",
        "        elif value > -0.5:\n",
        "            print(f\"  → Average (middle 38%) ⭐⭐⭐\")\n",
        "        elif value > -1.5:\n",
        "            print(f\"  → Below average (bottom 31%) ⭐⭐\")\n",
        "        else:\n",
        "            print(f\"  → Poor (bottom 7%) ⭐\")\n",
        "\n",
        "def display_percentage_predictions(filename, scores):\n",
        "    \"\"\"Display percentage predictions\"\"\"\n",
        "    if not scores:\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"PERCENTAGE SCORES: {filename}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    labels = {\n",
        "        \"user_engagement_signal\": \"👤 User Engagement\",\n",
        "        \"platform_quality_signal\": \"🎯 Platform Quality\",\n",
        "        \"relative_quality_signal\": \"⭐ Relative Quality\",\n",
        "        \"quality_final\": \"🏆 Overall Quality\",\n",
        "    }\n",
        "\n",
        "    for target, value in scores.items():\n",
        "        bar = \"█\" * int(value/5) + \"░\" * (20 - int(value/5))\n",
        "        label = labels.get(target, target)\n",
        "        print(f\"{label:30s} [{bar}] {value:5.1f}%\")\n",
        "\n",
        "# ==================== FIND TEST FILES ====================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Finding test files...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "master_file = config['master_file']\n",
        "master = pd.read_parquet(master_file)\n",
        "\n",
        "# Select 2 test samples\n",
        "np.random.seed(42)\n",
        "test_indices = np.random.choice(len(master), size=min(2, len(master)), replace=False)\n",
        "test_samples = master.iloc[test_indices].reset_index(drop=True)\n",
        "\n",
        "print(f\"✓ Selected {len(test_samples)} test files\")\n",
        "\n",
        "# ==================== RUN PREDICTIONS ====================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RUNNING PREDICTIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "all_results = []\n",
        "\n",
        "for i, row in test_samples.iterrows():\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"TEST FILE {i+1}/{len(test_samples)}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Video ID: {row['video_id']}\")\n",
        "    print(f\"File: {Path(row['feature_path']).name}\")\n",
        "\n",
        "    try:\n",
        "        # Approach 1: Quality signals\n",
        "        pred_norm, pred_real = predict_quality_signals(row['feature_path'])\n",
        "        actual = {t: row[t] for t in TARGETS_QUALITY if t in row.index}\n",
        "        display_quality_predictions(\n",
        "            Path(row['feature_path']).name,\n",
        "            pred_norm,\n",
        "            pred_real,\n",
        "            actual if actual else None\n",
        "        )\n",
        "\n",
        "        # Approach 2: Percentage scores\n",
        "        if HAS_PERCENT_MODEL:\n",
        "            percent_scores = predict_percentage_scores(row['feature_path'])\n",
        "            display_percentage_predictions(\n",
        "                Path(row['feature_path']).name,\n",
        "                percent_scores\n",
        "            )\n",
        "\n",
        "        # Store results\n",
        "        result = {\n",
        "            'video_id': row['video_id'],\n",
        "            'filename': Path(row['feature_path']).name,\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "        # Add quality predictions\n",
        "        for target in TARGETS_QUALITY:\n",
        "            result[f'quality_{target}'] = pred_real[target]\n",
        "            if target in actual:\n",
        "                result[f'actual_{target}'] = actual[target]\n",
        "\n",
        "        # Add percentage predictions\n",
        "        if HAS_PERCENT_MODEL and percent_scores:\n",
        "            for target, value in percent_scores.items():\n",
        "                result[f'percent_{target}'] = value\n",
        "\n",
        "        all_results.append(result)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# ==================== SAVE RESULTS ====================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SAVING RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if all_results:\n",
        "    df_results = pd.DataFrame(all_results)\n",
        "\n",
        "    # Save CSV\n",
        "    results_csv = OUTPUT_DIR / \"test_predictions_both.csv\"\n",
        "    df_results.to_csv(results_csv, index=False)\n",
        "    print(f\"✓ CSV saved: {results_csv}\")\n",
        "\n",
        "    # Convert numpy types to Python types for JSON\n",
        "    results_for_json = []\n",
        "    for result in all_results:\n",
        "        clean_result = {}\n",
        "        for key, value in result.items():\n",
        "            if isinstance(value, (np.float32, np.float64)):\n",
        "                clean_result[key] = float(value)\n",
        "            elif isinstance(value, (np.int32, np.int64)):\n",
        "                clean_result[key] = int(value)\n",
        "            else:\n",
        "                clean_result[key] = value\n",
        "        results_for_json.append(clean_result)\n",
        "\n",
        "    # Save JSON\n",
        "    results_json = OUTPUT_DIR / \"test_predictions_both.json\"\n",
        "    with open(results_json, 'w') as f:\n",
        "        json.dump(results_for_json, f, indent=2)\n",
        "    print(f\"✓ JSON saved: {results_json}\")\n",
        "\n",
        "# ==================== COMPARISON ====================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COMPARISON: Quality Signals vs Percentage Scores\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\"\"\n",
        "APPROACH 1: Quality Signals (What you just trained)\n",
        "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
        "✓ Normalized z-scores (mean=0, std=1)\n",
        "✓ Can be positive or negative\n",
        "✓ Interpretable: >1.5 = exceptional, 0 = average, <-1.5 = poor\n",
        "✓ Better for comparing songs relatively\n",
        "✓ No artificial constraints\n",
        "\n",
        "Example output:\n",
        "  user_engagement_signal:  0.85  (above average)\n",
        "  platform_quality_signal: 1.23  (exceptional)\n",
        "  quality_final:           1.05  (high quality)\n",
        "\n",
        "APPROACH 2: Percentage Scores (Alternative approach)\n",
        "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
        "✓ Constrained to 0-100% (using Sigmoid)\n",
        "✓ Always positive\n",
        "✓ More intuitive for end users\n",
        "✓ Like a \"score card\"\n",
        "✓ But may not capture extremes well\n",
        "\n",
        "Example output:\n",
        "  user_engagement:  72.5%\n",
        "  platform_quality: 85.3%\n",
        "  quality_final:    78.9%\n",
        "\n",
        "WHICH IS BETTER?\n",
        "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
        "Quality Signals (what you have) are BETTER for:\n",
        "  ✓ Ranking songs\n",
        "  ✓ Finding outliers\n",
        "  ✓ Statistical analysis\n",
        "  ✓ Model training\n",
        "\n",
        "Percentage Scores are BETTER for:\n",
        "  ✓ User-facing dashboards\n",
        "  ✓ Intuitive interpretation\n",
        "  ✓ Business presentations\n",
        "\n",
        "You can always CONVERT between them:\n",
        "  percentage = (quality_signal + 3) / 6 * 100  # Rough conversion\n",
        "\"\"\")\n",
        "\n",
        "# ==================== FINAL VERIFICATION ====================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"VERIFICATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "all_good = True\n",
        "for result in all_results:\n",
        "    for key, value in result.items():\n",
        "        if key.startswith('quality_') and abs(value) < 0.001:\n",
        "            print(f\"⚠️  {result['video_id']}: {key} is near zero\")\n",
        "            all_good = False\n",
        "\n",
        "if all_good:\n",
        "    print(\"✅ ALL QUALITY PREDICTIONS ARE NON-ZERO!\")\n",
        "    print(\"\\n✓ Model trained successfully\")\n",
        "    print(\"✓ Predictions are meaningful\")\n",
        "    print(\"✓ Different songs give different scores\")\n",
        "else:\n",
        "    print(\"⚠️  Some predictions near zero - check normalization\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"🎉 TESTING COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nTested {len(all_results)} files\")\n",
        "print(f\"Results: {results_csv if 'results_csv' in locals() else 'N/A'}\")\n",
        "print(\"\\nYour model is ready!\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n✅ Cell 8 Complete - Pipeline Finished!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}